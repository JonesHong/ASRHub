#!/usr/bin/env python3
"""
éŸ³è¨Šè™•ç†ç®¡ç·šæ¸¬è©¦
é€æ­¥æ¸¬è©¦æ¯å€‹è™•ç†éšæ®µï¼Œæ‰¾å‡ºæ‰å¹€å•é¡Œçš„æ ¹æº

æ¸¬è©¦æµç¨‹ï¼š
1. éº¥å…‹é¢¨åŸå§‹æ“·å– â†’ éŒ„éŸ³ (raw.wav)
2. éº¥å…‹é¢¨ â†’ éŸ³è¨Šå¢å¼· â†’ éŒ„éŸ³ (enhanced.wav)
3. éº¥å…‹é¢¨ â†’ é™å™ª â†’ éŒ„éŸ³ (denoised.wav)
4. éº¥å…‹é¢¨ â†’ å¢å¼· â†’ é™å™ª â†’ éŒ„éŸ³ (full_pipeline.wav)
"""

import time
import signal
import numpy as np
import wave
from pathlib import Path
from datetime import datetime
from typing import Optional, Tuple
import threading

from src.utils.logger import logger
from src.service.microphone_capture.microphone_capture import microphone_capture
from src.service.audio_enhancer import audio_enhancer
from src.core.audio_queue_manager import audio_queue

# DeepFilterNet æ˜¯å¯é¸çš„
try:
    from src.service.denoise.deepfilternet_denoiser import deepfilternet_denoiser
    HAS_DEEPFILTERNET = True
except (ImportError, AttributeError) as e:
    logger.warning(f"DeepFilterNet not available: {e}")
    deepfilternet_denoiser = None
    HAS_DEEPFILTERNET = False


class AudioPipelineTest:
    """éŸ³è¨Šè™•ç†ç®¡ç·šæ¸¬è©¦"""
    
    def __init__(self):
        self.is_running = False
        self.current_test = None
        self.session_id = "pipeline_test"
        self.audio_buffer = []
        self.chunk_count = 0
        self.dropped_frames = 0
        self.last_timestamp = None
        
        # è¨­å®šä¿¡è™Ÿè™•ç†å™¨
        signal.signal(signal.SIGINT, self._signal_handler)
        
        # æ¸¬è©¦åƒæ•¸
        self.sample_rate = 16000
        self.channels = 1
        self.chunk_size = 1024
        self.test_duration = 5  # æ¯å€‹æ¸¬è©¦éŒ„éŸ³5ç§’
        
        # è¼¸å‡ºç›®éŒ„
        self.output_dir = Path("recordings/pipeline_test")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def _signal_handler(self, signum, frame):
        """å„ªé›…åœæ­¢"""
        logger.info("ğŸ›‘ æ¥æ”¶åˆ°åœæ­¢ä¿¡è™Ÿ...")
        self.stop_test()
    
    def stop_test(self):
        """åœæ­¢ç•¶å‰æ¸¬è©¦"""
        self.is_running = False
        
    def save_audio(self, audio_data: np.ndarray, filename: str, test_name: str):
        """å„²å­˜éŸ³è¨Šåˆ°æª”æ¡ˆ"""
        filepath = self.output_dir / filename
        
        # ç¢ºä¿æ˜¯ int16 æ ¼å¼
        if audio_data.dtype != np.int16:
            audio_data = (audio_data * 32767).astype(np.int16)
        
        # å¯«å…¥ WAV æª”æ¡ˆ
        with wave.open(str(filepath), 'wb') as wav_file:
            wav_file.setnchannels(self.channels)
            wav_file.setsampwidth(2)  # int16 = 2 bytes
            wav_file.setframerate(self.sample_rate)
            wav_file.writeframes(audio_data.tobytes())
        
        logger.info(f"âœ… {test_name} éŸ³è¨Šå·²å„²å­˜: {filepath}")
        
        # è¨ˆç®—çµ±è¨ˆè³‡è¨Š
        duration = len(audio_data) / self.sample_rate
        logger.info(f"ğŸ“Š çµ±è¨ˆ:")
        logger.info(f"   â€¢ æ™‚é•·: {duration:.2f} ç§’")
        logger.info(f"   â€¢ æ¨£æœ¬æ•¸: {len(audio_data)}")
        logger.info(f"   â€¢ éŸ³è¨Šç¯„åœ: [{audio_data.min()}, {audio_data.max()}]")
        logger.info(f"   â€¢ RMS: {np.sqrt(np.mean(audio_data.astype(float)**2)):.1f}")
        
        return filepath
    
    def test_raw_capture(self):
        """æ¸¬è©¦1: åŸå§‹éº¥å…‹é¢¨æ“·å–"""
        logger.info("=" * 60)
        logger.info("ğŸ“ æ¸¬è©¦1: åŸå§‹éº¥å…‹é¢¨æ“·å–")
        logger.info("=" * 60)
        
        self.current_test = "raw"
        self.audio_buffer = []
        self.chunk_count = 0
        self.dropped_frames = 0
        self.last_timestamp = None
        
        def audio_callback(audio_data: np.ndarray, sample_rate: int):
            """éŸ³è¨Šå›èª¿"""
            if not self.is_running:
                return
                
            current_time = time.time()
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æ‰å¹€
            if self.last_timestamp:
                expected_interval = self.chunk_size / sample_rate
                actual_interval = current_time - self.last_timestamp
                if actual_interval > expected_interval * 1.5:  # è¶…éé æœŸé–“éš”çš„1.5å€
                    self.dropped_frames += 1
                    logger.warning(f"âš ï¸ å¯èƒ½æ‰å¹€! é–“éš”: {actual_interval:.3f}s (é æœŸ: {expected_interval:.3f}s)")
            
            self.last_timestamp = current_time
            self.chunk_count += 1
            self.audio_buffer.append(audio_data)
            
            # æ¯50å€‹chunkå ±å‘Šä¸€æ¬¡
            if self.chunk_count % 50 == 0:
                logger.info(f"   æ”¶åˆ° chunks: {self.chunk_count}, æ‰å¹€: {self.dropped_frames}")
        
        # è¨­å®šéº¥å…‹é¢¨
        microphone_capture.set_parameters(
            sample_rate=self.sample_rate,
            channels=self.channels,
            chunk_size=self.chunk_size
        )
        
        # é–‹å§‹æ“·å–
        logger.info("ğŸ™ï¸ é–‹å§‹åŸå§‹éŸ³è¨Šæ“·å–...")
        self.is_running = True
        microphone_capture.start_capture(callback=audio_callback)
        
        # éŒ„éŸ³æŒ‡å®šæ™‚é–“
        start_time = time.time()
        while self.is_running and (time.time() - start_time) < self.test_duration:
            time.sleep(0.1)
        
        self.is_running = False
        microphone_capture.stop_capture()
        
        # åˆä½µéŸ³è¨Š
        if self.audio_buffer:
            combined_audio = np.concatenate(self.audio_buffer)
            self.save_audio(combined_audio, "1_raw.wav", "åŸå§‹éŸ³è¨Š")
            logger.info(f"ğŸ“Š ç¸½chunks: {self.chunk_count}, ç¸½æ‰å¹€: {self.dropped_frames}")
            return combined_audio
        else:
            logger.error("âŒ æ²’æœ‰æ”¶åˆ°éŸ³è¨Šè³‡æ–™")
            return None
    
    def test_enhanced_capture(self):
        """æ¸¬è©¦2: éŸ³è¨Šå¢å¼·"""
        logger.info("=" * 60)
        logger.info("ğŸ“ æ¸¬è©¦2: éŸ³è¨Šå¢å¼·è™•ç†")
        logger.info("=" * 60)
        
        self.current_test = "enhanced"
        self.audio_buffer = []
        self.chunk_count = 0
        self.dropped_frames = 0
        self.last_timestamp = None
        
        def audio_callback(audio_data: np.ndarray, sample_rate: int):
            """éŸ³è¨Šå›èª¿ - åŠ ä¸Šå¢å¼·è™•ç†"""
            if not self.is_running:
                return
            
            current_time = time.time()
            
            # æª¢æŸ¥æ‰å¹€
            if self.last_timestamp:
                expected_interval = self.chunk_size / sample_rate
                actual_interval = current_time - self.last_timestamp
                if actual_interval > expected_interval * 1.5:
                    self.dropped_frames += 1
                    logger.warning(f"âš ï¸ å¯èƒ½æ‰å¹€! é–“éš”: {actual_interval:.3f}s")
            
            self.last_timestamp = current_time
            
            # éŸ³è¨Šå¢å¼·
            try:
                enhanced, report = audio_enhancer.auto_enhance(
                    audio_data.tobytes(),
                    purpose="asr"
                )
                
                # è½‰å› numpy array
                enhanced_array = np.frombuffer(enhanced, dtype=np.int16)
                self.audio_buffer.append(enhanced_array)
                
                # æ¯50å€‹chunkå ±å‘Šä¸€æ¬¡å¢å¼·æ•ˆæœ
                if self.chunk_count % 50 == 0:
                    logger.info(f"   å¢å¼·å ±å‘Š: {report}")
                
            except Exception as e:
                logger.error(f"å¢å¼·å¤±æ•—: {e}")
                self.audio_buffer.append(audio_data)
            
            self.chunk_count += 1
        
        # é–‹å§‹æ“·å–
        logger.info("ğŸ™ï¸ é–‹å§‹å¢å¼·éŸ³è¨Šæ“·å–...")
        self.is_running = True
        microphone_capture.start_capture(callback=audio_callback)
        
        # éŒ„éŸ³æŒ‡å®šæ™‚é–“
        start_time = time.time()
        while self.is_running and (time.time() - start_time) < self.test_duration:
            time.sleep(0.1)
        
        self.is_running = False
        microphone_capture.stop_capture()
        
        # åˆä½µéŸ³è¨Š
        if self.audio_buffer:
            combined_audio = np.concatenate(self.audio_buffer)
            self.save_audio(combined_audio, "2_enhanced.wav", "å¢å¼·éŸ³è¨Š")
            logger.info(f"ğŸ“Š ç¸½chunks: {self.chunk_count}, ç¸½æ‰å¹€: {self.dropped_frames}")
            return combined_audio
        else:
            logger.error("âŒ æ²’æœ‰æ”¶åˆ°éŸ³è¨Šè³‡æ–™")
            return None
    
    def test_denoised_capture(self):
        """æ¸¬è©¦3: é™å™ªè™•ç†"""
        if not HAS_DEEPFILTERNET:
            logger.warning("âš ï¸ DeepFilterNet ä¸å¯ç”¨ï¼Œè·³éé™å™ªæ¸¬è©¦")
            return None
            
        logger.info("=" * 60)
        logger.info("ğŸ“ æ¸¬è©¦3: é™å™ªè™•ç†")
        logger.info("=" * 60)
        
        self.current_test = "denoised"
        self.audio_buffer = []
        self.chunk_count = 0
        self.dropped_frames = 0
        self.last_timestamp = None
        
        # ç´¯ç©ç·©è¡å€ï¼ˆé™å™ªéœ€è¦è¼ƒå¤§çš„éŸ³è¨Šç‰‡æ®µï¼‰
        accumulation_buffer = []
        accumulation_size = 8  # ç´¯ç©8å€‹chunkså†è™•ç†
        
        def audio_callback(audio_data: np.ndarray, sample_rate: int):
            """éŸ³è¨Šå›èª¿ - åŠ ä¸Šé™å™ªè™•ç†"""
            if not self.is_running:
                return
            
            current_time = time.time()
            
            # æª¢æŸ¥æ‰å¹€
            if self.last_timestamp:
                expected_interval = self.chunk_size / sample_rate
                actual_interval = current_time - self.last_timestamp
                if actual_interval > expected_interval * 1.5:
                    self.dropped_frames += 1
                    logger.warning(f"âš ï¸ å¯èƒ½æ‰å¹€! é–“éš”: {actual_interval:.3f}s")
            
            self.last_timestamp = current_time
            self.chunk_count += 1
            
            # ç´¯ç©éŸ³è¨Šç‰‡æ®µ
            accumulation_buffer.append(audio_data)
            
            # ç•¶ç´¯ç©è¶³å¤ çš„ç‰‡æ®µæ™‚é€²è¡Œé™å™ª
            if len(accumulation_buffer) >= accumulation_size:
                try:
                    # åˆä½µç´¯ç©çš„éŸ³è¨Š
                    combined = np.concatenate(accumulation_buffer)
                    
                    # é™å™ªè™•ç†
                    denoised, denoise_report = deepfilternet_denoiser.auto_denoise(
                        combined.tobytes(),
                        purpose="asr",
                        sample_rate=sample_rate
                    )
                    
                    # è½‰å› numpy array
                    denoised_array = np.frombuffer(denoised, dtype=np.int16)
                    self.audio_buffer.append(denoised_array)
                    
                    # æ¸…ç©ºç´¯ç©ç·©è¡å€
                    accumulation_buffer.clear()
                    
                    # å ±å‘Šé™å™ªæ•ˆæœ
                    if self.chunk_count % 50 == 0:
                        logger.info(f"   é™å™ªå ±å‘Š: {denoise_report}")
                    
                except Exception as e:
                    logger.error(f"é™å™ªå¤±æ•—: {e}")
                    # å¤±æ•—æ™‚ç›´æ¥ä½¿ç”¨åŸå§‹éŸ³è¨Š
                    self.audio_buffer.append(combined)
                    accumulation_buffer.clear()
        
        # é–‹å§‹æ“·å–
        logger.info("ğŸ™ï¸ é–‹å§‹é™å™ªéŸ³è¨Šæ“·å–...")
        self.is_running = True
        microphone_capture.start_capture(callback=audio_callback)
        
        # éŒ„éŸ³æŒ‡å®šæ™‚é–“
        start_time = time.time()
        while self.is_running and (time.time() - start_time) < self.test_duration:
            time.sleep(0.1)
        
        self.is_running = False
        microphone_capture.stop_capture()
        
        # è™•ç†å‰©é¤˜çš„ç´¯ç©éŸ³è¨Š
        if accumulation_buffer:
            combined = np.concatenate(accumulation_buffer)
            self.audio_buffer.append(combined)
        
        # åˆä½µéŸ³è¨Š
        if self.audio_buffer:
            combined_audio = np.concatenate(self.audio_buffer)
            self.save_audio(combined_audio, "3_denoised.wav", "é™å™ªéŸ³è¨Š")
            logger.info(f"ğŸ“Š ç¸½chunks: {self.chunk_count}, ç¸½æ‰å¹€: {self.dropped_frames}")
            return combined_audio
        else:
            logger.error("âŒ æ²’æœ‰æ”¶åˆ°éŸ³è¨Šè³‡æ–™")
            return None
    
    def test_full_pipeline(self):
        """æ¸¬è©¦4: å®Œæ•´è™•ç†ç®¡ç·šï¼ˆå¢å¼·+é™å™ªï¼‰"""
        logger.info("=" * 60)
        logger.info("ğŸ“ æ¸¬è©¦4: å®Œæ•´è™•ç†ç®¡ç·šï¼ˆå¢å¼·+é™å™ªï¼‰")
        logger.info("=" * 60)
        
        self.current_test = "full"
        self.audio_buffer = []
        self.chunk_count = 0
        self.dropped_frames = 0
        self.last_timestamp = None
        
        # ç´¯ç©ç·©è¡å€
        accumulation_buffer = []
        accumulation_size = 8
        
        def audio_callback(audio_data: np.ndarray, sample_rate: int):
            """éŸ³è¨Šå›èª¿ - å®Œæ•´è™•ç†ç®¡ç·š"""
            if not self.is_running:
                return
            
            current_time = time.time()
            
            # æª¢æŸ¥æ‰å¹€
            if self.last_timestamp:
                expected_interval = self.chunk_size / sample_rate
                actual_interval = current_time - self.last_timestamp
                if actual_interval > expected_interval * 1.5:
                    self.dropped_frames += 1
                    logger.warning(f"âš ï¸ å¯èƒ½æ‰å¹€! é–“éš”: {actual_interval:.3f}s")
            
            self.last_timestamp = current_time
            self.chunk_count += 1
            
            # ç´¯ç©éŸ³è¨Šç‰‡æ®µ
            accumulation_buffer.append(audio_data)
            
            # ç•¶ç´¯ç©è¶³å¤ çš„ç‰‡æ®µæ™‚é€²è¡Œè™•ç†
            if len(accumulation_buffer) >= accumulation_size:
                try:
                    # åˆä½µç´¯ç©çš„éŸ³è¨Š
                    combined = np.concatenate(accumulation_buffer)
                    
                    # æ­¥é©Ÿ1: éŸ³è¨Šå¢å¼·
                    enhanced, enhance_report = audio_enhancer.auto_enhance(
                        combined.tobytes(),
                        purpose="asr"
                    )
                    
                    # æ­¥é©Ÿ2: é™å™ªï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if HAS_DEEPFILTERNET:
                        denoised, denoise_report = deepfilternet_denoiser.auto_denoise(
                            enhanced,
                            purpose="asr",
                            sample_rate=sample_rate
                        )
                        final_audio = np.frombuffer(denoised, dtype=np.int16)
                        
                        if self.chunk_count % 50 == 0:
                            logger.info(f"   å¢å¼·: {enhance_report}")
                            logger.info(f"   é™å™ª: {denoise_report}")
                    else:
                        final_audio = np.frombuffer(enhanced, dtype=np.int16)
                        if self.chunk_count % 50 == 0:
                            logger.info(f"   å¢å¼·: {enhance_report}")
                    
                    self.audio_buffer.append(final_audio)
                    accumulation_buffer.clear()
                    
                except Exception as e:
                    logger.error(f"è™•ç†å¤±æ•—: {e}")
                    self.audio_buffer.append(combined)
                    accumulation_buffer.clear()
        
        # é–‹å§‹æ“·å–
        logger.info("ğŸ™ï¸ é–‹å§‹å®Œæ•´ç®¡ç·šéŸ³è¨Šæ“·å–...")
        self.is_running = True
        microphone_capture.start_capture(callback=audio_callback)
        
        # éŒ„éŸ³æŒ‡å®šæ™‚é–“
        start_time = time.time()
        while self.is_running and (time.time() - start_time) < self.test_duration:
            time.sleep(0.1)
        
        self.is_running = False
        microphone_capture.stop_capture()
        
        # è™•ç†å‰©é¤˜çš„ç´¯ç©éŸ³è¨Š
        if accumulation_buffer:
            combined = np.concatenate(accumulation_buffer)
            self.audio_buffer.append(combined)
        
        # åˆä½µéŸ³è¨Š
        if self.audio_buffer:
            combined_audio = np.concatenate(self.audio_buffer)
            self.save_audio(combined_audio, "4_full_pipeline.wav", "å®Œæ•´ç®¡ç·šéŸ³è¨Š")
            logger.info(f"ğŸ“Š ç¸½chunks: {self.chunk_count}, ç¸½æ‰å¹€: {self.dropped_frames}")
            return combined_audio
        else:
            logger.error("âŒ æ²’æœ‰æ”¶åˆ°éŸ³è¨Šè³‡æ–™")
            return None
    
    def run_all_tests(self):
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        logger.info("ğŸš€ é–‹å§‹éŸ³è¨Šè™•ç†ç®¡ç·šæ¸¬è©¦")
        logger.info(f"æ¸¬è©¦åƒæ•¸: {self.sample_rate}Hz, {self.channels}ch, {self.chunk_size} samples/chunk")
        logger.info(f"æ¯å€‹æ¸¬è©¦éŒ„éŸ³ {self.test_duration} ç§’")
        logger.info(f"è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        logger.info("")
        
        # æ¸¬è©¦1: åŸå§‹éŸ³è¨Š
        logger.info("è«‹å°è‘—éº¥å…‹é¢¨èªªè©±...")
        time.sleep(1)
        self.test_raw_capture()
        time.sleep(1)
        
        # æ¸¬è©¦2: éŸ³è¨Šå¢å¼·
        logger.info("\nè«‹ç¹¼çºŒå°è‘—éº¥å…‹é¢¨èªªè©±...")
        time.sleep(1)
        self.test_enhanced_capture()
        time.sleep(1)
        
        # æ¸¬è©¦3: é™å™ª
        logger.info("\nè«‹ç¹¼çºŒå°è‘—éº¥å…‹é¢¨èªªè©±...")
        time.sleep(1)
        self.test_denoised_capture()
        time.sleep(1)
        
        # æ¸¬è©¦4: å®Œæ•´ç®¡ç·š
        logger.info("\nè«‹ç¹¼çºŒå°è‘—éº¥å…‹é¢¨èªªè©±...")
        time.sleep(1)
        self.test_full_pipeline()
        
        logger.info("\n" + "=" * 60)
        logger.info("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        logger.info(f"è«‹æª¢æŸ¥ {self.output_dir} ç›®éŒ„ä¸­çš„éŸ³è¨Šæª”æ¡ˆï¼š")
        logger.info("  1_raw.wav - åŸå§‹éŸ³è¨Š")
        logger.info("  2_enhanced.wav - å¢å¼·å¾ŒéŸ³è¨Š")
        logger.info("  3_denoised.wav - é™å™ªå¾ŒéŸ³è¨Š")
        logger.info("  4_full_pipeline.wav - å®Œæ•´è™•ç†å¾ŒéŸ³è¨Š")
        logger.info("\næ¯”è¼ƒé€™äº›æª”æ¡ˆå¯ä»¥æ‰¾å‡ºæ‰å¹€å•é¡Œçš„ä¾†æº")
        logger.info("=" * 60)


def main():
    """ä¸»ç¨‹å¼"""
    test = AudioPipelineTest()
    try:
        test.run_all_tests()
    except Exception as e:
        logger.error(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    finally:
        test.stop_test()


if __name__ == "__main__":
    main()