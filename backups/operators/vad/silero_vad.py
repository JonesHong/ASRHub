"""
Silero VAD Operator
ä½¿ç”¨ Silero VAD æ¨¡å‹é€²è¡ŒèªéŸ³æ´»å‹•æª¢æ¸¬
"""

import asyncio
import time
from typing import Dict, Any, Optional, Tuple
import numpy as np
import onnxruntime as ort
from pathlib import Path

from src.operators.base import OperatorBase
from src.core.exceptions import PipelineError
from src.utils.logger import logger
from src.audio import AudioMetadata, AudioSampleFormat
from .model_downloader import ensure_vad_model

# æ¨¡çµ„ç´šè®Šæ•¸ - ç›´æ¥å°å…¥å’Œå¯¦ä¾‹åŒ–
from src.config.manager import ConfigManager
from src.store import get_global_store
from src.core.audio_queue_manager import AudioQueueManager
from src.core.timer_manager import TimerManager

config_manager = ConfigManager()
store = get_global_store()
timer_manager = TimerManager()
audio_queue_manager = AudioQueueManager()


class SileroVADOperator(OperatorBase):
    """ä½¿ç”¨ Silero VAD æ¨¡å‹é€²è¡ŒèªéŸ³æ´»å‹•æª¢æ¸¬"""
    
    def __init__(self):
        """
        åˆå§‹åŒ– Silero VAD Operator
        ä½¿ç”¨æ¨¡çµ„ç´šè®Šæ•¸å’Œ TimerManager ç®¡ç†è¨ˆæ™‚å™¨
        """
        super().__init__()
        
        
        # ç”¨æ–¼è¿½è¹¤ç•¶å‰ session_id
        self.current_session_id = None
        
        self.model = None
        self.h = None  # éš±è—ç‹€æ…‹ h
        self.c = None  # éš±è—ç‹€æ…‹ c
        
        # ç²å–æ ¼å¼è¦æ±‚ - å–®ä¸€çœŸç›¸ä¾†æº
        self.required_format = self.get_required_audio_format()
        self.window_size_samples = 512  # Silero VAD ä½¿ç”¨ 512 æ¨£æœ¬çª—å£
        
        # å¾é…ç½®ä¸­ç²å–è¨­å®š - é…ç½®å¿…é ˆå­˜åœ¨
        vad_config = config_manager.operators.vad
        # æ ¹æ“š VAD é¡å‹ç²å–å°æ‡‰çš„é…ç½®ï¼Œé è¨­ä½¿ç”¨ silero
        if vad_config.type == "silero":
            silero_config = vad_config.silero
            self.threshold = silero_config.threshold
            self.min_silence_duration = silero_config.min_silence_duration
            self.min_speech_duration = silero_config.min_speech_duration
            self.model_path = silero_config.model_path
            # é€²éšåŠŸèƒ½
            self.adaptive_threshold = silero_config.adaptive_threshold
            self.smoothing_window = silero_config.smoothing_window
            # è‡ªé©æ‡‰é–¾å€¼çª—å£å¤§å°
            self.threshold_window_size = silero_config.threshold_window_size
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„ VAD é¡å‹: {vad_config.type}")
        
        # ç‹€æ…‹è¿½è¹¤
        self.in_speech = False
        self.speech_start_time = None
        self.speech_end_time = None
        self.silence_start_time = None
        self.speech_duration = 0
        self.silence_duration = 0
        self.last_speech_end_time = None  # è¨˜éŒ„æœ€å¾Œä¸€æ¬¡èªéŸ³çµæŸæ™‚é–“
        
        # ç·©è¡å€ï¼ˆè™•ç†è·¨å¹€éŸ³è¨Šï¼‰
        self.audio_buffer = bytearray()
        
        # çµ±è¨ˆè³‡è¨Š
        self.total_speech_frames = 0
        self.total_silence_frames = 0
        self.total_frames_processed = 0
        self.frame_count = 0  # æ·»åŠ å¹€è¨ˆæ•¸å™¨
        
        # é€²éšåŠŸèƒ½ç‹€æ…‹
        self.threshold_history = []  # ç”¨æ–¼è‡ªé©æ‡‰é–¾å€¼
        self.probability_history = []  # ç”¨æ–¼å¹³æ»‘è™•ç†
        self.last_speech_prob = 0.0  # ä¿å­˜æœ€å¾Œçš„èªéŸ³æ©Ÿç‡
        
        # å›èª¿å‡½æ•¸
        self.speech_start_callback = None
        self.speech_end_callback = None
        self.vad_result_callback = None
    
    def get_required_audio_format(self) -> AudioMetadata:
        """
        ç²å– Silero VAD éœ€è¦çš„éŸ³é »æ ¼å¼
        
        Silero VAD v4 æ¨¡å‹éœ€æ±‚ï¼š
        - æ¡æ¨£ç‡ï¼š16000 Hzï¼ˆæ¨¡å‹è¨“ç·´æ™‚çš„æ¡æ¨£ç‡ï¼‰
        - è²é“æ•¸ï¼š1ï¼ˆæ¨¡å‹åªæ”¯æ´å–®è²é“ï¼‰
        - æ ¼å¼ï¼šint16ï¼ˆé›–ç„¶å…§éƒ¨æœƒè½‰æ›ç‚º float32ï¼Œä½†è¼¸å…¥æ¥å— int16ï¼‰
        
        Returns:
            éœ€è¦çš„éŸ³é »æ ¼å¼
        """
        return AudioMetadata(
            sample_rate=config_manager.audio.default_sample_rate,  # å¾é…ç½®è®€å–
            channels=config_manager.audio.channels,               # å¾é…ç½®è®€å–
            format=AudioSampleFormat.INT16  # æ¥å— int16 è¼¸å…¥
        )
    
    def get_output_audio_format(self) -> Optional[AudioMetadata]:
        """
        VAD ä¸æ”¹è®ŠéŸ³é »æ ¼å¼ï¼Œåªæ˜¯éæ¿¾å’Œæ¨™è¨˜
        
        Returns:
            None è¡¨ç¤ºè¼¸å‡ºæ ¼å¼èˆ‡è¼¸å…¥ç›¸åŒ
        """
        return None
    
    async def _initialize(self):
        """åˆå§‹åŒ– VAD æ¨¡å‹"""
        logger.info("åˆå§‹åŒ– Silero VAD æ¨¡å‹...")
        
        try:
            # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡è‡ªå‹•ä¸‹è¼‰
            model_path = Path(self.model_path)
            if not model_path.exists():
                logger.info("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé–‹å§‹è‡ªå‹•ä¸‹è¼‰...")
                # å¾é…ç½®ä¸­ç²å–æ¨¡å‹åç¨±
                # æª¢æŸ¥æ˜¯å¦æœ‰ model_name é…ç½®
                try:
                    vad_config = config_manager.operators.vad
                    if vad_config.type == "silero":
                        model_name = vad_config.silero.model_name
                except AttributeError:
                    pass
                models_dir = model_path.parent
                
                # ç¢ºä¿æ¨¡å‹å·²ä¸‹è¼‰
                model_path = await ensure_vad_model(model_name, str(models_dir))
                self.model_path = str(model_path)
            
            # è¼‰å…¥ ONNX æ¨¡å‹
            logger.info(f"è¼‰å…¥ VAD æ¨¡å‹: {model_path}")
            
            # è¨­å®š ONNX Runtime é¸é …
            sess_options = ort.SessionOptions()
            sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            
            # æª¢æŸ¥å¯ç”¨çš„ providers
            available_providers = ort.get_available_providers()
            providers = ['CUDAExecutionProvider']  # é è¨­ä½¿ç”¨ GPU
            
            # å¦‚æœæœ‰ GPU å¯ç”¨ï¼Œå„ªå…ˆä½¿ç”¨
            use_gpu = True
            try:
                vad_config = config_manager.operators.vad
                if vad_config.type == "silero":
                    use_gpu = vad_config.silero.use_gpu
            except AttributeError:
                pass
            
            if 'CUDAExecutionProvider' in available_providers and use_gpu:
                providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                logger.info("ä½¿ç”¨ GPU åŠ é€Ÿ")
            
            self.model = ort.InferenceSession(
                str(model_path),
                sess_options=sess_options,
                providers=providers
            )
            
            # ç²å–æ¨¡å‹è¼¸å…¥è¼¸å‡ºè³‡è¨Š
            self.inputs = self.model.get_inputs()
            self.outputs = self.model.get_outputs()
            
            # è¨˜éŒ„æ‰€æœ‰è¼¸å…¥
            logger.info("æ¨¡å‹è¼¸å…¥:")
            for i, inp in enumerate(self.inputs):
                logger.info(f"  è¼¸å…¥ {i}: {inp.name}, å½¢ç‹€: {inp.shape}, é¡å‹: {inp.type}")
            
            # è¨˜éŒ„æ‰€æœ‰è¼¸å‡º
            logger.info("æ¨¡å‹è¼¸å‡º:")
            for i, out in enumerate(self.outputs):
                logger.info(f"  è¼¸å‡º {i}: {out.name}, å½¢ç‹€: {out.shape}, é¡å‹: {out.type}")
                
            # è¨­ç½®ä¸»è¦è¼¸å…¥è¼¸å‡ºåç¨±
            self.input_name = self.inputs[0].name
            self.output_name = self.outputs[0].name
            
            # åˆå§‹åŒ–éš±è—ç‹€æ…‹ (å¦‚æœæ¨¡å‹éœ€è¦)
            if len(self.inputs) > 2:
                # æª¢æŸ¥æ˜¯å¦æœ‰ h å’Œ c è¼¸å…¥
                for inp in self.inputs:
                    if inp.name == 'h':
                        # å¾å½¢ç‹€ä¸­ç²å–ç¶­åº¦ [2, batch, hidden_size]
                        shape = inp.shape
                        # shape[2] å¯èƒ½æ˜¯å‹•æ…‹çš„ï¼Œä½¿ç”¨é è¨­å€¼ 64
                        hidden_size = 64 if isinstance(shape[2], str) else shape[2]
                        self.h = np.zeros((2, 1, hidden_size), dtype=np.float32)
                        logger.info(f"åˆå§‹åŒ–éš±è—ç‹€æ…‹ h: shape=(2, 1, {hidden_size})")
                    elif inp.name == 'c':
                        # å¾å½¢ç‹€ä¸­ç²å–ç¶­åº¦ [2, batch, hidden_size]
                        shape = inp.shape
                        # shape[2] å¯èƒ½æ˜¯å‹•æ…‹çš„ï¼Œä½¿ç”¨é è¨­å€¼ 64
                        hidden_size = 64 if isinstance(shape[2], str) else shape[2]
                        self.c = np.zeros((2, 1, hidden_size), dtype=np.float32)
                        logger.info(f"åˆå§‹åŒ–éš±è—ç‹€æ…‹ c: shape=(2, 1, {hidden_size})")
            
            logger.info("âœ“ Silero VAD æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ– VAD æ¨¡å‹å¤±æ•—: {e}")
            raise PipelineError(f"VAD åˆå§‹åŒ–å¤±æ•—: {e}")
    
    async def _cleanup(self):
        """æ¸…ç†è³‡æº"""
        logger.info("æ¸…ç† Silero VAD è³‡æº...")
        
        # æ¸…ç©ºç·©è¡å€
        self.audio_buffer.clear()
        
        # é‡ç½®ç‹€æ…‹
        self.in_speech = False
        self.speech_start_time = None
        self.speech_end_time = None
        self.silence_start_time = None
        
        # é‡‹æ”¾æ¨¡å‹
        self.model = None
        
        logger.info("âœ“ Silero VAD è³‡æºæ¸…ç†å®Œæˆ")
    
    async def _process_window(self, window_bytes: bytes, vad_results: list, kwargs: dict):
        """è™•ç†å–®å€‹çª—å£çš„éŸ³è¨Š"""
        # è½‰æ›ç‚º numpy array - ä½¿ç”¨çµ±ä¸€çš„æ ¼å¼
        audio_np = np.frombuffer(window_bytes, dtype=self.required_format.format.numpy_dtype).astype(np.float32)
        audio_np = audio_np / 32768.0  # æ­£è¦åŒ–åˆ° [-1, 1]
        
        # åŸ·è¡Œ VAD æ¨è«–
        speech_prob = await self._run_vad_inference(audio_np)
        
        # å¢åŠ å¹€è¨ˆæ•¸
        self.frame_count += 1
        
        # èª¿è©¦è¼¸å‡º
        if self.frame_count <= 5:  # å‰ 5 å¹€éƒ½è¼¸å‡º
            logger.info(f"VAD æ¨è«–çµæœ: å¹€={self.frame_count}, æ©Ÿç‡={speech_prob:.4f}, éŸ³è¨Šèƒ½é‡={np.abs(audio_np).mean():.4f}, é–¾å€¼={self.threshold}")
        
        # æ‡‰ç”¨å¹³æ»‘è™•ç†
        speech_prob = self._apply_smoothing(speech_prob)
        
        # ä¿å­˜æœ€å¾Œçš„èªéŸ³æ©Ÿç‡
        self.last_speech_prob = float(speech_prob)
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºèªéŸ³ï¼ˆå¯èƒ½ä½¿ç”¨è‡ªé©æ‡‰é–¾å€¼ï¼‰
        current_threshold = self._get_adaptive_threshold() if self.adaptive_threshold else self.threshold
        is_speech = speech_prob > current_threshold
        
        # æ›´æ–°ç‹€æ…‹
        current_time = time.time()
        await self._update_speech_state(is_speech, current_time, speech_prob, **kwargs)
        
        # æ›´æ–°é–¾å€¼æ­·å²ï¼ˆç”¨æ–¼è‡ªé©æ‡‰é–¾å€¼ï¼‰
        if self.adaptive_threshold:
            self._update_threshold_history(speech_prob)
        
        vad_results.append({
            'speech_detected': is_speech,
            'speech_probability': float(speech_prob),
            'timestamp': current_time
        })
        
        self.total_frames_processed += 1
    
    async def process(self, audio_data: bytes, **kwargs) -> Optional[bytes]:
        """
        è™•ç†éŸ³è¨Šä¸¦è¿”å› VAD çµæœ
        
        Args:
            audio_data: è¼¸å…¥éŸ³è¨Šè³‡æ–™
            **kwargs: é¡å¤–åƒæ•¸
            
        Returns:
            audio_data: é€å‚³éŸ³è¨Šï¼Œé™„åŠ  VAD è³‡è¨Šåœ¨ kwargs ä¸­
        """
        # æ›´æ–°ç•¶å‰ session_id
        self.current_session_id = kwargs.get('session_id')
        
        if not self.enabled or not self._initialized:
            return audio_data
        
        if not self.validate_audio_params(audio_data):
            return None
        
        # èª¿è©¦ï¼šæª¢æŸ¥æ¥æ”¶åˆ°çš„éŸ³è¨Š
        if self.frame_count == 0:
            logger.debug(f"ç¬¬ä¸€æ¬¡æ¥æ”¶éŸ³è¨Š: {len(audio_data)} bytes")
            if 'metadata' in kwargs:
                meta = kwargs['metadata']
                if hasattr(meta, 'sample_rate'):  # ç¢ºèªæ˜¯ AudioMetadata å°è±¡
                    logger.debug(f"éŸ³è¨Šæ ¼å¼: {meta.sample_rate}Hz, {meta.channels}ch, {meta.format}")
        
        try:
            # æ·»åŠ éŸ³è¨Šåˆ°ç·©è¡å€
            self.audio_buffer.extend(audio_data)
            
            # è™•ç†å®Œæ•´çš„çª—å£
            bytes_per_sample = self.required_format.format.bytes_per_sample
            window_size_bytes = self.window_size_samples * bytes_per_sample
            
            # èª¿è©¦ï¼šç¬¬ä¸€æ¬¡è™•ç†æ™‚é¡¯ç¤ºè³‡è¨Š
            if self.frame_count == 0:
                logger.info(f"VAD çª—å£åƒæ•¸: æ¨£æœ¬æ•¸={self.window_size_samples}, æ¯æ¨£æœ¬ä½å…ƒçµ„={bytes_per_sample}, çª—å£å¤§å°={window_size_bytes} bytes")
                logger.info(f"ç·©è¡å€å¤§å°: {len(self.audio_buffer)} bytes")
            
            vad_results = []
            
            # è¨ˆç®—éœ€è¦è™•ç†çš„çª—å£æ•¸
            num_windows = len(self.audio_buffer) // window_size_bytes
            
            # å¦‚æœæœ‰å¤šå€‹çª—å£è¦è™•ç†ï¼Œé¡¯ç¤ºè™•ç†è³‡è¨Š
            if num_windows > 5:
                logger.debug(f"VAD é–‹å§‹è™•ç† {num_windows} å€‹éŸ³è¨Šçª—å£")
                window_idx = 0
                while len(self.audio_buffer) >= window_size_bytes:
                    # æ¯è™•ç† 10 å€‹çª—å£é¡¯ç¤ºä¸€æ¬¡é€²åº¦
                    if window_idx % 10 == 0:
                        logger.debug(f"VAD è™•ç†é€²åº¦: {window_idx + 1}/{num_windows}")
                    
                    # æå–ä¸€å€‹çª—å£çš„éŸ³è¨Š
                    window_bytes = self.audio_buffer[:window_size_bytes]
                    self.audio_buffer = self.audio_buffer[window_size_bytes:]
                    
                    # è™•ç†çª—å£ï¼ˆèˆ‡åŸé‚è¼¯ç›¸åŒï¼‰
                    await self._process_window(window_bytes, vad_results, kwargs)
                    window_idx += 1
                
                logger.debug(f"VAD è™•ç†å®Œæˆï¼Œå…±è™•ç† {window_idx} å€‹çª—å£")
            else:
                # å°‘é‡çª—å£ä¸éœ€è¦é€²åº¦æ¢
                while len(self.audio_buffer) >= window_size_bytes:
                    # æå–ä¸€å€‹çª—å£çš„éŸ³è¨Š
                    window_bytes = self.audio_buffer[:window_size_bytes]
                    self.audio_buffer = self.audio_buffer[window_size_bytes:]
                    
                    # è™•ç†çª—å£
                    await self._process_window(window_bytes, vad_results, kwargs)
                
            
            # å°‡ VAD çµæœé™„åŠ åˆ° kwargs
            # ç¢ºä¿æœ‰å€‹å­—å…¸ä¾†å­˜æ”¾ VAD çµæœ
            if 'vad_info' not in kwargs:
                kwargs['vad_info'] = {}
            
            kwargs['vad_info'] = {
                'results': vad_results,
                'in_speech': self.in_speech,
                'continuous_speech': self.speech_duration,
                'continuous_silence': self.silence_duration,
                'stats': {
                    'total_frames': self.total_frames_processed,
                    'speech_frames': self.total_speech_frames,
                    'silence_frames': self.total_silence_frames
                }
            }
            
            # è§¸ç™¼çµæœå›èª¿
            if self.vad_result_callback and vad_results:
                for result in vad_results:
                    await self.vad_result_callback(result)
            
            return audio_data
            
        except Exception as e:
            logger.error(f"VAD è™•ç†éŒ¯èª¤: {e}")
            raise PipelineError(f"VAD è™•ç†å¤±æ•—: {e}")
    
    def update_config(self, config: Dict[str, Any]):
        """
        æ›´æ–° VAD é…ç½®
        
        Args:
            config: é…ç½®å­—å…¸
        """
        logger.debug(f"VAD é…ç½®æ›´æ–°: {config}")
        
        # æ›´æ–°åŸºæœ¬åƒæ•¸
        if 'threshold' in config:
            self.threshold = config['threshold']
            logger.info(f"VAD é–¾å€¼æ›´æ–°ç‚º: {self.threshold}")
        
        if 'min_silence_duration' in config:
            self.min_silence_duration = config['min_silence_duration']
            
        if 'min_speech_duration' in config:
            self.min_speech_duration = config['min_speech_duration']
            
        if 'adaptive_threshold' in config:
            self.adaptive_threshold = config['adaptive_threshold']
            
        if 'smoothing_window' in config:
            self.smoothing_window = config['smoothing_window']
    
    async def _run_vad_inference(self, audio_chunk: np.ndarray) -> float:
        """
        åŸ·è¡Œ VAD æ¨è«–
        
        Args:
            audio_chunk: éŸ³è¨Šæ¨£æœ¬ (æ­£è¦åŒ–çš„ float32)
            
        Returns:
            èªéŸ³æ©Ÿç‡ (0-1)
        """
        try:
            # æº–å‚™è¼¸å…¥å¼µé‡
            # Silero VAD æœŸæœ›è¼¸å…¥å½¢ç‹€: [batch_size, samples]
            input_tensor = audio_chunk.reshape(1, -1)
            
            # åŸ·è¡Œæ¨è«– - ä½¿ç”¨çµ±ä¸€çš„æ¡æ¨£ç‡
            ort_inputs = {
                'input': input_tensor,
                'sr': np.array(self.required_format.sample_rate, dtype=np.int64)
            }
            
            # æ·»åŠ éš±è—ç‹€æ…‹
            if self.h is not None and self.c is not None:
                ort_inputs['h'] = self.h.astype(np.float32)
                ort_inputs['c'] = self.c.astype(np.float32)
            
            # å–å¾—æ‰€æœ‰è¼¸å‡º
            ort_outputs = self.model.run(None, ort_inputs)
            
            # æå–èªéŸ³æ©Ÿç‡
            speech_prob = ort_outputs[0][0].item()
            
            # æ›´æ–°éš±è—ç‹€æ…‹ (å¦‚æœæœ‰ hn å’Œ cn è¼¸å‡º)
            if len(ort_outputs) >= 3:
                self.h = ort_outputs[1]  # hn
                self.c = ort_outputs[2]  # cn
            
            # èª¿è©¦è¼¸å‡º
            if speech_prob > 0.01:  # åªè¼¸å‡ºæœ‰æ„ç¾©çš„æ©Ÿç‡å€¼
                logger.debug(f"VAD æ©Ÿç‡: {speech_prob:.4f}, é–¾å€¼: {self.threshold}")
            
            return speech_prob
            
        except Exception as e:
            logger.error(f"VAD æ¨è«–éŒ¯èª¤: {e}")
            raise
    
    async def _update_speech_state(self, is_speech: bool, timestamp: float, speech_prob: float, **kwargs):
        """
        æ›´æ–°èªéŸ³/éœéŸ³ç‹€æ…‹
        
        Args:
            is_speech: æ˜¯å¦æª¢æ¸¬åˆ°èªéŸ³
            timestamp: ç•¶å‰æ™‚é–“æˆ³
            speech_prob: èªéŸ³æ©Ÿç‡
        """
        frame_duration = self.window_size_samples / self.required_format.sample_rate
        
        if is_speech:
            self.total_speech_frames += 1
            
            if not self.in_speech:
                # èªéŸ³é–‹å§‹
                self.speech_start_time = timestamp
                self.in_speech = True
                self.silence_duration = 0
                self.silence_start_time = None  # é‡ç½®éœéŸ³é–‹å§‹æ™‚é–“
                self._silence_detected_triggered = False  # é‡ç½®éœéŸ³è§¸ç™¼æ¨™è¨˜
                
                logger.debug(f"èªéŸ³é–‹å§‹ (æ©Ÿç‡: {speech_prob:.3f})")
                
                # ä½¿ç”¨ TimerManager å–æ¶ˆéœéŸ³è¨ˆæ™‚å™¨
                if self.current_session_id:
                    timer = timer_manager.get_timer(self.current_session_id)
                    if timer:
                        await timer.on_speech_detected()
                    else:
                        logger.debug(f"No timer found for session: {self.current_session_id}")
                
                # å„ªå…ˆä½¿ç”¨ Store dispatchï¼Œå¦å‰‡ä½¿ç”¨å›å‘¼ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
                if self.store:
                    # ç›´æ¥ dispatch speech_detected action
                    from src.store.sessions.sessions_actions import speech_detected
                    self.store.dispatch(speech_detected(
                        session_id=kwargs.get("session_id"),
                        timestamp=timestamp,
                        confidence=float(speech_prob)
                    ))
                elif self.speech_start_callback:
                    # ä¿ç•™å›å‘¼ä»‹é¢ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
                    await self.speech_start_callback({
                        'timestamp': timestamp,
                        'speech_probability': speech_prob
                    })
            
            # æ›´æ–°èªéŸ³æŒçºŒæ™‚é–“
            if self.speech_start_time:
                self.speech_duration = timestamp - self.speech_start_time
        else:
            self.total_silence_frames += 1
            
            if self.in_speech:
                # èªéŸ³çµæŸï¼Œé–‹å§‹éœéŸ³è¨ˆæ™‚
                if self.silence_start_time is None:
                    self.silence_start_time = timestamp
                    logger.debug(f"é–‹å§‹è¿½è¹¤éœéŸ³æ™‚é–“")
                    
                # è¨ˆç®—éœéŸ³æŒçºŒæ™‚é–“
                silence_elapsed = timestamp - self.silence_start_time
                
                # æª¢æŸ¥æœ€å°èªéŸ³æŒçºŒæ™‚é–“
                speech_duration = timestamp - self.speech_start_time if self.speech_start_time else 0
                if speech_duration >= self.min_speech_duration:
                    # èªéŸ³è¶³å¤ é•·ï¼Œæ¨™è¨˜èªéŸ³çµæŸ
                    logger.info(f"ğŸ”‡ èªéŸ³çµæŸ (èªéŸ³æ™‚é•·: {speech_duration:.3f}s)")
                    
                    # è¨˜éŒ„èªéŸ³çµæŸ
                    self.speech_end_time = timestamp
                    self.last_speech_end_time = self.speech_end_time
                    self.in_speech = False
                    self.speech_duration = 0
                    # ä¸è¦é‡ç½® silence_start_timeï¼Œå› ç‚ºæˆ‘å€‘éœ€è¦ç¹¼çºŒè¨ˆç®—éœéŸ³æ™‚é–“
                    
                    # ç«‹å³ dispatch silence_started action è¡¨ç¤ºé€²å…¥éœéŸ³ç‹€æ…‹
                    if self.store:
                        from src.store.sessions.sessions_actions import silence_started
                        logger.info(f"ğŸ“¢ Dispatching silence_started - é€²å…¥éœéŸ³ç‹€æ…‹")
                        self.store.dispatch(silence_started(
                            session_id=kwargs.get("session_id"),
                            timestamp=timestamp
                        ))
                    
                    # è§¸ç™¼èªéŸ³çµæŸå›å‘¼ï¼ˆå¦‚æœæœ‰ï¼‰
                    if self.speech_end_callback:
                        await self.speech_end_callback({
                            'speech_duration': speech_duration,
                            'timestamp': timestamp
                        })
                # else: èªéŸ³å¤ªçŸ­ï¼Œç¹¼çºŒç­‰å¾…
                
            else:
                # æŒçºŒéœéŸ³
                if self.silence_start_time:
                    # è¨ˆç®—éœéŸ³æŒçºŒæ™‚é–“
                    silence_elapsed = timestamp - self.silence_start_time
                    self.silence_duration = silence_elapsed
                    
                    # æª¢æŸ¥æ˜¯å¦é”åˆ°æœ€å°éœéŸ³æŒçºŒæ™‚é–“ï¼ˆç¢ºèªç‚ºç©©å®šéœéŸ³ï¼‰
                    if not hasattr(self, '_silence_detected_triggered') or not self._silence_detected_triggered:
                        if silence_elapsed >= self.min_silence_duration:
                            # éœéŸ³å·²æŒçºŒè¶³å¤ æ™‚é–“ï¼Œç¾åœ¨æ‰è§¸ç™¼ silence_detected
                            logger.info(f"âœ… ç¢ºèªéœéŸ³ç‹€æ…‹ï¼Œé–‹å§‹å€’æ•¸è¨ˆæ™‚å™¨ (éœéŸ³å·²æŒçºŒ: {silence_elapsed:.3f}s)")
                            
                            # æ¨™è¨˜å·²è§¸ç™¼ï¼Œé¿å…é‡è¤‡
                            self._silence_detected_triggered = True
                            
                            # ä½¿ç”¨ TimerManager é–‹å§‹éœéŸ³è¨ˆæ™‚å™¨
                            if self.current_session_id:
                                timer = timer_manager.get_timer(self.current_session_id)
                                if timer:
                                    logger.info(f"å•Ÿå‹•éœéŸ³è¨ˆæ™‚å™¨ for session: {self.current_session_id}")
                                    await timer.on_silence_detected()
                                else:
                                    logger.warning(f"No timer found for session: {self.current_session_id}")
                            
                            # Dispatch silence_detected actionï¼ˆç¾åœ¨æ‰é–‹å§‹å€’æ•¸ï¼‰
                            if self.store:
                                from src.store.sessions.sessions_actions import silence_detected
                                # å¾é…ç½®è®€å–å€’æ•¸æ™‚é–“
                                try:
                                    countdown_duration = self.config_manager.operators.recording.vad_control.silence_countdown
                                except:
                                    countdown_duration = 1.8  # é è¨­å€¼
                                    
                                logger.info(f"ğŸ“¢ Dispatching silence_detected with countdown: {countdown_duration}s")
                                self.store.dispatch(silence_detected(
                                    session_id=kwargs.get("session_id"),
                                    duration=countdown_duration,
                                    timestamp=timestamp
                                ))
    
    def set_speech_callbacks(self, 
                            start_callback=None, 
                            end_callback=None, 
                            result_callback=None):
        """
        è¨­ç½®èªéŸ³äº‹ä»¶å›èª¿å‡½æ•¸
        
        Args:
            start_callback: èªéŸ³é–‹å§‹å›èª¿
            end_callback: èªéŸ³çµæŸå›èª¿
            result_callback: VAD çµæœå›èª¿
        """
        self.speech_start_callback = start_callback
        self.speech_end_callback = end_callback
        self.vad_result_callback = result_callback
    
    def get_state(self) -> Dict[str, Any]:
        """
        ç²å–ç•¶å‰ VAD ç‹€æ…‹
        
        Returns:
            ç‹€æ…‹å­—å…¸
        """
        return {
            'in_speech': self.in_speech,
            'speech_duration': self.speech_duration,
            'silence_duration': self.silence_duration,
            'total_frames_processed': self.total_frames_processed,
            'total_speech_frames': self.total_speech_frames,
            'total_silence_frames': self.total_silence_frames,
            'speech_ratio': self.total_speech_frames / max(1, self.total_frames_processed),
            'speech_probability': getattr(self, 'last_speech_prob', 0.0)  # æ·»åŠ ç•¶å‰èªéŸ³æ©Ÿç‡
        }
    
    def get_info(self) -> Dict[str, Any]:
        """
        ç²å– Operator è³‡è¨Š
        
        Returns:
            åŒ…å« VAD ç‹€æ…‹çš„è³‡è¨Šå­—å…¸
        """
        # å…ˆå–å¾—åŸºç¤è³‡è¨Š
        info = super().get_info()
        
        # åŠ å…¥ VAD ç‰¹å®šç‹€æ…‹
        vad_state = self.get_state()
        info.update({
            'is_speaking': self.in_speech,
            'speech_probability': vad_state['speech_probability'],
            'in_speech': vad_state['in_speech'],
            'speech_duration': vad_state['speech_duration'],
            'silence_duration': vad_state['silence_duration']
        })
        
        return info
    
    async def reset_state(self):
        """é‡ç½® VAD ç‹€æ…‹"""
        self.in_speech = False
        self.speech_start_time = None
        self.speech_end_time = None
        self.silence_start_time = None
        self.speech_duration = 0
        self.silence_duration = 0
        self.total_speech_frames = 0
        self.total_silence_frames = 0
        self.total_frames_processed = 0
        
        # é‡ç½®æ¨¡å‹ç‹€æ…‹å¼µé‡
        if hasattr(self, 'model') and self.model is not None:
            # é‡ç½®éš±è—ç‹€æ…‹
            if hasattr(self, 'h') and hasattr(self, 'c'):
                # ä¿æŒåŸæœ‰å½¢ç‹€
                if self.h is not None:
                    self.h = np.zeros_like(self.h)
                if self.c is not None:
                    self.c = np.zeros_like(self.c)
                logger.debug("é‡ç½® VAD éš±è—ç‹€æ…‹")
        self.audio_buffer.clear()
        
        logger.debug("VAD ç‹€æ…‹å·²é‡ç½®")
    
    def _apply_smoothing(self, probability: float) -> float:
        """
        æ‡‰ç”¨å¹³æ»‘è™•ç†ä»¥æ¸›å°‘èª¤åˆ¤
        
        Args:
            probability: ç•¶å‰èªéŸ³æ©Ÿç‡
            
        Returns:
            å¹³æ»‘å¾Œçš„æ©Ÿç‡
        """
        # æ·»åŠ åˆ°æ­·å²è¨˜éŒ„
        self.probability_history.append(probability)
        
        # é™åˆ¶æ­·å²è¨˜éŒ„å¤§å°
        if len(self.probability_history) > self.smoothing_window:
            self.probability_history.pop(0)
        
        # å¦‚æœæ­·å²è¨˜éŒ„ä¸è¶³ï¼Œç›´æ¥è¿”å›
        if len(self.probability_history) < self.smoothing_window:
            return probability
        
        # è¨ˆç®—åŠ æ¬Šå¹³å‡ï¼ˆæœ€è¿‘çš„æ¬Šé‡è¼ƒé«˜ï¼‰
        weights = np.linspace(0.5, 1.0, self.smoothing_window)
        weights = weights / weights.sum()
        
        smoothed_prob = np.average(self.probability_history, weights=weights)
        
        return float(smoothed_prob)
    
    def _get_adaptive_threshold(self) -> float:
        """
        è¨ˆç®—è‡ªé©æ‡‰é–¾å€¼
        åŸºæ–¼æœ€è¿‘çš„èªéŸ³æ©Ÿç‡åˆ†å¸ƒå‹•æ…‹èª¿æ•´é–¾å€¼
        
        Returns:
            è‡ªé©æ‡‰é–¾å€¼
        """
        # å¦‚æœæ­·å²è¨˜éŒ„ä¸è¶³ï¼Œä½¿ç”¨é è¨­é–¾å€¼
        if len(self.threshold_history) < self.threshold_window_size:
            return self.threshold
        
        # è¨ˆç®—æœ€è¿‘çª—å£å…§çš„çµ±è¨ˆè³‡è¨Š
        recent_probs = self.threshold_history[-self.threshold_window_size:]
        mean_prob = np.mean(recent_probs)
        std_prob = np.std(recent_probs)
        
        # åŸºæ–¼çµ±è¨ˆè³‡è¨Šè¨ˆç®—è‡ªé©æ‡‰é–¾å€¼
        # ä½¿ç”¨å‡å€¼åŠ ä¸Šæ¨™æº–å·®çš„å€æ•¸ä½œç‚ºé–¾å€¼
        adaptive_threshold = mean_prob + 1.5 * std_prob
        
        # é™åˆ¶é–¾å€¼ç¯„åœ
        adaptive_threshold = np.clip(adaptive_threshold, 0.3, 0.8)
        
        return float(adaptive_threshold)
    
    def _update_threshold_history(self, probability: float):
        """
        æ›´æ–°é–¾å€¼æ­·å²è¨˜éŒ„
        
        Args:
            probability: èªéŸ³æ©Ÿç‡
        """
        self.threshold_history.append(probability)
        
        # é™åˆ¶æ­·å²è¨˜éŒ„å¤§å°
        if len(self.threshold_history) > self.threshold_window_size * 2:
            self.threshold_history = self.threshold_history[-self.threshold_window_size:]
    
    
    async def process_from_queue(self, session_id: str):
        """
        å¾ AudioQueueManager è™•ç†éŸ³è¨Šï¼ˆä¸²æµæ¨¡å¼ï¼‰
        
        Args:
            session_id: Session ID
        """
        # è¨­å®šç•¶å‰ session_id
        self.current_session_id = session_id
        
        if not self.audio_queue_manager:
            logger.warning("VADOperator: No AudioQueueManager configured")
            return
        
        logger.info(f"VADOperator: Starting queue processing for session {session_id}")
        
        # ç¢ºä¿ä½‡åˆ—å­˜åœ¨
        if session_id not in self.audio_queue_manager.queues:
            await self.audio_queue_manager.create_queue(session_id)
        
        try:
            while self.enabled:
                try:
                    # å¾ä½‡åˆ—æ‹‰å–éŸ³è¨Šï¼ˆVAD éœ€è¦å›ºå®šå¤§å°çš„å¡Šï¼‰
                    audio_data = await self.audio_queue_manager.pull(session_id, timeout=0.1)
                    
                    if audio_data:
                        # å‰µå»ºå…ƒæ•¸æ“š
                        metadata = AudioMetadata(
                            sample_rate=self.required_format.sample_rate,
                            channels=self.required_format.channels,
                            format=self.required_format.format
                        )
                        
                        # è™•ç†éŸ³è¨Šä¸¦åŸ·è¡Œ VAD
                        result = await self.process(audio_data, metadata=metadata)
                        
                        # å¦‚æœ Store å­˜åœ¨ï¼Œdispatch VAD çµæœ
                        if self.store and self.in_speech:
                            from src.store.sessions.sessions_actions import speech_detected
                            self.store.dispatch(speech_detected(
                                session_id=session_id,
                                confidence=self.last_speech_prob,
                                timestamp=time.time()
                            ))
                        elif self.store and not self.in_speech and self.silence_duration > self.min_silence_duration:
                            from src.store.sessions.sessions_actions import silence_detected
                            self.store.dispatch(silence_detected(
                                session_id=session_id,
                                duration=self.silence_duration,
                                timestamp=time.time()
                            ))
                    else:
                        # æ²’æœ‰éŸ³è¨Šæ™‚çŸ­æš«ç­‰å¾…
                        await asyncio.sleep(0.01)
                        
                except asyncio.TimeoutError:
                    # è¶…æ™‚æ˜¯æ­£å¸¸çš„ï¼Œç¹¼çºŒç­‰å¾…
                    continue
                except Exception as e:
                    logger.error(f"VADOperator queue processing error: {e}")
                    break
                    
        finally:
            logger.info(f"VADOperator: Stopped queue processing for session {session_id}")