"""
éŸ³è¨Šè™•ç†æ•ˆæœæ¨¡çµ„

è™•ç†éŸ³è¨Šæ•¸æ“šæµã€æ ¼å¼è½‰æ›ã€VADã€å–šé†’è©æª¢æ¸¬ç­‰
"""

from typing import Dict, Optional, Any, List
from src.utils.logger import logger
from .base import BaseEffectHandler
from src.store.sessions.sessions_state import FSMStateEnum
from src.store.sessions.sessions_actions import (
    wake_triggered, speech_detected, silence_started, session_error
)
from src.audio.converter import AudioConverter
from src.audio.models import AudioContainerFormat, AudioMetadata


class AudioProcessingHandler(BaseEffectHandler):
    """éŸ³è¨Šè™•ç† Handler
    
    è² è²¬è™•ç†éŸ³è¨Šæ•¸æ“šæµçš„æ‰€æœ‰æ“ä½œ
    """
    
    def __init__(self, store=None):
        """åˆå§‹åŒ–
        
        Args:
            store: PyStoreX store å¯¦ä¾‹
        """
        super().__init__(store)
        
        # Session operators å­˜å„²ï¼ˆå¼•ç”¨ operator_handler çš„å­˜å„²ï¼‰
        self.session_operators = {}
        
        # åˆå§‹åŒ–éŸ³è¨Šè½‰æ›å™¨
        self.audio_converter = AudioConverter()
    
    def set_session_operators(self, operators: Dict):
        """è¨­ç½® session operators å¼•ç”¨
        
        Args:
            operators: Session operators å­—å…¸
        """
        self.session_operators = operators
    
    async def process_audio_through_operators(self, action) -> List:
        """è™•ç†éŸ³è¨Šé€šéé‹ç®—å­
        
        éŸ³è¨Šè™•ç†æµç¨‹ï¼š
        1. æ ¼å¼è½‰æ› - çµ±ä¸€éŸ³è¨Šæ ¼å¼ (PCM, 16kHz, mono)
        2. WakeWord æª¢æ¸¬ - åœ¨ LISTENING ç‹€æ…‹æª¢æ¸¬å–šé†’è©
        3. VAD è™•ç† - åœ¨ RECORDING ç‹€æ…‹æª¢æ¸¬èªéŸ³/éœéŸ³
        4. AudioQueue - å„²å­˜è™•ç†å¾Œçš„éŸ³è¨Šæ•¸æ“š
        
        æ³¨æ„ï¼šæ–°æ¶æ§‹ä¸­éŸ³è¨Šæ•¸æ“šç›´æ¥æ¨é€åˆ° AudioQueueManager
              
        Args:
            action: éŸ³è¨Š action (ä¾†è‡ª audio_chunk_received)
            
        Returns:
            å¾ŒçºŒ actions åˆ—è¡¨
        """
        session_id = action.payload.get("session_id")
        audio_data = action.payload.get("audio_data")  # å¾ server ä¾†çš„åŸå§‹æ•¸æ“š
        content_type = action.payload.get("content_type", "")
        
        if not session_id:
            logger.warning(f"Missing session_id in audio_chunk_received payload")
            return []
        
        if audio_data is None:
            logger.warning(f"No audio data in audio_chunk_received payload")
            return []
        
        try:
            # ç²å–ç•¶å‰ session ç‹€æ…‹
            session_state = self.get_session_state(session_id)
            if not session_state:
                logger.debug(f"Session {self.format_session_id(session_id)} not found or not initialized")
                return []
            
            current_fsm_state = session_state.get('fsm_state')
            logger.debug(f"Processing audio for session {self.format_session_id(session_id)} in state {current_fsm_state}")
            
            # åŸ·è¡ŒéŸ³è¨Šè™•ç†ç®¡ç·š
            processed_audio = await self._run_audio_pipeline(
                session_id, 
                audio_data, 
                current_fsm_state
            )
            
            # å­˜å…¥ AudioQueue (ç¸½æ˜¯åŸ·è¡Œ)
            if self.audio_queue_manager and processed_audio:
                try:
                    await self.audio_queue_manager.push(session_id, processed_audio)
                    logger.debug(
                        f"Audio pushed to queue for session {self.format_session_id(session_id)}: "
                        f"{len(processed_audio)} bytes"
                    )
                except Exception as e:
                    logger.error(f"Failed to push audio to queue: {e}")
            
            return []
            
        except Exception as e:
            logger.error(f"Operator processing failed for session {self.format_session_id(session_id)}: {e}")
            self.dispatch_error(session_id, str(e))
            return []
    
    async def _run_audio_pipeline(
        self, 
        session_id: str, 
        audio_data: bytes, 
        fsm_state: FSMStateEnum
    ) -> Optional[bytes]:
        """åŸ·è¡ŒéŸ³è¨Šè™•ç†ç®¡ç·š
        
        Args:
            session_id: Session ID
            audio_data: åŸå§‹éŸ³è¨Šæ•¸æ“š
            fsm_state: ç•¶å‰ FSM ç‹€æ…‹
            
        Returns:
            è™•ç†å¾Œçš„éŸ³è¨Šæ•¸æ“š
        """
        # 1. æ ¼å¼è½‰æ› (ç¸½æ˜¯åŸ·è¡Œ)
        audio_data = await self._apply_format_conversion(session_id, audio_data)
        
        # 2. WakeWord æª¢æ¸¬ (åªåœ¨ LISTENING ç‹€æ…‹)
        if fsm_state == FSMStateEnum.LISTENING:
            await self._apply_wakeword_detection(session_id, audio_data)
        
        # 3. VAD è™•ç† (åªåœ¨ RECORDING ç‹€æ…‹)
        elif fsm_state == FSMStateEnum.RECORDING or fsm_state == FSMStateEnum.STREAMING:
            await self._apply_vad_processing(session_id, audio_data)
        
        return audio_data
    
    async def _apply_format_conversion(self, session_id: str, audio_data: bytes) -> bytes:
        """æ‡‰ç”¨æ ¼å¼è½‰æ› - ä½¿ç”¨ AudioConverter
        
        å°‡ä»»æ„æ ¼å¼çš„éŸ³è¨Šè½‰æ›ç‚º PCM 16kHz mono
        
        Args:
            session_id: Session ID
            audio_data: åŸå§‹éŸ³è¨Šæ•¸æ“š
            
        Returns:
            è½‰æ›å¾Œçš„éŸ³è¨Šæ•¸æ“š (PCMæ ¼å¼)
        """
        try:
            # æª¢æ¸¬è¼¸å…¥æ ¼å¼
            input_format = self.audio_converter.detect_format(audio_data)
            
            # å¦‚æœå·²ç¶“æ˜¯ PCM æ ¼å¼ï¼Œæª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ¡æ¨£
            if input_format == AudioContainerFormat.RAW:
                # å‡è¨­å·²ç¶“æ˜¯æ­£ç¢ºçš„æ ¼å¼
                return audio_data
            
            # è¨­å®šç›®æ¨™æ ¼å¼ï¼šPCM 16kHz mono
            target_metadata = AudioMetadata(
                sample_rate=16000,
                channels=1,
                container_format=AudioContainerFormat.RAW
            )
            
            # åŸ·è¡Œè½‰æ›
            converted_chunk = self.audio_converter.convert(
                data=audio_data,
                to_format=AudioContainerFormat.RAW,
                to_metadata=target_metadata,
                from_format=input_format
            )
            
            logger.debug(
                f"Audio converted for session {self.format_session_id(session_id)}: "
                f"{input_format} -> PCM (16kHz, mono)"
            )
            
            return converted_chunk.data
            
        except Exception as e:
            logger.error(f"Format conversion failed: {e}")
            # è¿”å›åŸå§‹æ•¸æ“šï¼Œè®“å¾ŒçºŒè™•ç†æ±ºå®šå¦‚ä½•è™•ç†
            return audio_data
    
    async def _apply_wakeword_detection(self, session_id: str, audio_data: bytes):
        """æ‡‰ç”¨å–šé†’è©æª¢æ¸¬
        
        Args:
            session_id: Session ID
            audio_data: éŸ³è¨Šæ•¸æ“š
        """
        if session_id in self.session_operators.get('wakeword', {}):
            try:
                wakeword = self.session_operators['wakeword'][session_id]
                if hasattr(wakeword, 'process'):
                    detection = await wakeword.process(audio_data)
                    if detection and hasattr(detection, 'confidence'):
                        if detection.confidence > 0.7:  # é–¾å€¼å¯é…ç½®
                            # Phase 3.2: å–šé†’è©æª¢æ¸¬æ—¥èªŒ
                            logger.block("Wake Word Detected", [
                                f"ğŸ† WAKE WORD DETECTED!",
                                f"ğŸ”¹ Session: {self.format_session_id(session_id)}...",
                                f"ğŸ¯ Confidence: {detection.confidence:.2f}",
                                f"ğŸ”Š Trigger: {getattr(detection, 'trigger', 'unknown')}"
                            ])
                            
                            self.dispatch_action(wake_triggered(
                                session_id, 
                                detection.confidence, 
                                getattr(detection, 'trigger', 'unknown')
                            ))
            except Exception as e:
                logger.error(f"WakeWord detection failed: {e}")
    
    async def _apply_vad_processing(self, session_id: str, audio_data: bytes):
        """æ‡‰ç”¨ VAD è™•ç†
        
        Args:
            session_id: Session ID
            audio_data: éŸ³è¨Šæ•¸æ“š
        """
        if session_id in self.session_operators.get('vad', {}):
            try:
                vad = self.session_operators['vad'][session_id]
                if hasattr(vad, 'process'):
                    vad_result = await vad.process(audio_data)
                    if vad_result:
                        if getattr(vad_result, 'is_speech', False):
                            logger.debug(f"Speech detected for session {self.format_session_id(session_id)}")
                            self.dispatch_action(speech_detected(
                                session_id, 
                                getattr(vad_result, 'confidence', 0.5)
                            ))
                        else:
                            silence_duration = getattr(vad_result, 'silence_duration', 0)
                            if silence_duration > 0:
                                logger.debug(
                                    f"Silence detected for session {self.format_session_id(session_id)}: "
                                    f"{silence_duration}s"
                                )
                                self.dispatch_action(silence_started(
                                    session_id, 
                                    silence_duration
                                ))
            except Exception as e:
                logger.error(f"VAD processing failed: {e}")
    
    async def handle_audio_metadata(self, action) -> List:
        """è™•ç†éŸ³è¨Šå…ƒè³‡æ–™
        
        Args:
            action: éŸ³è¨Šå…ƒè³‡æ–™ action
            
        Returns:
            å¾ŒçºŒ actions åˆ—è¡¨
        """
        session_id = action.payload.get("session_id")
        audio_metadata = action.payload.get("audio_metadata")
        
        if not session_id or not audio_metadata:
            logger.warning("Missing session_id or audio_metadata in payload")
            return []
        
        logger.info(
            f"ğŸ“‹ Received audio metadata for session {self.format_session_id(session_id)}: "
            f"{audio_metadata}"
        )
        
        # é€™è£¡å¯ä»¥æ ¹æ“šå…ƒè³‡æ–™èª¿æ•´è™•ç†ç­–ç•¥
        # ä¾‹å¦‚ï¼šæ ¹æ“šéŸ³è¨Šæ ¼å¼å‹•æ…‹é…ç½®æ ¼å¼è½‰æ›å™¨
        
        return []
    
    async def clear_audio_buffer(self, session_id: str):
        """æ¸…é™¤éŸ³è¨Šç·©è¡å€
        
        Args:
            session_id: Session ID
        """
        if self.audio_queue_manager:
            try:
                self.audio_queue_manager.clear_buffer(session_id)
                logger.info(f"ğŸ—‘ï¸ Audio buffer cleared for session {self.format_session_id(session_id)}")
            except Exception as e:
                logger.error(f"Failed to clear audio buffer: {e}")