"""Whisper æ¨¡å‹è¼‰å…¥å™¨ - å…±äº«æ¨¡å‹ç®¡ç†
è² è²¬ï¼š
1. é è¼‰ Whisper æ¨¡å‹
2. æä¾›å…±äº«æ¨¡å‹å¯¦ä¾‹ 
3. èƒŒæ™¯è¼‰å…¥å’Œç‹€æ…‹ç®¡ç†
4. æ”¯æ´å¤šç¨® Whisper å¯¦ç¾

è¨­è¨ˆåŸå‰‡ï¼š
- å–®ä¾‹æ¨¡å¼ï¼šç¢ºä¿å…¨åŸŸåªæœ‰ä¸€å€‹è¼‰å…¥å™¨
- å»¶é²è¼‰å…¥ï¼šæŒ‰éœ€å‰µå»ºæ¨¡å‹
- èƒŒæ™¯è¼‰å…¥ï¼šä¸é˜»å¡ä¸»åŸ·è¡Œç·’
- ç‹€æ…‹ç®¡ç†ï¼šè¿½è¹¤è¼‰å…¥é€²åº¦å’ŒéŒ¯èª¤
"""

import threading
import time
from typing import Dict, Optional, Tuple, Any, Union
from concurrent.futures import ThreadPoolExecutor, Future

from src.utils.logger import logger
from src.interface.exceptions import ServiceInitializationError


class ModelLoader:
    """Whisper æ¨¡å‹è¼‰å…¥å™¨ï¼ˆå–®ä¾‹ï¼‰"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, '_initialized'):
            self._initialized = True
            
            # å·²è¼‰å…¥çš„æ¨¡å‹
            self._loaded_models: Dict[str, Any] = {}
            
            # è¼‰å…¥ç‹€æ…‹ï¼šloading, ready, error
            self._loading_status: Dict[str, str] = {}
            
            # è¼‰å…¥é–å®šï¼ˆé˜²æ­¢é‡è¤‡è¼‰å…¥ï¼‰
            self._loading_locks: Dict[str, threading.Lock] = {}
            
            # èƒŒæ™¯è¼‰å…¥ä»»å‹™
            self._loading_futures: Dict[str, Future] = {}
            
            # åŸ·è¡Œç·’æ± 
            self._executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="ModelLoader")
            
            logger.debug("ModelLoader åˆå§‹åŒ–å®Œæˆ")
    
    def _get_model_key(self, model_type: str, model_name: str, device: str, compute_type: str) -> str:
        """ç”Ÿæˆæ¨¡å‹çš„å”¯ä¸€éµå€¼"""
        return f"{model_type}:{model_name}:{device}:{compute_type}"
    
    def get_status(self) -> Dict[str, Any]:
        """å–å¾—è¼‰å…¥ç‹€æ…‹"""
        return {
            'loaded_models': list(self._loaded_models.keys()),
            'loading_status': self._loading_status.copy(),
            'loading_futures_count': len(self._loading_futures)
        }
    
    def preload_model_async(self, model_type: str, model_name: str, device: str, compute_type: str) -> Future:
        """èƒŒæ™¯é è¼‰æ¨¡å‹ï¼ˆéé˜»å¡ï¼‰
        
        Args:
            model_type: æ¨¡å‹é¡å‹ ("faster-whisper", "whisper")
            model_name: æ¨¡å‹åç¨± (e.g., "base", "small", "turbo")
            device: è¨­å‚™ ("cpu", "cuda")
            compute_type: è¨ˆç®—é¡å‹ ("int8", "float16", "float32")
            
        Returns:
            Future ç‰©ä»¶ï¼Œå¯ç”¨æ–¼æª¢æŸ¥è¼‰å…¥ç‹€æ…‹
        """
        model_key = self._get_model_key(model_type, model_name, device, compute_type)
        
        # å¦‚æœå·²ç¶“è¼‰å…¥æˆ–æ­£åœ¨è¼‰å…¥ï¼Œè¿”å›ç¾æœ‰çš„ Future
        if model_key in self._loaded_models:
            logger.debug(f"æ¨¡å‹å·²è¼‰å…¥: {model_key}")
            # å‰µå»ºä¸€å€‹å·²å®Œæˆçš„ Future
            future = Future()
            future.set_result(self._loaded_models[model_key])
            return future
        
        if model_key in self._loading_futures:
            logger.debug(f"æ¨¡å‹æ­£åœ¨è¼‰å…¥ä¸­: {model_key}")
            return self._loading_futures[model_key]
        
        # å‰µå»ºè¼‰å…¥é–
        if model_key not in self._loading_locks:
            self._loading_locks[model_key] = threading.Lock()
        
        # è¨­å®šè¼‰å…¥ç‹€æ…‹
        self._loading_status[model_key] = "loading"
        
        # æäº¤èƒŒæ™¯è¼‰å…¥ä»»å‹™
        future = self._executor.submit(self._load_model_sync, model_type, model_name, device, compute_type)
        self._loading_futures[model_key] = future
        
        logger.info(f"ğŸš€ èƒŒæ™¯è¼‰å…¥ä»»å‹™å·²æäº¤: {model_key}")
        
        return future
    
    def _load_model_sync(self, model_type: str, model_name: str, device: str, compute_type: str) -> Any:
        """åŒæ­¥è¼‰å…¥æ¨¡å‹ï¼ˆåœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­åŸ·è¡Œï¼‰"""
        model_key = self._get_model_key(model_type, model_name, device, compute_type)
        
        try:
            with self._loading_locks[model_key]:
                # é›™é‡æª¢æŸ¥
                if model_key in self._loaded_models:
                    return self._loaded_models[model_key]
                
                logger.info(f"ğŸ”„ é–‹å§‹è¼‰å…¥æ¨¡å‹: {model_key}")
                start_time = time.time()
                
                if model_type == "faster-whisper":
                    model = self._load_faster_whisper_model(model_name, device, compute_type)
                elif model_type == "whisper":
                    model = self._load_whisper_model(model_name, device)
                else:
                    raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹é¡å‹: {model_type}")
                
                load_time = time.time() - start_time
                
                # å„²å­˜æ¨¡å‹
                self._loaded_models[model_key] = model
                self._loading_status[model_key] = "ready"
                
                # æ¸…ç†è¼‰å…¥ä»»å‹™
                if model_key in self._loading_futures:
                    del self._loading_futures[model_key]
                
                logger.success(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ: {model_key} (è€—æ™‚: {load_time:.2f}s)")
                return model
                
        except Exception as e:
            self._loading_status[model_key] = "error"
            if model_key in self._loading_futures:
                del self._loading_futures[model_key]
            
            logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {model_key}, éŒ¯èª¤: {e}")
            raise ServiceInitializationError(f"ç„¡æ³•è¼‰å…¥æ¨¡å‹ {model_key}: {e}") from e
    
    def _load_faster_whisper_model(self, model_name: str, device: str, compute_type: str) -> Any:
        """è¼‰å…¥ Faster-Whisper æ¨¡å‹"""
        try:
            from faster_whisper import WhisperModel
        except ImportError as e:
            raise ServiceInitializationError(
                "faster-whisper æœªå®‰è£ã€‚è«‹åŸ·è¡Œ: pip install faster-whisper"
            ) from e
        
        logger.info(f"è¼‰å…¥ FasterWhisper æ¨¡å‹: {model_name} on {device} with {compute_type}")
        
        model = WhisperModel(
            model_name,
            device=device,
            compute_type=compute_type,
            cpu_threads=4,
            num_workers=1
        )
        
        return model
    
    def _load_whisper_model(self, model_name: str, device: str) -> Any:
        """è¼‰å…¥åŸå§‹ Whisper æ¨¡å‹"""
        try:
            import whisper
        except ImportError as e:
            raise ServiceInitializationError(
                "whisper æœªå®‰è£ã€‚è«‹åŸ·è¡Œ: pip install openai-whisper"
            ) from e
        
        logger.info(f"è¼‰å…¥ Whisper æ¨¡å‹: {model_name} on {device}")
        
        model = whisper.load_model(model_name, device=device)
        return model
    
    def get_model(self, model_type: str, model_name: str, device: str, compute_type: str, wait: bool = True) -> Tuple[Optional[Any], str]:
        """å–å¾—æ¨¡å‹å¯¦ä¾‹
        
        Args:
            model_type: æ¨¡å‹é¡å‹
            model_name: æ¨¡å‹åç¨±
            device: è¨­å‚™
            compute_type: è¨ˆç®—é¡å‹
            wait: æ˜¯å¦ç­‰å¾…è¼‰å…¥å®Œæˆ
            
        Returns:
            (æ¨¡å‹å¯¦ä¾‹, ç‹€æ…‹) - ç‹€æ…‹å¯èƒ½æ˜¯ "ready", "loading", "error"
        """
        model_key = self._get_model_key(model_type, model_name, device, compute_type)
        
        # å¦‚æœå·²è¼‰å…¥ï¼Œç›´æ¥è¿”å›
        if model_key in self._loaded_models:
            return self._loaded_models[model_key], "ready"
        
        # å¦‚æœä¸ç­‰å¾…ä¸”æ­£åœ¨è¼‰å…¥ï¼Œè¿”å› loading ç‹€æ…‹
        if not wait and model_key in self._loading_status:
            status = self._loading_status[model_key]
            return None, status
        
        # å¦‚æœéœ€è¦ç­‰å¾…ä¸”æœ‰æ­£åœ¨è¼‰å…¥çš„ä»»å‹™
        if model_key in self._loading_futures:
            future = self._loading_futures[model_key]
            if wait:
                try:
                    logger.info(f"â³ ç­‰å¾…æ¨¡å‹è¼‰å…¥å®Œæˆ: {model_key}")
                    model = future.result(timeout=60)  # ç­‰å¾…æœ€å¤š60ç§’
                    return model, "ready"
                except Exception as e:
                    logger.error(f"ç­‰å¾…æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
                    return None, "error"
            else:
                return None, "loading"
        
        # å¦‚æœæ²’æœ‰ä»»ä½•è¼‰å…¥è¨˜éŒ„ï¼Œé–‹å§‹åŒæ­¥è¼‰å…¥ï¼ˆé˜»å¡ï¼‰
        if wait:
            try:
                model = self._load_model_sync(model_type, model_name, device, compute_type)
                return model, "ready"
            except Exception:
                return None, "error"
        else:
            # é–‹å§‹èƒŒæ™¯è¼‰å…¥
            self.preload_model_async(model_type, model_name, device, compute_type)
            return None, "loading"
    
    def is_model_ready(self, model_type: str, model_name: str, device: str, compute_type: str) -> bool:
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²è¼‰å…¥å®Œæˆ"""
        model_key = self._get_model_key(model_type, model_name, device, compute_type)
        return model_key in self._loaded_models
    
    def wait_for_model(self, model_type: str, model_name: str, device: str, compute_type: str, timeout: float = 60.0) -> bool:
        """ç­‰å¾…æ¨¡å‹è¼‰å…¥å®Œæˆ
        
        Args:
            model_type: æ¨¡å‹é¡å‹
            model_name: æ¨¡å‹åç¨±  
            device: è¨­å‚™
            compute_type: è¨ˆç®—é¡å‹
            timeout: è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            True å¦‚æœè¼‰å…¥æˆåŠŸï¼ŒFalse å¦‚æœè¶…æ™‚æˆ–å¤±æ•—
        """
        model_key = self._get_model_key(model_type, model_name, device, compute_type)
        
        # å¦‚æœå·²è¼‰å…¥ï¼Œç«‹å³è¿”å›
        if model_key in self._loaded_models:
            return True
        
        # å¦‚æœæœ‰è¼‰å…¥ä»»å‹™ï¼Œç­‰å¾…å®Œæˆ
        if model_key in self._loading_futures:
            future = self._loading_futures[model_key]
            try:
                future.result(timeout=timeout)
                return True
            except Exception as e:
                logger.error(f"ç­‰å¾…æ¨¡å‹è¼‰å…¥è¶…æ™‚æˆ–å¤±æ•—: {e}")
                return False
        
        # æ²’æœ‰è¼‰å…¥ä»»å‹™ï¼Œè¿”å› False
        return False
    
    def shutdown(self):
        """é—œé–‰æ¨¡å‹è¼‰å…¥å™¨"""
        logger.info("æ­£åœ¨é—œé–‰ ModelLoader...")
        self._executor.shutdown(wait=True)
        logger.info("ModelLoader å·²é—œé–‰")


# æ¨¡çµ„ç´šåˆ¥çš„å–®ä¾‹
model_loader = ModelLoader()