"""
OpenWakeWord Operator å¯¦ä½œ
æ”¯æ´ openWakeWord æ¨¡å‹è¼‰å…¥ã€å³æ™‚éŸ³è¨Šè™•ç†å’Œå–šé†’è©åµæ¸¬
"""

import os
import asyncio
from typing import Dict, Any, Optional, List, Tuple
from collections import defaultdict, deque
from functools import partial
import numpy as np
import scipy.signal
from datetime import datetime
from huggingface_hub import hf_hub_download, HfFolder

from src.pipeline.operators.base import OperatorBase
from src.core.exceptions import PipelineError
from src.config.manager import ConfigManager


class OpenWakeWordOperator(OperatorBase):
    """
    OpenWakeWord å–šé†’è©åµæ¸¬ Operator
    
    ç‰¹é»ï¼š
    - æ”¯æ´ ONNX æ¨¡å‹æ¨è«–
    - è‡ªå‹•é‡æ¡æ¨£åˆ° 16kHz
    - æ»‘å‹•è¦–çª—æ©Ÿåˆ¶ï¼ˆ1280 æ¨£æœ¬/å¹€ï¼‰
    - 60 å¹€è©•åˆ†ä½‡åˆ—
    - å¯é…ç½®çš„åµæ¸¬é–¾å€¼
    - å»æŠ–å‹•æ©Ÿåˆ¶é˜²æ­¢é‡è¤‡è§¸ç™¼
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ– OpenWakeWord Operator
        """
        # å¾ ConfigManager è®€å–é…ç½®
        config_manager = ConfigManager()
        config = {
            "enabled": True,
            "model_path": None,
            "threshold": 0.5,
            "language": "zh-TW"
        }
        
        # è¨­å®šé è¨­å€¼
        self.hf_repo_id = "JTBTechnology/kmu_wakeword"
        self.hf_filename = "hi_kmu_0721.onnx"
        self.hf_token = None
        
        # å¾é…ç½®ä¸­ç²å– wakeword ç›¸é—œè¨­å®š
        if hasattr(config_manager, 'wake_word_detection') and config_manager.wake_word_detection.enabled:
            # æ‰¾åˆ° openWakeWord é…ç½®
            for model_config in config_manager.wake_word_detection.models:
                if model_config.type == "openWakeWord":
                    config = {
                        "enabled": model_config.enabled,
                        "model_path": model_config.model_path,
                        "threshold": model_config.threshold,
                        "language": model_config.language
                    }
                    # ç²å–å…¶ä»–é…ç½®
                    self.hf_repo_id = getattr(model_config, 'hf_repo_id', self.hf_repo_id)
                    self.hf_filename = getattr(model_config, 'hf_filename', self.hf_filename)
                    self.hf_token = getattr(model_config, 'hf_token', self.hf_token)
                    break
        
        super().__init__(config)
        
        # æ¨¡å‹ç›¸é—œ
        self.model = None
        self.model_path = self.config.get("model_path")
        # hf_repo_id, hf_filename, hf_token å·²åœ¨ä¸Šé¢è¨­å®š
        
        # éŸ³è¨Šè™•ç†åƒæ•¸
        self.chunk_size = 1280  # openWakeWord éœ€è¦çš„å›ºå®šå¤§å°
        self.target_sample_rate = 16000  # æ¨¡å‹éœ€è¦ 16kHz
        
        # ç‹€æ…‹ç®¡ç†
        self.state = defaultdict(partial(deque, maxlen=60))  # 60 å¹€çš„è©•åˆ†ä½‡åˆ—
        
        # åµæ¸¬åƒæ•¸
        self.threshold = self.config.get("threshold", 0.5)
        self.detection_cooldown = self.config.get("detection_cooldown", 0.8)  # å†·å»æœŸï¼ˆç§’ï¼‰
        self.last_detection_time = 0
        
        # éŸ³è¨Šç·©è¡å€ï¼ˆç”¨æ–¼é‡æ¡æ¨£ï¼‰
        self.audio_buffer = np.array([], dtype=np.float32)
        
        # åµæ¸¬å›å‘¼
        self.detection_callback = None
    
    async def _initialize(self):
        """åˆå§‹åŒ– Operator è³‡æº"""
        self.logger.info("åˆå§‹åŒ– OpenWakeWord Operator...")
        
        # è¼‰å…¥æ¨¡å‹
        await self._load_model()
        
        # æ¸…ç©ºç‹€æ…‹
        self.state.clear()
        self.audio_buffer = np.array([], dtype=np.float32)
        self.last_detection_time = 0
        
        self.logger.info("âœ“ OpenWakeWord Operator åˆå§‹åŒ–å®Œæˆ")
    
    async def _cleanup(self):
        """æ¸…ç† Operator è³‡æº"""
        self.logger.info("æ¸…ç† OpenWakeWord Operator...")
        
        # æ¸…ç†æ¨¡å‹
        if self.model:
            del self.model
            self.model = None
        
        # æ¸…ç†ç‹€æ…‹
        self.state.clear()
        self.audio_buffer = np.array([], dtype=np.float32)
        
        self.logger.info("âœ“ OpenWakeWord Operator æ¸…ç†å®Œæˆ")
    
    async def _load_model(self):
        """è¼‰å…¥ openWakeWord æ¨¡å‹"""
        try:
            # å‹•æ…‹å°å…¥ openwakewordï¼ˆé¿å…åœ¨æ²’æœ‰å®‰è£æ™‚å ±éŒ¯ï¼‰
            from openwakeword.model import Model
            from openwakeword.utils import download_models
        except ImportError:
            raise PipelineError("è«‹å®‰è£ openwakeword: pip install openwakeword")
        
        # ä¸‹è¼‰é è¨­æ¨¡å‹
        download_models()
        
        # æ±ºå®šæ¨¡å‹è·¯å¾‘
        model_path = self.model_path
        
        if not model_path:
            # å˜—è©¦å¾ HuggingFace ä¸‹è¼‰
            # å„ªå…ˆä½¿ç”¨é…ç½®ä¸­çš„ tokenï¼Œå¦å‰‡å¾ç’°å¢ƒè®Šæ•¸æˆ– HfFolder ç²å–
            hf_token = self.hf_token or os.environ.get("HF_TOKEN") or HfFolder.get_token()
            
            if hf_token and self.hf_repo_id and self.hf_filename:
                self.logger.info(f"å¾ HuggingFace ä¸‹è¼‰æ¨¡å‹: {self.hf_repo_id}/{self.hf_filename}")
                try:
                    model_path = hf_hub_download(
                        repo_id=self.hf_repo_id,
                        filename=self.hf_filename,
                        token=hf_token,
                        repo_type="model"
                    )
                    self.logger.info(f"âœ“ æ¨¡å‹ä¸‹è¼‰æˆåŠŸ: {model_path}")
                except Exception as e:
                    self.logger.error(f"æ¨¡å‹ä¸‹è¼‰å¤±æ•—: {e}")
                    raise PipelineError(f"ç„¡æ³•ä¸‹è¼‰æ¨¡å‹: {e}")
            else:
                raise PipelineError("è«‹è¨­å®šæ¨¡å‹è·¯å¾‘æˆ–æä¾› HF_TOKEN")
        
        # è¼‰å…¥æ¨¡å‹
        try:
            self.model = Model(
                wakeword_models=[model_path],
                inference_framework="onnx"
            )
            self.logger.info(f"âœ“ æ¨¡å‹è¼‰å…¥æˆåŠŸ: {model_path}")
        except Exception as e:
            self.logger.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise PipelineError(f"ç„¡æ³•è¼‰å…¥æ¨¡å‹: {e}")
    
    async def process(self, audio_data: bytes, **kwargs) -> Optional[bytes]:
        """
        è™•ç†éŸ³è¨Šè³‡æ–™ï¼Œåµæ¸¬å–šé†’è©
        
        Args:
            audio_data: è¼¸å…¥éŸ³è¨Šè³‡æ–™ï¼ˆbytesï¼‰
            **kwargs: é¡å¤–åƒæ•¸
                - sample_rate: è¼¸å…¥éŸ³è¨Šçš„æ¡æ¨£ç‡
                - session_id: æœƒè©± ID
            
        Returns:
            åŸå§‹éŸ³è¨Šè³‡æ–™ï¼ˆä¸ä¿®æ”¹ï¼‰
        """
        if not self.enabled or not self.model:
            return audio_data
        
        if not self.validate_audio_params(audio_data):
            return audio_data
        
        # ç²å–æ¡æ¨£ç‡
        input_sample_rate = kwargs.get("sample_rate", self.sample_rate)
        
        # è½‰æ›ç‚º numpy array
        audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32)
        
        # æ·»åŠ åˆ°ç·©è¡å€
        self.audio_buffer = np.concatenate([self.audio_buffer, audio_np])
        
        # é‡æ¡æ¨£åˆ° 16kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
        if input_sample_rate != self.target_sample_rate:
            # è¨ˆç®—éœ€è¦çš„æ¨£æœ¬æ•¸
            target_length = int(len(self.audio_buffer) * self.target_sample_rate / input_sample_rate)
            
            # å¦‚æœç·©è¡å€å¤ªå°ï¼Œç­‰å¾…æ›´å¤šè³‡æ–™
            if target_length < self.chunk_size:
                return audio_data
            
            # é‡æ¡æ¨£
            resampled = scipy.signal.resample(self.audio_buffer, target_length)
            self.audio_buffer = resampled
        
        # è™•ç†å®Œæ•´çš„ chunks
        detections = []
        while len(self.audio_buffer) >= self.chunk_size:
            # å–å‡ºä¸€å€‹ chunk
            chunk = self.audio_buffer[:self.chunk_size]
            self.audio_buffer = self.audio_buffer[self.chunk_size:]
            
            # æ¨è«–
            try:
                predictions = self.model.predict(chunk)
                
                # æ›´æ–°ç‹€æ…‹ä¸¦æª¢æŸ¥åµæ¸¬
                for model_name, score in predictions.items():
                    # æ›´æ–°è©•åˆ†ä½‡åˆ—
                    if len(self.state[model_name]) == 0:
                        # åˆå§‹åŒ–ç‚ºé›¶
                        self.state[model_name].extend(np.zeros(60))
                    
                    self.state[model_name].append(score)
                    
                    # æª¢æŸ¥æ˜¯å¦è¶…éé–¾å€¼
                    if score > self.threshold:
                        current_time = asyncio.get_event_loop().time()
                        
                        # æª¢æŸ¥å†·å»æœŸ
                        if current_time - self.last_detection_time > self.detection_cooldown:
                            self.last_detection_time = current_time
                            
                            detection = {
                                "model": model_name,
                                "score": float(score),
                                "timestamp": datetime.now().isoformat(),
                                "session_id": kwargs.get("session_id")
                            }
                            detections.append(detection)
                            
                            self.logger.info(
                                f"ğŸ¯ åµæ¸¬åˆ°å–šé†’è©ï¼æ¨¡å‹: {model_name}, "
                                f"åˆ†æ•¸: {score:.3f}"
                            )
                            
                            # è§¸ç™¼å›å‘¼
                            if self.detection_callback:
                                await self._trigger_callback(detection)
            
            except Exception as e:
                self.logger.error(f"æ¨è«–éŒ¯èª¤: {e}")
        
        # å°‡åµæ¸¬çµæœå­˜å…¥ kwargsï¼ˆä¾›å¾ŒçºŒ operator ä½¿ç”¨ï¼‰
        if detections:
            kwargs["wake_word_detections"] = detections
        
        # è¿”å›åŸå§‹éŸ³è¨Šï¼ˆä¸ä¿®æ”¹ï¼‰
        return audio_data
    
    async def _trigger_callback(self, detection: Dict[str, Any]):
        """è§¸ç™¼åµæ¸¬å›å‘¼"""
        try:
            if asyncio.iscoroutinefunction(self.detection_callback):
                await self.detection_callback(detection)
            else:
                self.detection_callback(detection)
        except Exception as e:
            self.logger.error(f"å›å‘¼åŸ·è¡ŒéŒ¯èª¤: {e}")
    
    def set_detection_callback(self, callback):
        """
        è¨­å®šå–šé†’è©åµæ¸¬å›å‘¼å‡½æ•¸
        
        Args:
            callback: åµæ¸¬åˆ°å–šé†’è©æ™‚å‘¼å«çš„å‡½æ•¸
        """
        self.detection_callback = callback
    
    def get_scores(self, model_name: Optional[str] = None) -> Dict[str, List[float]]:
        """
        ç²å–è©•åˆ†æ­·å²
        
        Args:
            model_name: æ¨¡å‹åç¨±ï¼Œå¦‚æœä¸æŒ‡å®šå‰‡è¿”å›æ‰€æœ‰æ¨¡å‹
            
        Returns:
            è©•åˆ†æ­·å²å­—å…¸
        """
        if model_name:
            return {model_name: list(self.state.get(model_name, []))}
        else:
            return {name: list(scores) for name, scores in self.state.items()}
    
    def get_latest_score(self, model_name: Optional[str] = None) -> Optional[float]:
        """
        ç²å–æœ€æ–°è©•åˆ†
        
        Args:
            model_name: æ¨¡å‹åç¨±
            
        Returns:
            æœ€æ–°è©•åˆ†ï¼Œå¦‚æœæ²’æœ‰å‰‡è¿”å› None
        """
        if not model_name and self.state:
            # ä½¿ç”¨ç¬¬ä¸€å€‹æ¨¡å‹
            model_name = list(self.state.keys())[0]
        
        if model_name and model_name in self.state and self.state[model_name]:
            return self.state[model_name][-1]
        
        return None
    
    async def flush(self):
        """æ¸…ç©ºå…§éƒ¨ç·©è¡å€"""
        self.audio_buffer = np.array([], dtype=np.float32)
        for model_name in self.state:
            self.state[model_name].clear()
            self.state[model_name].extend(np.zeros(60))
        self.logger.debug("å·²æ¸…ç©ºéŸ³è¨Šç·©è¡å€å’Œè©•åˆ†ä½‡åˆ—")
    
    def update_config(self, config: Dict[str, Any]):
        """æ›´æ–°é…ç½®"""
        super().update_config(config)
        
        # æ›´æ–°ç‰¹å®šåƒæ•¸
        if "threshold" in config:
            self.threshold = config["threshold"]
            self.logger.info(f"æ›´æ–°åµæ¸¬é–¾å€¼: {self.threshold}")
        
        if "detection_cooldown" in config:
            self.detection_cooldown = config["detection_cooldown"]
            self.logger.info(f"æ›´æ–°å†·å»æœŸ: {self.detection_cooldown}ç§’")
    
    def get_info(self) -> Dict[str, Any]:
        """ç²å– Operator è³‡è¨Š"""
        info = super().get_info()
        info.update({
            "model_loaded": self.model is not None,
            "model_path": self.model_path,
            "threshold": self.threshold,
            "detection_cooldown": self.detection_cooldown,
            "buffer_size": len(self.audio_buffer),
            "models": list(self.state.keys()) if self.state else []
        })
        return info