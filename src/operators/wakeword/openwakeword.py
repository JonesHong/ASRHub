"""
OpenWakeWord Operator å¯¦ä½œ
æ”¯æ´ openWakeWord æ¨¡å‹è¼‰å…¥ã€å³æ™‚éŸ³è¨Šè™•ç†å’Œå–šé†’è©åµæ¸¬
"""

import os
import asyncio
from typing import Dict, Any, Optional, List, Tuple
from collections import defaultdict, deque
from functools import partial
import numpy as np
import scipy.signal
from datetime import datetime
from huggingface_hub import hf_hub_download, HfFolder

# æ¨¡çµ„ç´šè®Šæ•¸ - ç›´æ¥å°å…¥å’Œå¯¦ä¾‹åŒ–
from src.utils.logger import logger
from src.operators.base import OperatorBase
from src.core.exceptions import PipelineError
from src.config.manager import ConfigManager
from src.audio import AudioMetadata, AudioSampleFormat
from src.store import get_global_store
from src.core.audio_queue_manager import get_audio_queue_manager

config_manager = ConfigManager()
store = get_global_store()
audio_queue_manager = get_audio_queue_manager()


class OpenWakeWordOperator(OperatorBase):
    """
    OpenWakeWord å–šé†’è©åµæ¸¬ Operator
    
    ç‰¹é»ï¼š
    - æ”¯æ´ ONNX æ¨¡å‹æ¨è«–
    - è‡ªå‹•é‡æ¡æ¨£åˆ° 16kHz
    - æ»‘å‹•è¦–çª—æ©Ÿåˆ¶ï¼ˆ1280 æ¨£æœ¬/å¹€ï¼‰
    - 60 å¹€è©•åˆ†ä½‡åˆ—
    - å¯é…ç½®çš„åµæ¸¬é–¾å€¼
    - å»æŠ–å‹•æ©Ÿåˆ¶é˜²æ­¢é‡è¤‡è§¸ç™¼
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ– OpenWakeWord Operator
        ä½¿ç”¨æ¨¡çµ„ç´šè®Šæ•¸æä¾›çµ±ä¸€çš„ä¾è³´é …
        """
        super().__init__()
        
        # ä½¿ç”¨æ¨¡çµ„ç´šå…¨åŸŸå¯¦ä¾‹ï¼ˆç¹¼æ‰¿è‡ª OperatorBaseï¼‰
        # self.config_manager, self.store, self.audio_queue_manager å·²åœ¨åŸºé¡ä¸­è¨­å®š
        config = {
            "enabled": True,
            "model_path": None,
            "threshold": 0.5,
            "language": "zh-TW"
        }
        
        # å¾é…ç½®ä¸­ç²å– wakeword ç›¸é—œè¨­å®š
        if hasattr(self.config_manager, 'wake_word_detection') and self.config_manager.wake_word_detection.enabled:
            # æ‰¾åˆ° openWakeWord é…ç½®
            for model_config in self.config_manager.wake_word_detection.models:
                if model_config.type == "openWakeWord":
                    config = {
                        "enabled": model_config.enabled,
                        "model_path": model_config.model_path,
                        "threshold": model_config.threshold,
                        "language": model_config.language
                    }
                    # ç›´æ¥ä½¿ç”¨ yaml2py ç”Ÿæˆçš„å±¬æ€§ï¼Œå®ƒå€‘å·²ç¶“æœ‰é è¨­å€¼
                    self.hf_repo_id = model_config.hf_repo_id
                    self.hf_filename = model_config.hf_filename
                    self.hf_token = model_config.hf_token
                    # å¾ wake_word_detection å±¤ç´šç²å– cooldown
                    self.detection_cooldown = self.config_manager.wake_word_detection.cooldown
                    break
        else:
            # å¦‚æœæ²’æœ‰é…ç½®ï¼Œä½¿ç”¨é è¨­å€¼
            self.hf_repo_id = "JTBTechnology/kmu_wakeword"
            self.hf_filename = "hi_kmu_0721.onnx"
            self.hf_token = None
            self.detection_cooldown = 2.0
        
        # ä¿å­˜é…ç½®ï¼ˆå…§éƒ¨ä½¿ç”¨ï¼‰
        self._config = config
        
        # æ¨¡å‹ç›¸é—œ
        self.model = None
        self.model_path = config["model_path"]
        # hf_repo_id, hf_filename, hf_token å·²åœ¨ä¸Šé¢è¨­å®š
        
        # éŸ³è¨Šè™•ç†åƒæ•¸
        self.chunk_size = 1280  # openWakeWord éœ€è¦çš„å›ºå®šå¤§å°
        self.sample_rate = self.config_manager.pipeline.default_sample_rate  # å¾é…ç½®è®€å–æ¡æ¨£ç‡
        
        # ç‹€æ…‹ç®¡ç†
        self.state = defaultdict(partial(deque, maxlen=60))  # 60 å¹€çš„è©•åˆ†ä½‡åˆ—
        
        # åµæ¸¬åƒæ•¸
        self.threshold = config["threshold"]
        # detection_cooldown å·²åœ¨ä¸Šé¢è¨­å®š
        self.last_detection_time = 0
        
        # è¨­å®šå•Ÿç”¨ç‹€æ…‹
        self.enabled = config["enabled"]
        
        # éŸ³è¨Šç·©è¡å€ï¼ˆç”¨æ–¼é‡æ¡æ¨£ï¼‰
        self.audio_buffer = np.array([], dtype=np.float32)
        
        # åµæ¸¬å›å‘¼
        self.detection_callback = None
    
    async def _initialize(self):
        """åˆå§‹åŒ– Operator è³‡æº"""
        logger.info("åˆå§‹åŒ– OpenWakeWord Operator...")
        
        # è¼‰å…¥æ¨¡å‹
        await self._load_model()
        
        # æ¸…ç©ºç‹€æ…‹
        self.state.clear()
        self.audio_buffer = np.array([], dtype=np.float32)
        self.last_detection_time = 0
        
        logger.info("âœ“ OpenWakeWord Operator åˆå§‹åŒ–å®Œæˆ")
    
    async def _cleanup(self):
        """æ¸…ç† Operator è³‡æº"""
        logger.info("æ¸…ç† OpenWakeWord Operator...")
        
        # æ¸…ç†æ¨¡å‹
        if self.model:
            del self.model
            self.model = None
        
        # æ¸…ç†ç‹€æ…‹
        self.state.clear()
        self.audio_buffer = np.array([], dtype=np.float32)
        
        logger.info("âœ“ OpenWakeWord Operator æ¸…ç†å®Œæˆ")
    
    async def _load_model(self):
        """è¼‰å…¥ openWakeWord æ¨¡å‹"""
        try:
            # å‹•æ…‹å°å…¥ openwakewordï¼ˆé¿å…åœ¨æ²’æœ‰å®‰è£æ™‚å ±éŒ¯ï¼‰
            from openwakeword.model import Model
            from openwakeword.utils import download_models
        except ImportError:
            raise PipelineError("è«‹å®‰è£ openwakeword: pip install openwakeword")
        
        # ä¸‹è¼‰é è¨­æ¨¡å‹
        download_models()
        
        # æ±ºå®šæ¨¡å‹è·¯å¾‘
        model_path = self.model_path
        
        if not model_path:
            # å˜—è©¦å¾ HuggingFace ä¸‹è¼‰
            # å„ªå…ˆä½¿ç”¨é…ç½®ä¸­çš„ tokenï¼Œå¦å‰‡å¾ç’°å¢ƒè®Šæ•¸æˆ– HfFolder ç²å–
            hf_token = self.hf_token or os.environ.get("HF_TOKEN") or HfFolder.get_token()
            
            if hf_token and self.hf_repo_id and self.hf_filename:
                logger.info(f"å¾ HuggingFace ä¸‹è¼‰æ¨¡å‹: {self.hf_repo_id}/{self.hf_filename}")
                try:
                    model_path = hf_hub_download(
                        repo_id=self.hf_repo_id,
                        filename=self.hf_filename,
                        token=hf_token,
                        repo_type="model"
                    )
                    logger.info(f"âœ“ æ¨¡å‹ä¸‹è¼‰æˆåŠŸ: {model_path}")
                except Exception as e:
                    logger.error(f"æ¨¡å‹ä¸‹è¼‰å¤±æ•—: {e}")
                    raise PipelineError(f"ç„¡æ³•ä¸‹è¼‰æ¨¡å‹: {e}")
            else:
                raise PipelineError("è«‹è¨­å®šæ¨¡å‹è·¯å¾‘æˆ–æä¾› HF_TOKEN")
        
        # è¼‰å…¥æ¨¡å‹
        try:
            self.model = Model(
                wakeword_models=[model_path],
                inference_framework="onnx"
            )
            logger.info(f"âœ“ æ¨¡å‹è¼‰å…¥æˆåŠŸ: {model_path}")
        except Exception as e:
            logger.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise PipelineError(f"ç„¡æ³•è¼‰å…¥æ¨¡å‹: {e}")
    
    async def process(self, audio_data: bytes, **kwargs) -> Optional[bytes]:
        """
        è™•ç†éŸ³è¨Šè³‡æ–™ï¼Œåµæ¸¬å–šé†’è©
        
        Args:
            audio_data: è¼¸å…¥éŸ³è¨Šè³‡æ–™ï¼ˆbytesï¼‰
            **kwargs: é¡å¤–åƒæ•¸
                - sample_rate: è¼¸å…¥éŸ³è¨Šçš„æ¡æ¨£ç‡
                - session_id: æœƒè©± ID
            
        Returns:
            åŸå§‹éŸ³è¨Šè³‡æ–™ï¼ˆä¸ä¿®æ”¹ï¼‰
        """
        if not self.enabled or not self.model:
            return audio_data
        
        if not self.validate_audio_params(audio_data):
            return audio_data
        
        # ç²å–æ¡æ¨£ç‡
        input_sample_rate = kwargs.get("sample_rate", self.sample_rate)
        
        # è½‰æ›ç‚º numpy array
        audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32)
        
        # æ·»åŠ åˆ°ç·©è¡å€
        self.audio_buffer = np.concatenate([self.audio_buffer, audio_np])
        
        # é‡æ¡æ¨£åˆ° 16kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
        if input_sample_rate != self.sample_rate:
            # è¨ˆç®—éœ€è¦çš„æ¨£æœ¬æ•¸
            target_length = int(len(self.audio_buffer) * self.sample_rate / input_sample_rate)
            
            # å¦‚æœç·©è¡å€å¤ªå°ï¼Œç­‰å¾…æ›´å¤šè³‡æ–™
            if target_length < self.chunk_size:
                return audio_data
            
            # é‡æ¡æ¨£
            resampled = scipy.signal.resample(self.audio_buffer, target_length)
            self.audio_buffer = resampled
        
        # è™•ç†å®Œæ•´çš„ chunks
        detections = []
        while len(self.audio_buffer) >= self.chunk_size:
            # å–å‡ºä¸€å€‹ chunk
            chunk = self.audio_buffer[:self.chunk_size]
            self.audio_buffer = self.audio_buffer[self.chunk_size:]
            
            # æ¨è«–
            try:
                predictions = self.model.predict(chunk)
                
                # æ›´æ–°ç‹€æ…‹ä¸¦æª¢æŸ¥åµæ¸¬
                for model_name, score in predictions.items():
                    # æ›´æ–°è©•åˆ†ä½‡åˆ—
                    if len(self.state[model_name]) == 0:
                        # åˆå§‹åŒ–ç‚ºé›¶
                        self.state[model_name].extend(np.zeros(60))
                    
                    self.state[model_name].append(score)
                    
                    # æª¢æŸ¥æ˜¯å¦è¶…éé–¾å€¼
                    if score > self.threshold:
                        current_time = asyncio.get_event_loop().time()
                        
                        # æª¢æŸ¥å†·å»æœŸ
                        if current_time - self.last_detection_time > self.detection_cooldown:
                            self.last_detection_time = current_time
                            
                            detection = {
                                "model": model_name,
                                "score": float(score),
                                "timestamp": datetime.now().isoformat(),
                                "session_id": kwargs.get("session_id")
                            }
                            detections.append(detection)
                            
                            logger.info(
                                f"ğŸ¯ åµæ¸¬åˆ°å–šé†’è©ï¼æ¨¡å‹: {model_name}, "
                                f"åˆ†æ•¸: {score:.3f}"
                            )
                            
                            # å„ªå…ˆä½¿ç”¨ Store dispatchï¼Œå¦å‰‡ä½¿ç”¨å›å‘¼ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
                            if self.store:
                                # ç›´æ¥ dispatch wake_triggered action
                                from src.store.sessions.sessions_actions import wake_triggered
                                self.store.dispatch(wake_triggered(
                                    session_id=kwargs.get("session_id"),
                                    confidence=float(score),
                                    trigger=model_name
                                ))
                            elif self.detection_callback:
                                # ä¿ç•™å›å‘¼ä»‹é¢ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
                                await self._trigger_callback(detection)
            
            except Exception as e:
                logger.error(f"æ¨è«–éŒ¯èª¤: {e}")
        
        # å°‡åµæ¸¬çµæœå­˜å…¥ kwargsï¼ˆä¾›å¾ŒçºŒ operator ä½¿ç”¨ï¼‰
        if detections:
            kwargs["wake_word_detections"] = detections
        
        # è¿”å›åŸå§‹éŸ³è¨Šï¼ˆä¸ä¿®æ”¹ï¼‰
        return audio_data
    
    async def _trigger_callback(self, detection: Dict[str, Any]):
        """è§¸ç™¼åµæ¸¬å›å‘¼"""
        try:
            if asyncio.iscoroutinefunction(self.detection_callback):
                await self.detection_callback(detection)
            else:
                self.detection_callback(detection)
        except Exception as e:
            logger.error(f"å›å‘¼åŸ·è¡ŒéŒ¯èª¤: {e}")
    
    def set_detection_callback(self, callback):
        """
        è¨­å®šå–šé†’è©åµæ¸¬å›å‘¼å‡½æ•¸
        
        Args:
            callback: åµæ¸¬åˆ°å–šé†’è©æ™‚å‘¼å«çš„å‡½æ•¸
        """
        self.detection_callback = callback
    
    def get_scores(self, model_name: Optional[str] = None) -> Dict[str, List[float]]:
        """
        ç²å–è©•åˆ†æ­·å²
        
        Args:
            model_name: æ¨¡å‹åç¨±ï¼Œå¦‚æœä¸æŒ‡å®šå‰‡è¿”å›æ‰€æœ‰æ¨¡å‹
            
        Returns:
            è©•åˆ†æ­·å²å­—å…¸
        """
        if model_name:
            return {model_name: list(self.state.get(model_name, []))}
        else:
            return {name: list(scores) for name, scores in self.state.items()}
    
    def get_latest_score(self, model_name: Optional[str] = None) -> Optional[float]:
        """
        ç²å–æœ€æ–°è©•åˆ†
        
        Args:
            model_name: æ¨¡å‹åç¨±
            
        Returns:
            æœ€æ–°è©•åˆ†ï¼Œå¦‚æœæ²’æœ‰å‰‡è¿”å› None
        """
        if not model_name and self.state:
            # ä½¿ç”¨ç¬¬ä¸€å€‹æ¨¡å‹
            model_name = list(self.state.keys())[0]
        
        if model_name and model_name in self.state and self.state[model_name]:
            return self.state[model_name][-1]
        
        return None
    
    async def flush(self):
        """æ¸…ç©ºå…§éƒ¨ç·©è¡å€"""
        self.audio_buffer = np.array([], dtype=np.float32)
        for model_name in self.state:
            self.state[model_name].clear()
            self.state[model_name].extend(np.zeros(60))
        logger.debug("å·²æ¸…ç©ºéŸ³è¨Šç·©è¡å€å’Œè©•åˆ†ä½‡åˆ—")
    
    def update_config(self, config: Dict[str, Any]):
        """æ›´æ–°é…ç½®"""
        super().update_config(config)
        
        # æ›´æ–°ç‰¹å®šåƒæ•¸
        if "threshold" in config:
            self.threshold = config["threshold"]
            logger.info(f"æ›´æ–°åµæ¸¬é–¾å€¼: {self.threshold}")
        
        if "detection_cooldown" in config:
            self.detection_cooldown = config["detection_cooldown"]
            logger.info(f"æ›´æ–°å†·å»æœŸ: {self.detection_cooldown}ç§’")
    
    def get_info(self) -> Dict[str, Any]:
        """ç²å– Operator è³‡è¨Š"""
        info = super().get_info()
        info.update({
            "model_loaded": self.model is not None,
            "model_path": self.model_path,
            "threshold": self.threshold,
            "detection_cooldown": self.detection_cooldown,
            "buffer_size": len(self.audio_buffer),
            "models": list(self.state.keys()) if self.state else []
        })
        return info
    
    def get_required_audio_format(self) -> AudioMetadata:
        """
        ç²å– OpenWakeWord éœ€è¦çš„éŸ³é »æ ¼å¼
        
        OpenWakeWord æ¨¡å‹éœ€æ±‚ï¼š
        - æ¡æ¨£ç‡ï¼š16000 Hzï¼ˆæ¨¡å‹å›ºå®šéœ€æ±‚ï¼‰
        - è²é“æ•¸ï¼š1ï¼ˆæ¨¡å‹æ¶æ§‹é™åˆ¶ï¼‰
        - æ ¼å¼ï¼šfloat32ï¼ˆå…§éƒ¨è™•ç†ä½¿ç”¨ float32ï¼Œä½†å¯æ¥å— int16 è¼¸å…¥ï¼‰
        
        æ³¨æ„ï¼šé›–ç„¶é€™è£¡è²æ˜éœ€è¦ float32ï¼Œä½† process æ–¹æ³•æœƒè™•ç† int16 åˆ° float32 çš„è½‰æ›
        
        Returns:
            éœ€è¦çš„éŸ³é »æ ¼å¼
        """
        return AudioMetadata(
            sample_rate=self.config_manager.pipeline.default_sample_rate,  # å¾é…ç½®è®€å–
            channels=self.config_manager.pipeline.channels,               # å¾é…ç½®è®€å–
            format=AudioSampleFormat.INT16  # æ¥å— int16ï¼Œå…§éƒ¨æœƒè½‰æ›
        )
    
    def get_output_audio_format(self) -> Optional[AudioMetadata]:
        """
        OpenWakeWord ä¸æ”¹è®ŠéŸ³é »æ ¼å¼ï¼Œåªé€²è¡Œæª¢æ¸¬
        
        Returns:
            None è¡¨ç¤ºè¼¸å‡ºæ ¼å¼èˆ‡è¼¸å…¥ç›¸åŒ
        """
        return None
    
    async def process_from_queue(self, session_id: str):
        """
        å¾ AudioQueueManager è™•ç†éŸ³è¨Šï¼ˆä¸²æµæ¨¡å¼ï¼‰
        
        Args:
            session_id: Session ID
        """
        if not self.audio_queue_manager:
            logger.warning("WakeWordOperator: No AudioQueueManager configured")
            return
        
        logger.info(f"WakeWordOperator: Starting queue processing for session {session_id}")
        
        # ç¢ºä¿ä½‡åˆ—å­˜åœ¨
        if session_id not in self.audio_queue_manager.queues:
            await self.audio_queue_manager.create_queue(session_id)
        
        try:
            while self.enabled:
                try:
                    # å¾ä½‡åˆ—æ‹‰å–éŸ³è¨Š
                    audio_data = await self.audio_queue_manager.pull(session_id, timeout=0.1)
                    
                    if audio_data:
                        # å‰µå»ºå…ƒæ•¸æ“š
                        metadata = AudioMetadata(
                            sample_rate=self.sample_rate,
                            channels=1,
                            format=AudioSampleFormat.INT16
                        )
                        
                        # è™•ç†éŸ³è¨Šä¸¦åŸ·è¡Œå–šé†’è©æª¢æ¸¬
                        result = await self.process(audio_data, metadata=metadata)
                        
                        # çµæœå·²ç¶“åœ¨ process æ–¹æ³•ä¸­é€šé callback æˆ– Store dispatch è™•ç†
                    else:
                        # æ²’æœ‰éŸ³è¨Šæ™‚çŸ­æš«ç­‰å¾…
                        await asyncio.sleep(0.01)
                        
                except asyncio.TimeoutError:
                    # è¶…æ™‚æ˜¯æ­£å¸¸çš„ï¼Œç¹¼çºŒç­‰å¾…
                    continue
                except Exception as e:
                    logger.error(f"WakeWordOperator queue processing error: {e}")
                    break
                    
        finally:
            logger.info(f"WakeWordOperator: Stopped queue processing for session {session_id}")