#!/usr/bin/env python3
"""
DeepFilterNet - éŸ³è¨Šé™å™ªæœå‹™
ä½¿ç”¨ DeepFilterNet é€²è¡Œæ·±åº¦å­¸ç¿’éŸ³è¨Šé™å™ªè™•ç†

è¨­è¨ˆåŸå‰‡:
- KISS: Keep It Simple, Stupid - ç°¡å–®æœ‰æ•ˆçš„è¨­è¨ˆ
- ç„¡ç‹€æ…‹: æ‰€æœ‰æ–¹æ³•éƒ½æ˜¯ç´”å‡½æ•¸ï¼Œç„¡å…§éƒ¨ç‹€æ…‹ä¾è³´  
- å–®ä¸€è·è²¬: å°ˆé–€è² è²¬éŸ³è¨Šé™å™ªè™•ç†
- å–®ä¾‹æ¨¡å¼: å¯¦ç¾æ¨¡çµ„ç´šå–®ä¾‹
- ç›´æ¥èª¿ç”¨: å¯è¢« Effects ç›´æ¥èª¿ç”¨
"""

import numpy as np
from typing import Optional, Tuple, Union, Dict, Any, TYPE_CHECKING
from threading import Lock
import warnings

from src.config.manager import ConfigManager
from src.utils.logger import logger
from src.utils.singleton import SingletonMixin

# è®“ torch è®Šç‚ºå¯é¸ä¾è³´
try:
    import torch
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False
    logger.warning("PyTorch not installed. DeepFilterNet will not be available.")

# ç”¨æ–¼é¡å‹æç¤º
if TYPE_CHECKING:
    import torch


class DeepFilterNetDenoiser(SingletonMixin):
    """
    DeepFilterNet é™å™ªå™¨ - åŸºæ–¼ DeepFilterNet çš„æ·±åº¦å­¸ç¿’é™å™ª
    
    ç‰¹è‰²:
    - ğŸ§  æ™ºæ…§é™å™ª - auto_denoise() è‡ªå‹•åˆ†æéŸ³è¨Šä¸¦æ±ºå®šé™å™ªå¼·åº¦
    - ğŸ¯ ç²¾æº–æ§åˆ¶ - denoise() æä¾›ç²¾ç¢ºçš„é™å™ªå¼·åº¦æ§åˆ¶
    - âš¡ é«˜æ•ˆèƒ½ - åŸºæ–¼ DeepFilterNet çš„æœ€æ–°æ·±åº¦å­¸ç¿’æŠ€è¡“
    - ğŸ”§ éˆæ´»é…ç½® - æ”¯æ´å¤šç¨®é™å™ªæ¨¡å¼å’Œåƒæ•¸èª¿æ•´
    - ğŸ“Š è©³ç´°å ±å‘Š - æä¾›é™å™ªè™•ç†çš„è©³ç´°åˆ†æå ±å‘Š
    """
    
    _init_lock = Lock()
    
    def _get_device(self, requested_device: str = 'auto') -> str:
        """
        ç²å–æœ€ä½³å¯ç”¨è¨­å‚™
        
        åƒè€ƒ DeepFilterNet utils.py:20-29
        
        Args:
            requested_device: è«‹æ±‚çš„è¨­å‚™ ('auto', 'cuda', 'cpu')
            
        Returns:
            è¨­å‚™å­—ç¬¦ä¸² ('cuda' æˆ– 'cpu')
        """
        if not HAS_TORCH:
            return 'cpu'
            
        # æ ¹æ“šé…ç½®æ±ºå®šè¨­å‚™
        if requested_device == 'cpu':
            return 'cpu'
        elif requested_device == 'cuda':
            if torch.cuda.is_available():
                return 'cuda'
            else:
                logger.warning("è«‹æ±‚ä½¿ç”¨ CUDA ä½†ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU")
                return 'cpu'
        else:  # auto
            if torch.cuda.is_available():
                logger.debug(f"è‡ªå‹•é¸æ“‡ CUDA è¨­å‚™: {torch.cuda.get_device_name(0)}")
                return 'cuda'
            else:
                logger.debug("è‡ªå‹•é¸æ“‡ CPU è¨­å‚™")
                return 'cpu'
    
    def __init__(self):
        if hasattr(self, '_initialized'):
            return
            
        with self._init_lock:
            if hasattr(self, '_initialized'):
                return
                
            self._initialized = True
            self._model = None
            self._df_state = None
            self.internal_sample_rate = 48000  # DeepFilterNet å…§éƒ¨è™•ç†æ¡æ¨£ç‡
            self.supports_16khz_io = True  # æ”¯æ´ 16kHz è¼¸å…¥/è¼¸å‡ºï¼Œå…§éƒ¨è‡ªå‹•è½‰æ›
            self._model_initialized = False
            
            # è¼‰å…¥é…ç½®
            self._load_config()
            
            # åˆå§‹åŒ– DeepFilterNet æ¨¡å‹ (å»¶é²åˆå§‹åŒ–)
            if self.enabled and self.auto_init and HAS_TORCH:
                try:
                    self._initialize_model()
                except Exception as e:
                    logger.warning(f"ğŸ”§ DeepFilterNet æ¨¡å‹åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡åœ¨é¦–æ¬¡ä½¿ç”¨æ™‚é‡è©¦: {e}")
            elif self.enabled and not HAS_TORCH:
                logger.warning("âš ï¸ DeepFilterNet éœ€è¦ PyTorchï¼Œä½† PyTorch æœªå®‰è£ã€‚é™å™ªåŠŸèƒ½å°‡è¢«åœç”¨ã€‚")
                self.enabled = False
                    
            logger.info("ğŸ”‡ DeepFilterNet æœå‹™åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self):
        """è¼‰å…¥é™å™ªæœå‹™é…ç½®"""
        config = ConfigManager()
        denoiser_config = config.services.denoiser
        
        self.enabled = denoiser_config.enabled
        self.type = denoiser_config.type
        self.strength = denoiser_config.strength
        
        # æ“´å±•é…ç½®ä»¥æ”¯æ´ DeepFilterNet
        if hasattr(denoiser_config, 'deepfilternet'):
            dfn_config = denoiser_config.deepfilternet
            self.model_base_dir = dfn_config.model_base_dir if hasattr(dfn_config, 'model_base_dir') else "DeepFilterNet3"
            self.post_filter = dfn_config.post_filter if hasattr(dfn_config, 'post_filter') else True
            self.auto_init = dfn_config.auto_init if hasattr(dfn_config, 'auto_init') else True
            self.device = dfn_config.device if hasattr(dfn_config, 'device') else 'auto'  # auto, cpu, cuda
            self.chunk_size = dfn_config.chunk_size if hasattr(dfn_config, 'chunk_size') else 16000  # 1ç§’éŸ³è¨Šå¡Š
        else:
            # é è¨­é…ç½®
            self.model_base_dir = "DeepFilterNet3"
            self.post_filter = True
            self.auto_init = True
            self.device = 'auto'
            self.chunk_size = 16000
            
        # ä½¿ç”¨æ”¹é€²çš„è¨­å‚™é¸æ“‡é‚è¼¯
        # ä¿å­˜åŸå§‹é…ç½®å€¼
        requested_device = self.device
        # ç²å–å¯¦éš›ä½¿ç”¨çš„è¨­å‚™
        self.device = self._get_device(requested_device)
            
        logger.debug(f"DeepFilterNet é…ç½®è¼‰å…¥: enabled={self.enabled}, type={self.type}, device={self.device}")
    
    def _initialize_model(self):
        """åˆå§‹åŒ– DeepFilterNet æ¨¡å‹"""
        if self._model_initialized:
            return
        
        if not HAS_TORCH:
            logger.warning("Cannot initialize DeepFilterNet model: PyTorch not installed")
            self.enabled = False
            return
            
        try:
            # å‹•æ…‹å°å…¥ DeepFilterNet (é¿å…åœ¨æœªå®‰è£æ™‚å‡ºéŒ¯)
            from df.enhance import init_df
            
            logger.info(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– DeepFilterNet æ¨¡å‹: {self.model_base_dir}")
            
            # åˆå§‹åŒ–æ¨¡å‹
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")  # æŠ‘åˆ¶ DeepFilterNet çš„è­¦å‘Š
                
                # init_df è¿”å› 3 å€‹å€¼ï¼šmodel, df_state, sample_rate
                self._model, self._df_state, self._sr = init_df(
                    model_base_dir=self.model_base_dir,
                    post_filter=self.post_filter,
                    log_level="WARNING"
                )
            
            # è¨­å®šè¨­å‚™
            if self.device == 'cuda' and torch.cuda.is_available():
                self._model = self._model.cuda()
                logger.info("ğŸš€ DeepFilterNet æ¨¡å‹å·²è¼‰å…¥åˆ° GPU")
            else:
                self._model = self._model.cpu()
                logger.info("ğŸ’» DeepFilterNet æ¨¡å‹å·²è¼‰å…¥åˆ° CPU")
                
            self._model_initialized = True
            logger.info("âœ… DeepFilterNet æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except ImportError:
            raise ImportError(
                "DeepFilterNet æœªå®‰è£ã€‚è«‹ä½¿ç”¨ 'pip install deepfilternet' å®‰è£"
            )
        except Exception as e:
            logger.error(f"âŒ DeepFilterNet æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    def _ensure_model_ready(self):
        """ç¢ºä¿æ¨¡å‹å·²æº–å‚™å°±ç·’"""
        if not self.enabled:
            raise RuntimeError("DeepFilterNet æœªå•Ÿç”¨")
            
        if not self._model_initialized:
            self._initialize_model()
    
    def denoise(self, audio_data: Union[bytes, np.ndarray], 
               strength: Optional[float] = None,
               sample_rate: int = 16000) -> Union[bytes, np.ndarray]:
        """
        éŸ³è¨Šé™å™ªè™•ç†
        
        Args:
            audio_data: éŸ³è¨Šè³‡æ–™ (bytes æˆ– numpy array)
            strength: é™å™ªå¼·åº¦ (0.0-1.0)ï¼ŒNone å‰‡ä½¿ç”¨é…ç½®å€¼
            sample_rate: å–æ¨£ç‡ï¼Œé è¨­ 16kHz
            
        Returns:
            é™å™ªå¾Œçš„éŸ³è¨Šè³‡æ–™ï¼Œèˆ‡è¼¸å…¥æ ¼å¼ç›¸åŒ
            
        Raises:
            RuntimeError: ç•¶æœå‹™æœªå•Ÿç”¨æˆ–æ¨¡å‹åˆå§‹åŒ–å¤±æ•—æ™‚
            ValueError: ç•¶éŸ³è¨Šè³‡æ–™æ ¼å¼ä¸æ­£ç¢ºæ™‚
        """
        self._ensure_model_ready()
        
        # è™•ç†è¼¸å…¥æ ¼å¼
        input_is_bytes = isinstance(audio_data, bytes)
        if input_is_bytes:
            audio = self._bytes_to_audio(audio_data)
        else:
            audio = audio_data.astype(np.float32)
            
        # é©—è­‰éŸ³è¨Šæ ¼å¼
        if audio.ndim != 1:
            raise ValueError("ç›®å‰åªæ”¯æ´å–®è²é“éŸ³è¨Š")
            
        if len(audio) == 0:
            logger.warning("æ”¶åˆ°ç©ºçš„éŸ³è¨Šè³‡æ–™")
            return audio_data
            
        # ä½¿ç”¨æŒ‡å®šå¼·åº¦æˆ–é…ç½®å€¼
        if strength is None:
            strength = self.strength
        strength = max(0.0, min(1.0, strength))  # é™åˆ¶åœ¨ 0-1 ç¯„åœ
        
        try:
            # ä½¿ç”¨ DeepFilterNet è™•ç† (è‡ªå‹•è™•ç†æ¡æ¨£ç‡è½‰æ›)
            enhanced_audio = self._process_with_deepfilternet(audio, strength, sample_rate)
            
            # è¿”å›ç›¸åŒæ ¼å¼
            if input_is_bytes:
                return self._audio_to_bytes(enhanced_audio)
            else:
                return enhanced_audio
                
        except Exception as e:
            logger.error(f"âŒ é™å™ªè™•ç†å¤±æ•—: {e}")
            # é™å™ªå¤±æ•—æ™‚è¿”å›åŸå§‹éŸ³è¨Š
            return audio_data
    
    def auto_denoise(self, audio_data: Union[bytes, np.ndarray],
                    purpose: str = "asr",
                    sample_rate: int = 16000) -> Tuple[Union[bytes, np.ndarray], Dict[str, Any]]:
        """
        æ™ºæ…§éŸ³è¨Šé™å™ª - è‡ªå‹•åˆ†æéŸ³è¨Šä¸¦æ±ºå®šæœ€ä½³é™å™ªç­–ç•¥
        
        Args:
            audio_data: éŸ³è¨Šè³‡æ–™ (bytes æˆ– numpy array)
            purpose: ç”¨é€” ("asr", "vad", "wakeword", "recording", "general")
            sample_rate: å–æ¨£ç‡ï¼Œé è¨­ 16kHz
            
        Returns:
            Tuple[è™•ç†å¾ŒéŸ³è¨Š, åˆ†æå ±å‘Š]
            
        åˆ†æå ±å‘ŠåŒ…å«:
        - purpose: è™•ç†ç”¨é€”
        - analysis: éŸ³è¨Šåˆ†æçµæœ
        - decisions: é™å™ªæ±ºç­–
        - applied_steps: åŸ·è¡Œçš„è™•ç†æ­¥é©Ÿ
        - performance: æ•ˆèƒ½æŒ‡æ¨™
        """
        self._ensure_model_ready()
        
        # è™•ç†è¼¸å…¥æ ¼å¼
        input_is_bytes = isinstance(audio_data, bytes)
        if input_is_bytes:
            audio = self._bytes_to_audio(audio_data)
        else:
            audio = audio_data.astype(np.float32)
            
        # é©—è­‰éŸ³è¨Šæ ¼å¼
        if len(audio) == 0:
            return audio_data, self._empty_report(purpose)
            
        import time
        start_time = time.time()
        
        try:
            # 1. éŸ³è¨Šåˆ†æ
            analysis = self._analyze_audio(audio)
            
            # 2. æ±ºå®šè™•ç†ç­–ç•¥
            decisions = self._determine_denoise_strategy(analysis, purpose)
            
            # 3. åŸ·è¡Œé™å™ªè™•ç†
            processed_audio, applied_steps = self._execute_denoise_pipeline(
                audio, decisions, sample_rate
            )
            
            # 4. æ€§èƒ½çµ±è¨ˆ
            processing_time = (time.time() - start_time) * 1000  # æ¯«ç§’
            
            # 5. ç”Ÿæˆå ±å‘Š
            report = {
                'purpose': purpose,
                'analysis': {
                    'snr_estimate': f"{analysis['snr_db']:.1f} dB",
                    'noise_level': analysis['noise_level'],
                    'spectral_centroid': f"{analysis['spectral_centroid']:.0f} Hz",
                    'zero_crossing_rate': f"{analysis['zcr']:.3f}",
                    'rms_energy': f"{analysis['rms']:.4f}",
                    'needs_denoising': analysis['needs_denoising']
                },
                'decisions': decisions,
                'applied_steps': applied_steps,
                'performance': {
                    'processing_time_ms': f"{processing_time:.2f}",
                    'enhancement_strength': decisions.get('strength', 0.0),
                    'snr_improvement': f"{analysis.get('expected_snr_gain', 0):.1f} dB"
                }
            }
            
            # è¿”å›çµæœ
            result = self._audio_to_bytes(processed_audio) if input_is_bytes else processed_audio
            return result, report
            
        except Exception as e:
            logger.error(f"âŒ æ™ºæ…§é™å™ªè™•ç†å¤±æ•—: {e}")
            return audio_data, self._error_report(purpose, str(e))
    
    def _as_numpy(self, tensor) -> np.ndarray:
        """å®‰å…¨åœ°å°‡ PyTorch tensor è½‰æ›ç‚º numpy array
        
        æ ¹æ“š DeepFilterNet å®˜æ–¹å¯¦ç¾ï¼Œä½¿ç”¨ cpu().detach().numpy() åºåˆ—
        åƒè€ƒ: evaluation_utils.py:622-625
        
        Args:
            tensor: PyTorch tensor æˆ– numpy array
            
        Returns:
            numpy array
        """
        if HAS_TORCH and torch is not None:
            if isinstance(tensor, torch.Tensor):
                # æ ¹æ“š DeepFilterNet å®˜æ–¹: å…ˆ cpu() å† detach() æœ€å¾Œ numpy()
                return tensor.cpu().detach().numpy()
        return tensor
    
    def _process_with_deepfilternet(self, audio: np.ndarray, strength: float, 
                                  input_sample_rate: int = 16000) -> np.ndarray:
        """ä½¿ç”¨ DeepFilterNet è™•ç†éŸ³è¨Š
        
        Args:
            audio: è¼¸å…¥éŸ³è¨Š (16kHz)
            strength: é™å™ªå¼·åº¦ (0.0-1.0)
            input_sample_rate: è¼¸å…¥æ¡æ¨£ç‡ï¼Œé è¨­ 16kHz
            
        Returns:
            è™•ç†å¾Œçš„éŸ³è¨Šï¼Œä¿æŒèˆ‡è¼¸å…¥ç›¸åŒçš„æ¡æ¨£ç‡
        """
        try:
            from df.enhance import enhance
            from df.io import resample
            
            # è½‰æ›ç‚º PyTorch å¼µé‡
            audio_tensor = torch.from_numpy(audio).unsqueeze(0)  # åŠ å…¥ batch ç¶­åº¦
            
            # === 1. ä¸Šæ¡æ¨£åˆ° 48kHz (å¦‚æœéœ€è¦) ===
            if input_sample_rate != self.internal_sample_rate:
                logger.debug(f"ä¸Šæ¡æ¨£éŸ³è¨Š: {input_sample_rate}Hz â†’ {self.internal_sample_rate}Hz")
                # ä½¿ç”¨æ–°çš„é‡æ¡æ¨£æ–¹æ³•é¿å…æ£„ç”¨è­¦å‘Š
                audio_tensor = resample(
                    audio_tensor, 
                    orig_sr=input_sample_rate, 
                    new_sr=self.internal_sample_rate,
                    method="sinc_fast"  # ä½¿ç”¨ sinc_fast ä»¥ç²å¾—æœ€ä½³çš„é€Ÿåº¦èˆ‡å“è³ªå¹³è¡¡
                )
            
            # if self.device == 'cuda':
            #     audio_tensor = audio_tensor.cuda()
                
            # === 2. DeepFilterNet å¢å¼·è™•ç† (48kHz) ===
            with torch.no_grad():
                enhanced_tensor = enhance(self._model, self._df_state, audio_tensor, pad=True)
            
            # ç¢ºä¿ enhanced_tensor åœ¨ CPU ä¸Šï¼ˆenhance å¯èƒ½è¿”å› CUDA tensorï¼‰
            # ä½¿ç”¨ isinstance æª¢æŸ¥æ›´å¯é 
            if torch is not None and isinstance(enhanced_tensor, torch.Tensor):
                if enhanced_tensor.is_cuda:
                    enhanced_tensor = enhanced_tensor.cpu()
                
            # === 3. ä¸‹æ¡æ¨£å›åŸå§‹æ¡æ¨£ç‡ (å¦‚æœéœ€è¦) ===
            if input_sample_rate != self.internal_sample_rate:
                logger.debug(f"ä¸‹æ¡æ¨£éŸ³è¨Š: {self.internal_sample_rate}Hz â†’ {input_sample_rate}Hz")
                enhanced_tensor = resample(
                    enhanced_tensor, 
                    orig_sr=self.internal_sample_rate, 
                    new_sr=input_sample_rate,
                    method="sinc_fast"  # ä½¿ç”¨ sinc_fast ä»¥ç²å¾—æœ€ä½³çš„é€Ÿåº¦èˆ‡å“è³ªå¹³è¡¡
                )
                
                # resample å¾Œå¯èƒ½åˆè¿”å› CUDA tensorï¼Œéœ€è¦å†æ¬¡æª¢æŸ¥
                if torch is not None and isinstance(enhanced_tensor, torch.Tensor):
                    if enhanced_tensor.is_cuda:
                        enhanced_tensor = enhanced_tensor.cpu()
            
            # è½‰æ›å› numpy (ä½¿ç”¨ _as_numpy utility function)
            # é€™æœƒè‡ªå‹•è™•ç†ä»»ä½•å‰©é¤˜çš„ CUDA tensors å’Œè¨ˆç®—åœ–åˆ†é›¢
            enhanced_audio = self._as_numpy(enhanced_tensor).squeeze(0)
            
            # æ ¹æ“šå¼·åº¦æ··åˆåŸå§‹å’Œé™å™ªéŸ³è¨Š
            if strength < 1.0:
                enhanced_audio = audio * (1 - strength) + enhanced_audio * strength
                
            return enhanced_audio.astype(np.float32)
            
        except RuntimeError as e:
            # ç‰¹åˆ¥è™•ç† CUDA ç›¸é—œéŒ¯èª¤
            if "cuda" in str(e).lower() or "gpu" in str(e).lower():
                logger.error(f"DeepFilterNet CUDA éŒ¯èª¤: {e}")
                logger.info("å˜—è©¦å›é€€åˆ° CPU è™•ç†...")
                # å¯ä»¥åœ¨é€™è£¡å¯¦ç¾ CPU å›é€€é‚è¼¯
            else:
                logger.error(f"DeepFilterNet é‹è¡Œæ™‚éŒ¯èª¤: {e}")
            return audio
        except Exception as e:
            logger.error(f"DeepFilterNet è™•ç†å¤±æ•—: {e}")
            import traceback
            logger.debug(f"éŒ¯èª¤è¿½è¹¤:\n{traceback.format_exc()}")
            return audio
    
    def _analyze_audio(self, audio: np.ndarray) -> Dict[str, Any]:
        """åˆ†æéŸ³è¨Šç‰¹å¾µï¼Œåˆ¤æ–·é™å™ªéœ€æ±‚"""
        # è¨ˆç®—åŸºæœ¬éŸ³è¨Šç‰¹å¾µ
        rms = np.sqrt(np.mean(audio ** 2))
        
        # ä¼°ç®— SNR (ç°¡åŒ–ç‰ˆæœ¬)
        # ä½¿ç”¨å‰ 10% ä½œç‚ºå™ªéŸ³åŸºç·šä¼°ç®—
        noise_segment = audio[:len(audio)//10]
        noise_rms = np.sqrt(np.mean(noise_segment ** 2))
        signal_rms = rms
        
        if noise_rms > 0:
            snr_db = 20 * np.log10(signal_rms / noise_rms)
        else:
            snr_db = 60.0  # å‡è¨­é«˜ SNR
            
        # å™ªéŸ³ç­‰ç´šè©•ä¼°
        if snr_db > 20:
            noise_level = "low"
        elif snr_db > 10:
            noise_level = "medium"
        else:
            noise_level = "high"
            
        # é »è­œé‡å¿ƒ (ç°¡åŒ–è¨ˆç®—)
        fft = np.abs(np.fft.rfft(audio))
        freqs = np.linspace(0, 8000, len(fft))  # 16kHz æ¡æ¨£ç‡ï¼Œå¥ˆå¥æ–¯ç‰¹é »ç‡ 8kHz
        spectral_centroid = np.sum(freqs * fft) / (np.sum(fft) + 1e-10)
        
        # éé›¶ç‡
        zero_crossings = np.where(np.diff(np.signbit(audio)))[0]
        zcr = len(zero_crossings) / len(audio)
        
        # åˆ¤æ–·æ˜¯å¦éœ€è¦é™å™ª
        needs_denoising = snr_db < 15.0 or noise_level in ["medium", "high"]
        
        return {
            'rms': rms,
            'snr_db': snr_db,
            'noise_level': noise_level,
            'spectral_centroid': spectral_centroid,
            'zcr': zcr,
            'needs_denoising': needs_denoising,
            'expected_snr_gain': min(10.0, max(0.0, 20.0 - snr_db))  # é æœŸ SNR æ”¹å–„
        }
    
    def _determine_denoise_strategy(self, analysis: Dict[str, Any], purpose: str) -> Dict[str, Any]:
        """æ ¹æ“šåˆ†æçµæœå’Œç”¨é€”æ±ºå®šé™å™ªç­–ç•¥"""
        decisions = {
            'apply_denoising': False,
            'strength': 0.0,
            'aggressive': False,
            'preserve_quality': True
        }
        
        if not analysis['needs_denoising']:
            return decisions
            
        # æ ¹æ“šç”¨é€”èª¿æ•´ç­–ç•¥
        if purpose == "asr":
            # ASR éœ€è¦æœ€ä¹¾æ·¨çš„éŸ³è¨Š
            if analysis['noise_level'] == "high":
                decisions.update({
                    'apply_denoising': True,
                    'strength': min(0.8, self.strength + 0.2),
                    'aggressive': True,
                    'preserve_quality': False
                })
            elif analysis['noise_level'] == "medium":
                decisions.update({
                    'apply_denoising': True,
                    'strength': self.strength,
                    'aggressive': False,
                    'preserve_quality': True
                })
                
        elif purpose in ["vad", "wakeword"]:
            # VAD å’Œ WakeWord éœ€è¦ä¿æŒç‰¹å¾µ
            if analysis['noise_level'] == "high":
                decisions.update({
                    'apply_denoising': True,
                    'strength': max(0.3, self.strength - 0.2),
                    'aggressive': False,
                    'preserve_quality': True
                })
                
        elif purpose == "recording":
            # éŒ„éŸ³ä¿æŒæœ€å°‘è™•ç†
            if analysis['noise_level'] == "high":
                decisions.update({
                    'apply_denoising': True,
                    'strength': max(0.2, self.strength - 0.3),
                    'aggressive': False,
                    'preserve_quality': True
                })
                
        else:  # general
            # ä¸€èˆ¬ç”¨é€”å¹³è¡¡è™•ç†
            if analysis['needs_denoising']:
                decisions.update({
                    'apply_denoising': True,
                    'strength': self.strength,
                    'aggressive': analysis['noise_level'] == "high",
                    'preserve_quality': True
                })
                
        return decisions
    
    def _execute_denoise_pipeline(self, audio: np.ndarray, decisions: Dict[str, Any], 
                                 sample_rate: int = 16000) -> Tuple[np.ndarray, list]:
        """åŸ·è¡Œé™å™ªè™•ç†ç®¡ç·š
        
        Args:
            audio: è¼¸å…¥éŸ³è¨Š
            decisions: é™å™ªæ±ºç­–
            sample_rate: æ¡æ¨£ç‡
            
        Returns:
            Tuple[è™•ç†å¾ŒéŸ³è¨Š, æ‡‰ç”¨æ­¥é©Ÿåˆ—è¡¨]
        """
        applied_steps = []
        processed_audio = audio.copy()
        
        if decisions['apply_denoising']:
            # ä½¿ç”¨ DeepFilterNet é™å™ª (è‡ªå‹•è™•ç†æ¡æ¨£ç‡è½‰æ›)
            processed_audio = self._process_with_deepfilternet(
                processed_audio, decisions['strength'], sample_rate
            )
            applied_steps.append(
                f"DeepFilterNet é™å™ª (å¼·åº¦: {decisions['strength']:.2f}, "
                f"{sample_rate}Hzâ†’{self.internal_sample_rate}Hzâ†’{sample_rate}Hz)"
            )
            
            # å¦‚æœéœ€è¦ç©æ¥µè™•ç†ï¼Œå¯ä»¥åŠ å…¥é¡å¤–çš„å¾Œè™•ç†
            if decisions['aggressive']:
                applied_steps.append("ç©æ¥µé™å™ªæ¨¡å¼")
                
        if not applied_steps:
            applied_steps.append("ç„¡éœ€é™å™ªè™•ç†")
            
        return processed_audio, applied_steps
    
    def _bytes_to_audio(self, audio_bytes: bytes) -> np.ndarray:
        """å°‡ bytes è½‰æ›ç‚º float32 éŸ³è¨Šé™£åˆ—"""
        return np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
    
    def _audio_to_bytes(self, audio: np.ndarray) -> bytes:
        """å°‡ float32 éŸ³è¨Šé™£åˆ—è½‰æ›ç‚º bytes"""
        return (np.clip(audio, -1.0, 1.0) * 32768).astype(np.int16).tobytes()
    
    def _empty_report(self, purpose: str) -> Dict[str, Any]:
        """ç”Ÿæˆç©ºéŸ³è¨Šçš„å ±å‘Š"""
        return {
            'purpose': purpose,
            'analysis': {'error': 'ç©ºéŸ³è¨Šè³‡æ–™'},
            'decisions': {'apply_denoising': False},
            'applied_steps': [],
            'performance': {'processing_time_ms': '0.00'}
        }
    
    def _error_report(self, purpose: str, error: str) -> Dict[str, Any]:
        """ç”ŸæˆéŒ¯èª¤å ±å‘Š"""
        return {
            'purpose': purpose,
            'analysis': {'error': error},
            'decisions': {'apply_denoising': False},
            'applied_steps': [],
            'performance': {'processing_time_ms': '0.00'}
        }
    
    @property
    def is_available(self) -> bool:
        """æª¢æŸ¥æœå‹™æ˜¯å¦å¯ç”¨"""
        if not self.enabled:
            return False
            
        try:
            self._ensure_model_ready()
            return True
        except Exception:
            return False
    
    @property
    def model_info(self) -> Dict[str, Any]:
        """ç²å–æ¨¡å‹è³‡è¨Š"""
        if not self._model_initialized:
            return {'status': 'not_initialized'}
            
        return {
            'status': 'ready',
            'model_type': self.model_base_dir,
            'device': self.device,
            'post_filter': self.post_filter,
            'default_strength': self.strength
        }


# æ¨¡çµ„ç´šå–®ä¾‹å¯¦ä¾‹
deepfilternet_denoiser = DeepFilterNetDenoiser()

__all__ = ['DeepFilterNetDenoiser', 'deepfilternet_denoiser']