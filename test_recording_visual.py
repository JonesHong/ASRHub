#!/usr/bin/env python3
"""
è¦–è¦ºåŒ–éŒ„éŸ³åŠŸèƒ½æ¸¬è©¦
å°ˆæ³¨æ¸¬è©¦ RecordingOperator ä¸¦é¡¯ç¤ºå³æ™‚è²æ³¢åœ–
"""

import asyncio
import sys
import os
import time
import numpy as np
import pyaudio
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from pathlib import Path

# è¨­ç½® matplotlib æ”¯æŒä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Noto Sans CJK TC', 'WenQuanYi Micro Hei', 'Microsoft YaHei', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False
from collections import deque
from typing import Optional

# æ·»åŠ  src åˆ°è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.pipeline.operators.recording import RecordingOperator
from src.utils.logger import logger
from src.pipeline.operators.audio_format.scipy_operator import ScipyAudioFormatOperator
from src.models.audio_format import AudioMetadata, AudioFormat



class RecordingVisualTester:
    """è¦–è¦ºåŒ–éŒ„éŸ³æ¸¬è©¦å™¨"""
    
    def __init__(self):
        # RecordingOperator æœƒå¾ ConfigManager è®€å–é…ç½®
        self.recording_operator = None
        
        # éŸ³è¨Šæ ¼å¼è½‰æ›å™¨
        # Recording éœ€è¦çš„æ ¼å¼
        self.recording_format = AudioMetadata(
            sample_rate=16000,
            channels=1,
            format=AudioFormat.INT16
        )
        self.format_converter = None  # å°‡åœ¨ setup ä¸­åˆå§‹åŒ–
        
        # PyAudio
        self.p = pyaudio.PyAudio()
        
        # æª¢æ¸¬é è¨­è¨­å‚™çš„æ¡æ¨£ç‡
        try:
            device_info = self.p.get_default_input_device_info()
            self.device_sample_rate = int(device_info['defaultSampleRate'])
            logger.info(f"é è¨­éº¥å…‹é¢¨æ¡æ¨£ç‡: {self.device_sample_rate} Hz")
        except:
            self.device_sample_rate = 16000
            logger.warning("ç„¡æ³•ç²å–è¨­å‚™è³‡è¨Šï¼Œå‡è¨­æ¡æ¨£ç‡ç‚º 16000 Hz")
            
        # éŸ³è¨Šåƒæ•¸
        self.target_sample_rate = 16000  # RecordingOperator æœŸæœ›çš„æ¡æ¨£ç‡
        self.channels = 1
        self.chunk_size = 1024
        self.format = pyaudio.paInt16
        
        # è¨ˆç®—éº¥å…‹é¢¨çš„ chunk å¤§å°ï¼ˆè€ƒæ…®æ¡æ¨£ç‡å·®ç•°ï¼‰
        self.mic_chunk_size = int(self.chunk_size * self.device_sample_rate / self.target_sample_rate)
        logger.info(f"éŸ³è¨Šåƒæ•¸: Recording chunk_size={self.chunk_size}, éº¥å…‹é¢¨ chunk_size={self.mic_chunk_size}")
        
        # éŸ³è¨Šæµ
        self.stream = None
        self.is_recording = False
        
        # è¦–è¦ºåŒ–ç›¸é—œ
        self.fig = None
        self.ax_waveform = None
        self.ax_volume = None
        self.line_waveform = None
        self.line_volume = None
        self.bar_volume = None
        
        # è³‡æ–™ç·©è¡
        self.waveform_buffer = deque(maxlen=int(self.target_sample_rate * 2))  # 2ç§’çš„æ³¢å½¢
        self.volume_history = deque(maxlen=100)  # éŸ³é‡æ­·å²
        self.time_history = deque(maxlen=100)
        
    async def setup(self):
        """è¨­å®šæ¸¬è©¦ç’°å¢ƒ"""
        logger.info("è¨­å®šéŒ„éŸ³æ¸¬è©¦ç’°å¢ƒ...")
        
        # å‰µå»ºæ¸¬è©¦ç›®éŒ„
        Path('test_recordings').mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æ ¼å¼è½‰æ›å™¨ï¼ˆå¦‚æœéœ€è¦é‡æ¡æ¨£ï¼‰
        if self.device_sample_rate != self.target_sample_rate:
            # è¨­å‚™éŸ³è¨Šæ ¼å¼
            self.device_format = AudioMetadata(
                sample_rate=self.device_sample_rate,
                channels=self.channels,
                format=AudioFormat.INT16
            )
            self.format_converter = ScipyAudioFormatOperator(
                operator_id='recording_converter',
                target_metadata=self.recording_format
            )
            await self.format_converter.start()
            logger.info(f"éŸ³è¨Šæ ¼å¼è½‰æ›å™¨å·²åˆå§‹åŒ–: {self.device_sample_rate}Hz -> {self.target_sample_rate}Hz")
        
        # åˆå§‹åŒ– RecordingOperator
        self.recording_operator = RecordingOperator()
        
        # å¼·åˆ¶è¨­å®šç‚ºæª”æ¡ˆå„²å­˜æ¨¡å¼ï¼ˆæ¸¬è©¦ç”¨ï¼‰
        self.recording_operator.storage_type = 'file'
        self.recording_operator.storage_path = Path('test_recordings')
        
        await self.recording_operator.start()  # ä½¿ç”¨ start() è€Œä¸æ˜¯ initialize()
        
        logger.info("âœ“ æ¸¬è©¦ç’°å¢ƒè¨­å®šå®Œæˆ")
    
    async def cleanup(self):
        """æ¸…ç†æ¸¬è©¦ç’°å¢ƒ"""
        logger.info("æ¸…ç†æ¸¬è©¦ç’°å¢ƒ...")
        
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        
        if self.recording_operator:
            await self.recording_operator.stop()  # ä½¿ç”¨ stop() è€Œä¸æ˜¯ cleanup()
        
        if self.format_converter:
            await self.format_converter.stop()
        
        self.p.terminate()
        
        logger.info("âœ“ æ¸¬è©¦ç’°å¢ƒæ¸…ç†å®Œæˆ")
    
    def setup_visualization(self):
        """è¨­å®šè¦–è¦ºåŒ–åœ–è¡¨"""
        # è¨­å®šåœ–è¡¨æ¨£å¼
        plt.style.use('dark_background')
        
        # å‰µå»ºåœ–è¡¨
        self.fig, (self.ax_waveform, self.ax_volume) = plt.subplots(
            2, 1, 
            figsize=(12, 8),
            gridspec_kw={'height_ratios': [3, 1]}
        )
        
        # è¨­å®šæ³¢å½¢åœ–
        self.ax_waveform.set_title('Real-time Audio Waveform', fontsize=16, pad=10)
        self.ax_waveform.set_xlabel('Time (seconds)')
        self.ax_waveform.set_ylabel('Amplitude')
        self.ax_waveform.set_ylim(-32768, 32767)
        self.ax_waveform.grid(True, alpha=0.3)
        
        # åˆå§‹åŒ–æ³¢å½¢ç·š
        x_data = np.linspace(0, 2, len(self.waveform_buffer)) if self.waveform_buffer else [0]
        y_data = list(self.waveform_buffer) if self.waveform_buffer else [0]
        self.line_waveform, = self.ax_waveform.plot(x_data, y_data, color='cyan', linewidth=0.5)
        
        # è¨­å®šéŸ³é‡åœ–
        self.ax_volume.set_title('Volume History', fontsize=14, pad=5)
        self.ax_volume.set_xlabel('Time (seconds)')
        self.ax_volume.set_ylabel('Volume (dB)')
        self.ax_volume.set_ylim(-60, 0)
        self.ax_volume.grid(True, alpha=0.3)
        
        # åˆå§‹åŒ–éŸ³é‡ç·š
        self.line_volume, = self.ax_volume.plot([], [], color='lime', linewidth=2)
        
        # æ·»åŠ éŸ³é‡æ¢
        self.bar_volume = self.ax_volume.axhspan(-60, -60, alpha=0.3, color='green')
        
        # èª¿æ•´å¸ƒå±€
        plt.tight_layout()
        
        # è¨­å®šçª—å£æ¨™é¡Œ
        self.fig.canvas.manager.set_window_title('ASRHub Recording Visualization Test')
    
    def update_visualization(self, audio_data):
        """æ›´æ–°è¦–è¦ºåŒ–è³‡æ–™"""
        # è½‰æ›ç‚º numpy array
        audio_np = np.frombuffer(audio_data, dtype=np.int16)
        
        # è¨ˆç®—éŸ³è¨Šèƒ½é‡ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰
        audio_energy = np.abs(audio_np).mean()
        
        # æ›´æ–°æ³¢å½¢ç·©è¡
        self.waveform_buffer.extend(audio_np)
        
        # è¨ˆç®—éŸ³é‡ (dB)
        if len(audio_np) > 0:
            rms = np.sqrt(np.mean(audio_np.astype(float) ** 2))
            volume_db = 20 * np.log10(max(rms, 1)) - 60  # æ­¸ä¸€åŒ–åˆ° -60 åˆ° 0 dB
        else:
            volume_db = -60
        
        # æ›´æ–°éŸ³é‡æ­·å²
        current_time = time.time()
        self.volume_history.append(volume_db)
        self.time_history.append(current_time)
        
        # æ›´æ–°æ³¢å½¢åœ–
        if len(self.waveform_buffer) > 0:
            x_data = np.linspace(0, len(self.waveform_buffer) / self.target_sample_rate, 
                               len(self.waveform_buffer))
            self.line_waveform.set_data(x_data, list(self.waveform_buffer))
            self.ax_waveform.set_xlim(0, max(2, x_data[-1]))
        
        # æ›´æ–°éŸ³é‡åœ–
        if len(self.time_history) > 1:
            # è½‰æ›ç‚ºç›¸å°æ™‚é–“
            times = np.array(self.time_history) - self.time_history[0]
            volumes = list(self.volume_history)
            
            self.line_volume.set_data(times, volumes)
            self.ax_volume.set_xlim(max(0, times[-1] - 10), times[-1] + 0.5)
            
            # æ›´æ–°éŸ³é‡æ¢
            self.bar_volume.remove()
            bar_color = 'red' if volume_db > -20 else 'yellow' if volume_db > -40 else 'green'
            self.bar_volume = self.ax_volume.axhspan(
                -60, volume_db, 
                alpha=0.3, 
                color=bar_color
            )
        
        # æ›´æ–°éŒ„éŸ³è³‡è¨Š
        recording_info = self.recording_operator.get_info() if hasattr(self.recording_operator, 'get_info') else self.recording_operator.get_recording_info()
        if recording_info.get('is_recording', False):
            status_text = (
                f"[Recording] | "
                f"Duration: {recording_info.get('duration', 0):.1f}s | "
                f"Size: {recording_info.get('bytes_recorded', 0) / 1024:.1f} KB | "
                f"Volume: {volume_db:.1f} dB"
            )
        else:
            status_text = "[Recording Stopped]"
        
        self.fig.suptitle(status_text, fontsize=12, y=0.98)
        
        # é‡ç¹ªåœ–è¡¨
        self.fig.canvas.draw_idle()
    
    async def test_visual_recording(self, duration: float = 10.0):
        """è¦–è¦ºåŒ–éŒ„éŸ³æ¸¬è©¦"""
        logger.info(f"\n{'='*60}")
        logger.info(f"è¦–è¦ºåŒ–éŒ„éŸ³æ¸¬è©¦ ({duration} ç§’)")
        logger.info(f"{'='*60}")
        
        session_id = f"visual_{int(time.time())}"
        
        # è¨­å®šè¦–è¦ºåŒ–
        self.setup_visualization()
        
        # é–‹å§‹éŒ„éŸ³
        await self.recording_operator.start_recording(session_id)
        logger.info(f"éŒ„éŸ³é–‹å§‹ (session_id: {session_id})")
        
        # é–‹å•Ÿéº¥å…‹é¢¨ï¼ˆä½¿ç”¨è¨­å‚™å¯¦éš›åƒæ•¸ï¼‰
        logger.info(f"é–‹å•ŸéŸ³è¨Šæµ: format={self.format}, channels={self.channels}, rate={self.device_sample_rate}, buffer={self.mic_chunk_size}")
        self.stream = self.p.open(
            format=self.format,
            channels=self.channels,
            rate=self.device_sample_rate,
            input=True,
            frames_per_buffer=self.mic_chunk_size
        )
        logger.info(f"éŸ³è¨Šæµå·²é–‹å•Ÿ: is_active={self.stream.is_active()}")
        
        start_time = time.time()
        self.is_recording = True
        frame_count = 0
        
        logger.info("è«‹å°è‘—éº¥å…‹é¢¨èªªè©±...")
        
        # ä½¿ç”¨éé˜»å¡æ–¹å¼é¡¯ç¤ºåœ–è¡¨
        plt.ion()
        plt.show()
        
        # éŒ„éŸ³ä¸»è¿´åœˆ
        while time.time() - start_time < duration and self.is_recording:
            try:
                frame_count += 1
                # è®€å–éŸ³è¨Š - ä½¿ç”¨æ­£ç¢ºçš„ mic_chunk_size
                audio_data = self.stream.read(self.mic_chunk_size, exception_on_overflow=False)
                
                if frame_count <= 5:  # åªè¨˜éŒ„å‰5å¹€
                    logger.info(f"è®€å–åˆ°ç¬¬ {frame_count} å¹€éŸ³è¨Š: {len(audio_data)} bytes")
                
                # å¦‚æœéœ€è¦é‡æ¡æ¨£
                if self.format_converter:
                    # å‰µå»ºè¨­å‚™éŸ³è¨Šçš„å…ƒæ•¸æ“š
                    device_metadata = {
                        'metadata': AudioMetadata(
                            sample_rate=self.device_sample_rate,
                            channels=self.channels,
                            format=AudioFormat.INT16
                        )
                    }
                    # è½‰æ›éŸ³è¨Šæ ¼å¼
                    converted_audio = await self.format_converter.process(audio_data, **device_metadata)
                    if converted_audio:
                        audio_data = converted_audio
                    else:
                        logger.error("éŸ³è¨Šæ ¼å¼è½‰æ›å¤±æ•—")
                        continue
                
                # å‰µå»ºéŸ³è¨Šå…ƒæ•¸æ“š
                recording_metadata = {
                    'metadata': AudioMetadata(
                        sample_rate=self.target_sample_rate,
                        channels=self.channels,
                        format=AudioFormat.INT16
                    )
                }
                
                # å‚³éçµ¦ RecordingOperator
                result = await self.recording_operator.process(audio_data, **recording_metadata)
                
                if frame_count <= 5:
                    logger.info(f"éŒ„éŸ³è™•ç†å®Œæˆï¼Œçµæœ: {result is not None}")
                
                # æ›´æ–°è¦–è¦ºåŒ– - ä½¿ç”¨åŸå§‹éŸ³è¨Šæ•¸æ“š
                original_audio_np = np.frombuffer(audio_data, dtype=np.int16)
                self.update_visualization(audio_data)
                
                # è®“ matplotlib è™•ç†äº‹ä»¶
                plt.pause(0.001)
                
            except Exception as e:
                logger.error(f"éŸ³è¨Šè™•ç†éŒ¯èª¤: {e}")
                break
        
        # åœæ­¢éŒ„éŸ³
        self.is_recording = False
        recorded_data = await self.recording_operator.stop_recording(session_id)
        
        # é—œé–‰éŸ³è¨Šæµ
        self.stream.stop_stream()
        self.stream.close()
        self.stream = None
        
        # é¡¯ç¤ºçµæœ
        duration_actual = time.time() - start_time
        
        if recorded_data:
            logger.info(f"\néŒ„éŸ³å®Œæˆ:")
            logger.info(f"  å¯¦éš›éŒ„éŸ³æ™‚é•·: {duration_actual:.2f} ç§’")
            logger.info(f"  éŸ³è¨Šè³‡æ–™å¤§å°: {len(recorded_data) / 1024:.1f} KB")
            logger.info(f"  é æœŸéŸ³è¨Šé•·åº¦: {len(recorded_data) / (self.target_sample_rate * 2):.2f} ç§’")
            logger.info(f"  å„²å­˜ä½ç½®: test_recordings/{session_id}_*.wav")
            logger.info(f"  è™•ç†å¹€æ•¸: {frame_count}")
        else:
            logger.error("éŒ„éŸ³å¤±æ•—ï¼Œæ²’æœ‰æ”¶åˆ°è³‡æ–™")
        
        # ä¿æŒåœ–è¡¨é¡¯ç¤ºä¸€æ®µæ™‚é–“
        logger.info("\næŒ‰é—œé–‰è¦–çª—çµæŸ...")
        plt.ioff()
        plt.show()
        
        return len(recorded_data) > 0


async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ™ï¸  RecordingOperator è¦–è¦ºåŒ–æ¸¬è©¦")
    print("=" * 60)
    
    tester = RecordingVisualTester()
    
    try:
        # è¨­å®šæ¸¬è©¦ç’°å¢ƒ
        await tester.setup()
        
        # è©¢å•éŒ„éŸ³æ™‚é•·
        while True:
            try:
                duration = input("\nè«‹è¼¸å…¥éŒ„éŸ³æ™‚é•·ï¼ˆç§’ï¼Œ5-60ï¼‰[é è¨­: 10]: ").strip()
                if not duration:
                    duration = 10.0
                else:
                    duration = float(duration)
                    
                if 5 <= duration <= 60:
                    break
                else:
                    print("è«‹è¼¸å…¥ 5-60 ä¹‹é–“çš„æ•¸å­—")
            except ValueError:
                print("è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
        
        # åŸ·è¡Œè¦–è¦ºåŒ–éŒ„éŸ³æ¸¬è©¦
        success = await tester.test_visual_recording(duration)
        print(f"\næ¸¬è©¦çµæœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±æ•—'}")
    
    except KeyboardInterrupt:
        print("\n\næ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        logger.info("ç”¨æˆ¶ä¸­æ–·æ¸¬è©¦")
    except Exception as e:
        print(f"\næ¸¬è©¦éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†è³‡æº
        await tester.cleanup()
        print("\næ¸¬è©¦çµæŸ")


if __name__ == "__main__":
    asyncio.run(main())