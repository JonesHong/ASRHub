#!/usr/bin/env python3
"""
å–šé†’è©è§¸ç™¼çš„è‡ªå‹•éŒ„éŸ³æµç¨‹æ¸¬è©¦
æ•´åˆ WakeWord â†’ VAD â†’ Recording çš„å®Œæ•´æµç¨‹
"""

import asyncio
import sys
import os
import time
import numpy as np
import pyaudio
from typing import Dict, Any, Optional
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import queue
import threading

# æ·»åŠ  src åˆ°è·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.pipeline.operators.wakeword import OpenWakeWordOperator
from src.pipeline.operators.vad import SileroVADOperator
from src.pipeline.operators.recording import RecordingOperator
from src.core.fsm import StateMachine, State
from src.utils.logger import logger

# è¨­å®šä¸­æ–‡å­—é«”ï¼ˆè·¨å¹³å°ï¼‰
import platform
if platform.system() == "Windows":
    plt.rcParams["font.sans-serif"] = ["Microsoft YaHei", "SimHei", "Arial Unicode MS", "sans-serif"]
else:
    plt.rcParams["font.sans-serif"] = ["DejaVu Sans", "sans-serif"]
plt.rcParams["axes.unicode_minus"] = False

# è§£æ±º Windows ä¸­æ–‡é¡¯ç¤ºå•é¡Œ
import matplotlib
matplotlib.use('TkAgg')



# æ“´å±•ç‹€æ…‹å®šç¾©
class ExtendedState(State):
    """æ“´å±•çš„ç‹€æ…‹å®šç¾©"""
    IDLE = "idle"              # å¾…æ©Ÿï¼Œç­‰å¾…å–šé†’
    LISTENING = "listening"    # ç›£è½ä¸­ï¼ŒVAD å•Ÿç”¨
    RECORDING = "recording"    # éŒ„éŸ³ä¸­ï¼ŒVAD æ§åˆ¶çµæŸ
    PROCESSING = "processing"  # è™•ç†ä¸­ï¼ŒéŒ„éŸ³å·²çµæŸ


class WakeRecordFlow:
    """å–šé†’è©è§¸ç™¼çš„è‡ªå‹•éŒ„éŸ³æµç¨‹"""
    
    def __init__(self):
        # åˆå§‹åŒ– Operators
        self.wakeword_operator = OpenWakeWordOperator()
        
        # VAD é…ç½®
        vad_config = {
            'threshold': 0.3,
            'min_silence_duration': 0.3,
            'min_speech_duration': 0.1,
            'adaptive_threshold': True,
            'smoothing_window': 3
        }
        self.vad_operator = SileroVADOperator(vad_config)
        
        self.recording_operator = RecordingOperator({
            'silence_countdown': 1.8,  # éœéŸ³å€’æ•¸ç§’æ•¸
            'vad_controlled': True,    # å•Ÿç”¨ VAD æ§åˆ¶
            'storage': {
                'type': 'file',
                'path': 'wake_recordings'
            }
        })
        
        # ç‹€æ…‹æ©Ÿ
        self.fsm = StateMachine(initial_state=ExtendedState.IDLE)
        self._setup_fsm_transitions()
        
        # éŸ³è¨Šåƒæ•¸
        self.sample_rate = 16000
        self.channels = 1
        self.chunk_size = 1280  # WakeWord éœ€è¦çš„å¤§å°
        self.format = pyaudio.paInt16
        
        # PyAudio
        self.p = pyaudio.PyAudio()
        self.stream = None
        
        # ç‹€æ…‹
        self.is_running = False
        self.is_recording = False
        self.current_session_id = None
        
        # å€’æ•¸è¨ˆæ™‚å™¨
        self.countdown_visualizer = CountdownVisualizer()
        self.countdown_task = None
        
        # è¦–è¦ºåŒ–
        self.audio_queue = queue.Queue()
        self.fig = None
        self.axes = None
        
        # çµ±è¨ˆ
        self.flow_stats = {
            'wake_detections': 0,
            'recordings_completed': 0,
            'auto_stops': 0,
            'manual_stops': 0,
            'total_speech_duration': 0.0,
            'total_recording_duration': 0.0
        }
    
    def _setup_fsm_transitions(self):
        """è¨­å®šç‹€æ…‹è½‰æ›"""
        # IDLE â†’ LISTENING (å–šé†’è©æª¢æ¸¬)
        self.fsm.add_transition(
            from_state=ExtendedState.IDLE,
            to_state=ExtendedState.LISTENING,
            event='wake_detected'
        )
        
        # LISTENING â†’ RECORDING (é–‹å§‹éŒ„éŸ³)
        self.fsm.add_transition(
            from_state=ExtendedState.LISTENING,
            to_state=ExtendedState.RECORDING,
            event='start_recording'
        )
        
        # RECORDING â†’ PROCESSING (VAD å€’æ•¸çµæŸ)
        self.fsm.add_transition(
            from_state=ExtendedState.RECORDING,
            to_state=ExtendedState.PROCESSING,
            event='recording_complete'
        )
        
        # PROCESSING â†’ IDLE (è™•ç†å®Œæˆ)
        self.fsm.add_transition(
            from_state=ExtendedState.PROCESSING,
            to_state=ExtendedState.IDLE,
            event='processing_complete'
        )
        
        # ä»»ä½•ç‹€æ…‹ â†’ IDLE (é‡ç½®)
        for state in [ExtendedState.LISTENING, ExtendedState.RECORDING, ExtendedState.PROCESSING]:
            self.fsm.add_transition(
                from_state=state,
                to_state=ExtendedState.IDLE,
                event='reset'
            )
    
    async def setup(self):
        """è¨­å®šæµç¨‹ç’°å¢ƒ"""
        logger.info("è¨­å®šå–šé†’éŒ„éŸ³æµç¨‹...")
        
        try:
            # å‰µå»ºéŒ„éŸ³ç›®éŒ„
            Path('wake_recordings').mkdir(exist_ok=True)
            
            # åˆå§‹åŒ–æ‰€æœ‰ Operators
            await self.wakeword_operator.start()
            await self.vad_operator.start()
            await self.recording_operator.start()
            
            # è¨­å®šå›èª¿
            self.wakeword_operator.set_detection_callback(self.on_wake_detected)
            self.vad_operator.set_speech_callbacks(
                result_callback=self.on_vad_result
            )
            self.recording_operator.set_callbacks(
                recording_complete_callback=self.on_recording_complete
            )
            
            logger.info("âœ“ å–šé†’éŒ„éŸ³æµç¨‹è¨­å®šå®Œæˆ")
            
        except Exception as e:
            logger.error(f"è¨­å®šå¤±æ•—: {e}")
            raise
    
    async def cleanup(self):
        """æ¸…ç†è³‡æº"""
        logger.info("æ¸…ç†æµç¨‹è³‡æº...")
        
        try:
            # åœæ­¢éŸ³è¨Šæµ
            if self.stream:
                self.stream.stop_stream()
                self.stream.close()
            
            self.p.terminate()
            
            # åœæ­¢æ‰€æœ‰ Operators
            await self.wakeword_operator.stop()
            await self.vad_operator.stop()
            await self.recording_operator.stop()
            
            logger.info("âœ“ æµç¨‹è³‡æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¸…ç†éŒ¯èª¤: {e}")
    
    async def start(self):
        """é–‹å§‹æµç¨‹"""
        logger.info("é–‹å§‹å–šé†’éŒ„éŸ³æµç¨‹")
        logger.info("è«‹èªªå‡ºå–šé†’è©ï¼š'å—¨ï¼Œé«˜é†«' æˆ– 'hi kmu'")
        
        # é–‹å•ŸéŸ³è¨Šæµ
        self.stream = self.p.open(
            format=self.format,
            channels=self.channels,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )
        
        self.is_running = True
        
        # å•Ÿå‹•éŸ³è¨Šè™•ç†ç·šç¨‹
        audio_thread = threading.Thread(target=self._audio_processing_loop)
        audio_thread.daemon = True
        audio_thread.start()
        
        # å•Ÿå‹•è¦–è¦ºåŒ–
        await self._start_visualization()
    
    def _audio_processing_loop(self):
        """éŸ³è¨Šè™•ç†è¿´åœˆ"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        while self.is_running:
            try:
                # è®€å–éŸ³è¨Š
                audio_data = self.stream.read(self.chunk_size, exception_on_overflow=False)
                
                # æ ¹æ“šç‹€æ…‹è™•ç†éŸ³è¨Š
                current_state = self.fsm.get_state()
                
                if current_state == ExtendedState.IDLE:
                    # å¾…æ©Ÿç‹€æ…‹ï¼šåªè™•ç†å–šé†’è©
                    loop.run_until_complete(self._process_wakeword(audio_data))
                    
                elif current_state in [ExtendedState.LISTENING, ExtendedState.RECORDING]:
                    # ç›£è½/éŒ„éŸ³ç‹€æ…‹ï¼šä¸¦è¡Œè™•ç† VAD å’ŒéŒ„éŸ³
                    loop.run_until_complete(self._process_recording_and_vad(audio_data))
                
                # è¦–è¦ºåŒ–è³‡æ–™
                audio_np = np.frombuffer(audio_data, dtype=np.int16)
                self.audio_queue.put({
                    'audio': audio_np,
                    'timestamp': time.time(),
                    'state': current_state,
                    'wake_score': getattr(self.wakeword_operator, 'latest_score', 0),
                    'vad_state': self.vad_operator.get_state() if current_state != ExtendedState.IDLE else None,
                    'recording_info': self.recording_operator.get_recording_info() if self.is_recording else None,
                    'countdown': self.countdown_visualizer.countdown_value
                })
                
            except Exception as e:
                logger.error(f"éŸ³è¨Šè™•ç†éŒ¯èª¤: {e}")
                time.sleep(0.01)
        
        loop.close()
    
    async def _process_wakeword(self, audio_data: bytes):
        """è™•ç†å–šé†’è©æª¢æ¸¬"""
        result = await self.wakeword_operator.process(
            audio_data,
            sample_rate=self.sample_rate,
            session_id="wake_session"
        )
    
    async def _process_recording_and_vad(self, audio_data: bytes):
        """ä¸¦è¡Œè™•ç†éŒ„éŸ³å’Œ VAD"""
        # ä¸¦è¡Œè™•ç†
        recording_task = self.recording_operator.process(audio_data)
        vad_task = self.vad_operator.process(audio_data)
        
        await asyncio.gather(recording_task, vad_task)
    
    async def on_wake_detected(self, wake_event: dict):
        """å–šé†’è©æª¢æ¸¬å›èª¿"""
        logger.info("ğŸ¤ æª¢æ¸¬åˆ°å–šé†’è©ï¼Œé–‹å§‹éŒ„éŸ³...")
        
        self.flow_stats['wake_detections'] += 1
        
        # ç‹€æ…‹è½‰æ›ï¼šIDLE â†’ LISTENING
        self.fsm.transition('wake_detected')
        
        # ç”Ÿæˆ session ID
        self.current_session_id = f"wake_rec_{int(time.time())}"
        
        # çŸ­æš«å»¶é²å¾Œé–‹å§‹éŒ„éŸ³ï¼ˆè®“ç”¨æˆ¶æº–å‚™ï¼‰
        await asyncio.sleep(0.5)
        
        # é–‹å§‹éŒ„éŸ³
        await self.recording_operator.start_recording(
            session_id=self.current_session_id
        )
        self.is_recording = True
        
        # ç‹€æ…‹è½‰æ›ï¼šLISTENING â†’ RECORDING
        self.fsm.transition('start_recording')
        
        # é‡ç½® VAD ç‹€æ…‹
        await self.vad_operator.reset_state()
        
        logger.info("é–‹å§‹éŒ„éŸ³ï¼Œè«‹èªªè©±...")
    
    async def on_vad_result(self, vad_result: dict):
        """VAD çµæœå›èª¿"""
        if self.is_recording and self.fsm.get_state() == ExtendedState.RECORDING:
            # å°‡ VAD çµæœå‚³éçµ¦éŒ„éŸ³ Operator
            await self.recording_operator.on_vad_result(vad_result)
            
            # æ›´æ–°å€’æ•¸è¨ˆæ™‚è¦–è¦ºåŒ–
            if not vad_result['speech_detected']:
                # é–‹å§‹æˆ–æ›´æ–°å€’æ•¸
                if self.recording_operator.is_countdown_active:
                    remaining_time = self.recording_operator.silence_countdown_duration
                    self.countdown_visualizer.update_countdown(remaining_time)
                    
                    # å¦‚æœé‚„æ²’æœ‰å€’æ•¸ä»»å‹™ï¼Œå‰µå»ºä¸€å€‹
                    if not self.countdown_task or self.countdown_task.done():
                        self.countdown_task = asyncio.create_task(
                            self._countdown_animation()
                        )
            else:
                # æª¢æ¸¬åˆ°èªéŸ³ï¼Œé‡ç½®å€’æ•¸
                self.countdown_visualizer.update_countdown(0)
                if self.countdown_task and not self.countdown_task.done():
                    self.countdown_task.cancel()
    
    async def _countdown_animation(self):
        """å€’æ•¸å‹•ç•«"""
        start_time = time.time()
        duration = self.recording_operator.silence_countdown_duration
        
        while self.is_recording:
            elapsed = time.time() - start_time
            remaining = max(0, duration - elapsed)
            
            self.countdown_visualizer.update_countdown(remaining)
            
            if remaining <= 0:
                break
            
            await asyncio.sleep(0.1)
    
    async def on_recording_complete(self, info: dict):
        """éŒ„éŸ³å®Œæˆå›èª¿"""
        logger.info(f"éŒ„éŸ³å®Œæˆ: æ™‚é•· {info['duration']:.2f}s")
        
        self.is_recording = False
        self.flow_stats['recordings_completed'] += 1
        
        # åˆ¤æ–·æ˜¯å¦è‡ªå‹•åœæ­¢
        if info['duration'] < 60:  # å‡è¨­æœ€å¤§éŒ„éŸ³æ™‚é•·æ˜¯ 60 ç§’
            self.flow_stats['auto_stops'] += 1
        else:
            self.flow_stats['manual_stops'] += 1
        
        self.flow_stats['total_recording_duration'] += info['duration']
        
        # ç‹€æ…‹è½‰æ›ï¼šRECORDING â†’ PROCESSING
        self.fsm.transition('recording_complete')
        
        # æ¨¡æ“¬è™•ç†éç¨‹
        await asyncio.sleep(1.0)
        
        # ç‹€æ…‹è½‰æ›ï¼šPROCESSING â†’ IDLE
        self.fsm.transition('processing_complete')
        
        logger.info("è¿”å›å¾…æ©Ÿç‹€æ…‹ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡å–šé†’...")
    
    async def _start_visualization(self):
        """å•Ÿå‹•è¦–è¦ºåŒ–"""
        logger.info("å•Ÿå‹•æµç¨‹è¦–è¦ºåŒ–...")
        
        # è¨­å®šåœ–è¡¨
        plt.style.use("dark_background")
        self.fig, self.axes = plt.subplots(4, 1, figsize=(12, 12))
        
        # éŸ³è¨Šæ³¢å½¢
        ax1 = self.axes[0]
        ax1.set_title("éŸ³è¨Šæ³¢å½¢")
        ax1.set_xlabel("æ¨£æœ¬")
        ax1.set_ylabel("æŒ¯å¹…")
        ax1.grid(True, alpha=0.3)
        self.audio_line, = ax1.plot([], [], 'b-', alpha=0.7)
        
        # å–šé†’è©åˆ†æ•¸
        ax2 = self.axes[1]
        ax2.set_title("å–šé†’è©æª¢æ¸¬")
        ax2.set_xlabel("æ™‚é–“")
        ax2.set_ylabel("åˆ†æ•¸")
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim(0, 1.1)
        self.wake_scatter = ax2.scatter([], [], c='r', s=50)
        
        # ç‹€æ…‹å’Œå€’æ•¸
        ax3 = self.axes[2]
        ax3.set_title("ç³»çµ±ç‹€æ…‹")
        ax3.axis('off')
        self.state_text = ax3.text(0.05, 0.5, "", fontsize=14, verticalalignment='center')
        
        # çµ±è¨ˆè³‡è¨Š
        ax4 = self.axes[3]
        ax4.set_title("æµç¨‹çµ±è¨ˆ")
        ax4.axis('off')
        self.stats_text = ax4.text(0.05, 0.5, "", fontsize=12, verticalalignment='center')
        
        plt.tight_layout()
        
        # å•Ÿå‹•å‹•ç•«
        ani = FuncAnimation(self.fig, self._update_plot, interval=100, blit=False)
        
        try:
            plt.show()
        except KeyboardInterrupt:
            logger.info("è¦–è¦ºåŒ–è¢«ç”¨æˆ¶ä¸­æ–·")
        finally:
            self.is_running = False
    
    def _update_plot(self, frame):
        """æ›´æ–°åœ–è¡¨"""
        # è™•ç†ä½‡åˆ—
        latest_data = None
        while not self.audio_queue.empty():
            try:
                latest_data = self.audio_queue.get_nowait()
            except queue.Empty:
                break
        
        if latest_data:
            # æ›´æ–°éŸ³è¨Šæ³¢å½¢
            audio_data = latest_data['audio']
            self.audio_line.set_data(range(len(audio_data)), audio_data)
            self.axes[0].set_xlim(0, len(audio_data))
            self.axes[0].set_ylim(-32768, 32767)
            
            # æ›´æ–°ç‹€æ…‹é¡¯ç¤º
            state = latest_data['state']
            countdown = latest_data['countdown']
            
            state_text = f"""
ç•¶å‰ç‹€æ…‹: {self._get_state_display(state)}

"""
            
            if state == ExtendedState.RECORDING and countdown > 0:
                # é¡¯ç¤ºå€’æ•¸è¨ˆæ™‚
                bar = self.countdown_visualizer.get_progress_bar()
                state_text += f"éœéŸ³å€’æ•¸: {bar} {countdown:.1f}s\n"
            
            if latest_data['recording_info'] and latest_data['recording_info']['is_recording']:
                duration = latest_data['recording_info']['duration']
                state_text += f"éŒ„éŸ³æ™‚é•·: {duration:.1f}s\n"
            
            self.state_text.set_text(state_text)
            
            # æ›´æ–°çµ±è¨ˆ
            stats_text = f"""
å–šé†’æ¬¡æ•¸: {self.flow_stats['wake_detections']}
å®ŒæˆéŒ„éŸ³: {self.flow_stats['recordings_completed']}
è‡ªå‹•åœæ­¢: {self.flow_stats['auto_stops']}
æ‰‹å‹•åœæ­¢: {self.flow_stats['manual_stops']}
ç¸½éŒ„éŸ³æ™‚é•·: {self.flow_stats['total_recording_duration']:.1f}s
"""
            self.stats_text.set_text(stats_text)
        
        return self.audio_line, self.state_text, self.stats_text
    
    def _get_state_display(self, state):
        """ç²å–ç‹€æ…‹é¡¯ç¤ºæ–‡å­—"""
        state_map = {
            ExtendedState.IDLE: "ğŸŸ¢ å¾…æ©Ÿä¸­ï¼ˆç­‰å¾…å–šé†’è©ï¼‰",
            ExtendedState.LISTENING: "ğŸŸ¡ ç›£è½ä¸­ï¼ˆæº–å‚™éŒ„éŸ³ï¼‰",
            ExtendedState.RECORDING: "ğŸ”´ éŒ„éŸ³ä¸­ï¼ˆVAD ç›£æ§ï¼‰",
            ExtendedState.PROCESSING: "ğŸ”µ è™•ç†ä¸­"
        }
        return state_map.get(state, state)
    
    def print_flow_statistics(self):
        """æ‰“å°æµç¨‹çµ±è¨ˆ"""
        print("\n" + "="*60)
        print("ğŸ“Š å–šé†’éŒ„éŸ³æµç¨‹çµ±è¨ˆ")
        print("="*60)
        
        print(f"\nå–šé†’è©æª¢æ¸¬:")
        print(f"  ç¸½æª¢æ¸¬æ¬¡æ•¸: {self.flow_stats['wake_detections']}")
        
        print(f"\néŒ„éŸ³çµ±è¨ˆ:")
        print(f"  å®ŒæˆéŒ„éŸ³æ•¸: {self.flow_stats['recordings_completed']}")
        print(f"  è‡ªå‹•åœæ­¢: {self.flow_stats['auto_stops']}")
        print(f"  æ‰‹å‹•åœæ­¢: {self.flow_stats['manual_stops']}")
        print(f"  ç¸½éŒ„éŸ³æ™‚é•·: {self.flow_stats['total_recording_duration']:.1f}s")
        
        if self.flow_stats['recordings_completed'] > 0:
            avg_duration = self.flow_stats['total_recording_duration'] / self.flow_stats['recordings_completed']
            print(f"  å¹³å‡éŒ„éŸ³æ™‚é•·: {avg_duration:.1f}s")
        
        print("="*60)


class CountdownVisualizer:
    """å€’æ•¸è¨ˆæ™‚å™¨è¦–è¦ºåŒ–"""
    
    def __init__(self):
        self.countdown_value = 0
        self.max_countdown = 1.8
    
    def update_countdown(self, remaining_time: float):
        """æ›´æ–°å€’æ•¸é¡¯ç¤º"""
        self.countdown_value = remaining_time
    
    def get_progress_bar(self) -> str:
        """ç²å–é€²åº¦æ¢å­—ç¬¦ä¸²"""
        if self.countdown_value <= 0:
            return ""
        
        progress = self.countdown_value / self.max_countdown
        bar_length = int(progress * 20)
        bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
        return f"[{bar}]"
    
    def print_countdown(self):
        """æ‰“å°å€’æ•¸ï¼ˆçµ‚ç«¯æ¨¡å¼ï¼‰"""
        bar = self.get_progress_bar()
        print(f"\rå€’æ•¸è¨ˆæ™‚: {bar} {self.countdown_value:.1f}s", end="", flush=True)


async def test_scenarios():
    """æ¸¬è©¦ä¸åŒå ´æ™¯"""
    print("\nğŸ§ª æ¸¬è©¦å ´æ™¯æ¨¡å¼")
    print("1. æ­£å¸¸å°è©±ï¼šèªªè©± â†’ çŸ­æš«åœé “ â†’ ç¹¼çºŒèªªè©±")
    print("2. çµæŸå°è©±ï¼šèªªè©± â†’ éœéŸ³ 1.8s â†’ è‡ªå‹•åœæ­¢")
    print("3. é•·å°è©±ï¼šæŒçºŒèªªè©±ç›´åˆ°æœ€å¤§æ™‚é•·")
    print("4. å™ªéŸ³å¹²æ“¾ï¼šèƒŒæ™¯å™ªéŸ³æ¸¬è©¦")
    
    # TODO: å¯¦ä½œæ¸¬è©¦å ´æ™¯
    pass


async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ™ï¸ å–šé†’è©è§¸ç™¼è‡ªå‹•éŒ„éŸ³æµç¨‹")
    print("-" * 60)
    print("èªªå‡ºå–šé†’è©é–‹å§‹éŒ„éŸ³ï¼ŒéœéŸ³ 1.8 ç§’è‡ªå‹•åœæ­¢")
    print("æ”¯æ´çš„å–šé†’è©ï¼š'å—¨ï¼Œé«˜é†«' æˆ– 'hi kmu'")
    print("-" * 60)
    
    flow = WakeRecordFlow()
    
    try:
        # è¨­å®šæµç¨‹
        await flow.setup()
        
        # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
        if not os.environ.get("HF_TOKEN"):
            print("\nâš ï¸  è­¦å‘Š: æœªè¨­å®š HF_TOKEN ç’°å¢ƒè®Šæ•¸")
            print("å¦‚æœéœ€è¦ä¸‹è¼‰æ¨¡å‹ï¼Œè«‹è¨­å®š: export HF_TOKEN=your_token")
        
        # é–‹å§‹æµç¨‹
        await flow.start()
        
    except KeyboardInterrupt:
        print("\næµç¨‹è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\næµç¨‹éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†è³‡æº
        await flow.cleanup()
        
        # æ‰“å°çµ±è¨ˆ
        flow.print_flow_statistics()


if __name__ == "__main__":
    asyncio.run(main())