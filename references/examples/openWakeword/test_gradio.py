import os
from huggingface_hub import HfFolder, hf_hub_download
import gradio as gr
import json
import pandas as pd
import collections
import scipy.signal
import numpy as np
from functools import partial
from openwakeword.model import Model

from openwakeword.utils import download_models
download_models()

# ç”¨ Secret token å¾ HF Model Hub ä¸‹è¼‰ç§æœ‰æ¨¡å‹
hf_token = os.environ.get("HF_TOKEN") or HfFolder.get_token()

if hf_token:
    print("è¼‰å…¥ KMU æ¨¡å‹...")
    model_path = hf_hub_download(
        repo_id="JTBTechnology/kmu_wakeword",
        filename="hi_kmu_0721.onnx",
        token=hf_token,
        repo_type="model"
    )

# ç›´æ¥ç”¨ä¸‹è¼‰çš„æ¨¡å‹è·¯å¾‘è¼‰å…¥
model = Model(wakeword_models=[model_path], inference_framework="onnx")

# Define function to process audio
# def process_audio(audio, state=collections.defaultdict(partial(collections.deque, maxlen=60))):
def process_audio(audio, state=None):
    if state is None:
        state = collections.defaultdict(partial(collections.deque, maxlen=60))
    
    
    # Resample audio to 16khz if needed
    if audio[0] != 16000:
        data = scipy.signal.resample(audio[1], int(float(audio[1].shape[0])/audio[0]*16000))
    else:
        data = audio[1]
    
    # ç¢ºä¿æ•¸æ“šæ˜¯ float32 æ ¼å¼
    if data.dtype != np.float32:
        data = data.astype(np.float32)
    
    # Get predictions
    for i in range(0, data.shape[0], 1280):
        if len(data.shape) == 2 or data.shape[-1] == 2:
            chunk = data[i:i+1280][:, 0]  # just get one channel of audio
        else:
            chunk = data[i:i+1280]

        if chunk.shape[0] == 1280:
            prediction = model.predict(chunk)
            for key in prediction:
                #Fill deque with zeros if it's empty
                if len(state[key]) == 0:
                    state[key].extend(np.zeros(60))
                    
                # Add prediction
                state[key].append(prediction[key])
                
                # æª¢æ¸¬å–šé†’è©æ˜¯å¦æˆåŠŸï¼ˆé–¾å€¼è¨­ç‚º 0.5ï¼‰
                if prediction[key] > 0.5:
                    print("\n" + "="*50)
                    print(f"ğŸ¯ å–šé†’è©åµæ¸¬æˆåŠŸï¼")
                    print(f"æ¨¡å‹åç¨±: {key}")
                    print(f"ç½®ä¿¡åº¦åˆ†æ•¸: {prediction[key]:.4f}")
                    print(f"\néŸ³è¨Šæ ¼å¼è³‡è¨Š:")
                    print(f"  - åŸå§‹æ¡æ¨£ç‡: {audio[0]} Hz")
                    print(f"  - é‡æ¡æ¨£å¾Œæ¡æ¨£ç‡: 16000 Hz")
                    print(f"  - éŸ³è¨Šæ•¸æ“šé¡å‹: {data.dtype}")
                    print(f"  - éŸ³è¨Šå½¢ç‹€: {data.shape}")
                    print(f"  - éŸ³è¨Šé•·åº¦: {data.shape[0]/16000:.2f} ç§’")
                    print(f"  - éŸ³è¨Šé€šé“æ•¸: {1 if len(data.shape) == 1 else data.shape[-1]}")
                    print(f"  - éŸ³è¨ŠæŒ¯å¹…ç¯„åœ: [{np.min(data):.4f}, {np.max(data):.4f}]")
                    print(f"  - éŸ³è¨Šå¹³å‡å€¼: {np.mean(data):.4f}")
                    print(f"  - éŸ³è¨Šæ¨™æº–å·®: {np.std(data):.4f}")
                    print(f"\nè™•ç†è³‡è¨Š:")
                    print(f"  - ç•¶å‰è™•ç†å¹€ä½ç½®: {i}")
                    print(f"  - è™•ç†å¡Šå¤§å°: {chunk.shape[0]}")
                    print(f"  - æ™‚é–“æˆ³: {i/16000:.2f} ç§’")
                    print("="*50 + "\n")
    
    # Make line plot
    dfs = []
    for key in state.keys():
        df = pd.DataFrame({"x": np.arange(len(state[key])), "y": state[key], "Model": key})
        dfs.append(df)
    
    df = pd.concat(dfs)

    plot = gr.LinePlot(
        value=df,
        x='x',
        y='y',
        color="Model",
        y_lim=(0,1),
        tooltip="Model",
        width=600,
        height=300,
        x_title="Time (frames)",
        y_title="Model Score",
        color_legend_position="bottom"
    )
    # 1. å°‡ state è½‰æˆå¯ JSON åºåˆ—åŒ–æ ¼å¼ï¼ˆdict of listsï¼‰
    serializable_state = {k: [float(x) for x in v] for k, v in state.items()}

    # 2. å›å‚³ serializable_state çµ¦ Gradio
    return plot, serializable_state

# Create Gradio interface and launch

desc = """
é€™æ˜¯ [openWakeWord](https://github.com/dscripka/openWakeWord) æœ€æ–°ç‰ˆæœ¬é è¨­æ¨¡å‹çš„å°å·¥å…·ç¤ºç¯„ã€‚
è«‹é»ä¸€ä¸‹ä¸‹é¢çš„ã€Œé–‹å§‹éŒ„éŸ³ã€æŒ‰éˆ•ï¼Œå°±èƒ½ç›´æ¥ç”¨éº¥å…‹é¢¨æ¸¬è©¦ã€‚
ç³»çµ±æœƒå³æ™‚æŠŠæ¯å€‹æ¨¡å‹çš„åˆ†æ•¸ç”¨æŠ˜ç·šåœ–ç§€å‡ºä¾†ï¼Œä½ ä¹Ÿå¯ä»¥æŠŠæ»‘é¼ ç§»åˆ°ç·šä¸Šçœ‹æ˜¯å“ªä¸€å€‹æ¨¡å‹ã€‚
æ¯ä¸€å€‹æ¨¡å‹éƒ½æœ‰è‡ªå·±å°ˆå±¬çš„å–šé†’è©æˆ–æŒ‡ä»¤å¥ï¼ˆæ›´å¤šå¯ä»¥åƒè€ƒ [æ¨¡å‹èªªæ˜](https://github.com/dscripka/openWakeWord/tree/main/docs/models)ï¼‰ã€‚
å¦‚æœåµæ¸¬åˆ°ä½ è¬›äº†å°çš„é—œéµè©ï¼Œåœ–ä¸Šå°æ‡‰æ¨¡å‹çš„åˆ†æ•¸æœƒçªç„¶è®Šé«˜ã€‚ä½ å¯ä»¥è©¦è‘—è¬›ä¸‹é¢çš„ç¯„ä¾‹èªå¥è©¦è©¦çœ‹ï¼š
| æ¨¡å‹åç¨±          | å»ºè­°èªå¥   |
| ------------- | ------ |
| hi_kmu_0721 | ã€Œå—¨ï¼Œé«˜é†«ã€ |
"""

gr_int = gr.Interface(
    title = "èªéŸ³å–šé†’å±•ç¤º",
    description = desc,
    css = ".flex {flex-direction: column} .gr-panel {width: 100%}",
    fn=process_audio,
    inputs=[
        gr.Audio(sources=["microphone"], type="numpy", streaming=True, show_label=False), 
        "state"
    ],
    outputs=[
        gr.LinePlot(show_label=False),
        "state"
    ],
    live=True)

gr_int.launch()