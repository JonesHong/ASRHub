# WebASRCore - å‰ç«¯èªéŸ³è­˜åˆ¥æ ¸å¿ƒåº«è¨­è¨ˆè¦åŠƒæ›¸

## åŸ·è¡Œæ‘˜è¦

WebASRCore æ˜¯ä¸€å€‹åŸºæ–¼ ASRHub æ¶æ§‹ç†å¿µè¨­è¨ˆçš„ç´”å‰ç«¯èªéŸ³è­˜åˆ¥åº«ã€‚å®ƒæ‰¿è¥²äº† ASRHub çš„æ ¸å¿ƒè¨­è¨ˆåŸå‰‡ï¼šKISSï¼ˆKeep It Simple, Stupidï¼‰ã€ç„¡ç‹€æ…‹æœå‹™æ¶æ§‹ã€å’ŒéŸ³è¨Šè™•ç†ç®¡ç·šæ¨¡å¼ï¼ŒåŒæ™‚é‡å°ç€è¦½å™¨ç’°å¢ƒé€²è¡Œäº†å„ªåŒ–ã€‚

### å¾ POC å­¸åˆ°çš„é—œéµç¶“é©—

é€šéåˆ†æ wake-word-transcriber POC å¯¦ç¾ï¼Œæˆ‘å€‘ç²å¾—ä»¥ä¸‹é‡è¦æ´å¯Ÿï¼š

1. **åŸ·è¡Œæ¨¡å¼å›ºå®š**ï¼šåˆå§‹åŒ–æ™‚æª¢æ¸¬èƒ½åŠ›ä¸¦é¸æ“‡æœ€é©åˆçš„æ¨¡å¼ï¼Œä¹‹å¾Œä¸å†æ”¹è®Š
2. **Worker å¯†é›†ä½¿ç”¨**ï¼šå°‡ CPU å¯†é›†ä»»å‹™å¸è¼‰åˆ° Worker æå‡ä¸»ç·šç¨‹éŸ¿æ‡‰  
3. **æ¨¡å‹é è¼‰å…¥**ï¼šä½¿ç”¨ link prefetch å’Œå¿«å–ç­–ç•¥åŠ é€Ÿæ¨¡å‹è¼‰å…¥
4. **éŸ³è¨Šç®¡ç·šæ•´åˆ**ï¼šæä¾›çµ±ä¸€çš„ä»‹é¢å±¤å”èª¿å„å€‹æœå‹™
5. **ç€è¦½å™¨ç›¸å®¹æ€§**ï¼šåˆå§‹åŒ–æ™‚çš„å…¨é¢èƒ½åŠ›æª¢æ¸¬å’Œè¨ºæ–·
6. **é…ç½®å„ªå…ˆ**ï¼šæä¾›é è¨­é…ç½®ä½†å…è¨±ç”¨æˆ¶è¦†å¯«ï¼Œä¸åšéåº¦æ™ºèƒ½æ±ºç­–

### æ ¸å¿ƒç‰¹æ€§
- ğŸ¯ **é›¶ä¼ºæœå™¨ä¾è³´**ï¼šå®Œå…¨åœ¨ç€è¦½å™¨ç«¯é‹è¡Œ
- ğŸ” **éš±ç§å„ªå…ˆ**ï¼šéŸ³è¨Šæ•¸æ“šä¸é›¢é–‹ç”¨æˆ¶è¨­å‚™
- ğŸ“¦ **è¼•é‡ç´š**ï¼šæ”¯æ´æŒ‰éœ€è¼‰å…¥å’Œ Tree Shaking
- ğŸŒ **CDN å‹å–„**ï¼šå¯ç›´æ¥é€é script æ¨™ç±¤å¼•å…¥
- ğŸ”§ **é«˜åº¦å¯é…ç½®**ï¼šéˆæ´»çš„æœå‹™å•Ÿç”¨/åœç”¨æ©Ÿåˆ¶
- ğŸš€ **å³æ™‚è™•ç†**ï¼šä½å»¶é²çš„æœ¬åœ°éŸ³è¨Šè™•ç†

## 1. æ¶æ§‹ç¸½è¦½

### 1.1 è¨­è¨ˆç†å¿µæ‰¿è¥²

å¾ ASRHub ç¹¼æ‰¿çš„æ ¸å¿ƒç†å¿µï¼š

1. **KISS åŸå‰‡**
   - ç°¡å–®ç›´æ¥çš„ API è¨­è¨ˆ
   - é¿å…éåº¦å·¥ç¨‹åŒ–
   - æ¸…æ™°çš„è²¬ä»»åŠƒåˆ†

2. **ç„¡ç‹€æ…‹æœå‹™**
   - æ¯å€‹æœå‹™ç¨ç«‹é‹ä½œ
   - æœå‹™é–“ç„¡ç›¸äº’ä¾è³´
   - æ˜“æ–¼æ¸¬è©¦å’Œç¶­è­·

3. **ç›´æ¥èª¿ç”¨æ¨¡å¼**
   - é¿å…ä¸å¿…è¦çš„æŠ½è±¡å±¤
   - æœå‹™ç›´æ¥æš´éœ²ç‚ºæ¨¡çµ„ç´šåˆ¥çš„å–®ä¾‹
   - æ•ˆæœï¼ˆEffectsï¼‰ç›´æ¥èª¿ç”¨æœå‹™

4. **éŸ³è¨Šè™•ç†ç®¡ç·š**
   ```
   Microphone/File â†’ AudioQueue â†’ Buffer â†’ Enhance â†’ Denoise â†’ VAD â†’ ASR Provider
   ```

### 1.2 å‰ç«¯ç’°å¢ƒé©é…

é‡å°ç€è¦½å™¨ç’°å¢ƒçš„ç‰¹æ®Šè¨­è¨ˆï¼š

- **å–®ä¸€ç”¨æˆ¶å ´æ™¯**ï¼šç§»é™¤å¤š session ç®¡ç†
- **ç€è¦½å™¨ API å„ªå…ˆ**ï¼šå……åˆ†åˆ©ç”¨åŸç”Ÿ Web API
- **Web Worker éš”é›¢**ï¼šCPU å¯†é›†å‹ä»»å‹™åœ¨ Worker ä¸­åŸ·è¡Œ
- **æ¼¸é€²å¼è¼‰å…¥**ï¼šML æ¨¡å‹æŒ‰éœ€è¼‰å…¥ï¼Œæ¸›å°‘åˆå§‹è¼‰å…¥æ™‚é–“
- **å›ºå®šæ¨¡å¼**ï¼šåˆå§‹åŒ–æ™‚æª¢æ¸¬èƒ½åŠ›ä¸¦é¸æ“‡æœ€é©åˆæ¨¡å¼ï¼Œä¹‹å¾Œä¸å†æ”¹è®Š

## 2. æŠ€è¡“æ¶æ§‹

### 2.1 æŠ€è¡“æ£§é¸å‹

| é¡åˆ¥ | æŠ€è¡“é¸æ“‡ | ç†ç”± |
|------|----------|------|
| ç‹€æ…‹ç®¡ç† | XState | å¼·å¤§çš„ FSM å¯¦ç¾ï¼ŒTypeScript æ”¯æ´å®Œå–„ |
| åæ‡‰å¼ç³»çµ± | SolidJS | è¼•é‡ç´šï¼ˆ~5KBï¼‰ï¼Œç´°ç²’åº¦åæ‡‰æ€§ï¼Œè‡ªå‹•ä¾è³´è¿½è¹¤ |
| éŸ³è¨Šè™•ç† | Web Audio API + AudioWorklet | ä½å»¶é²ã€é«˜æ€§èƒ½éŸ³è¨Šè™•ç† |
| ML Runtime | ONNX Runtime Web | è·¨å¹³å° ML æ¨¡å‹åŸ·è¡Œ |
| èªéŸ³æ¨¡å‹ | Transformers.js | Whisper æ¨¡å‹çš„ Web ç‰ˆæœ¬ |
| æ‰“åŒ…å·¥å…· | Vite/Rollup | ESM å„ªå…ˆï¼Œå„ªç§€çš„ Tree Shaking |
| é¡å‹ç³»çµ± | TypeScript | å®Œæ•´çš„é¡å‹å®‰å…¨ |

### 2.2 æ¨¡çµ„æ¶æ§‹

```
WebASRCore/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                 # æ ¸å¿ƒå¼•æ“
â”‚   â”‚   â”œâ”€â”€ fsm/              # ç‹€æ…‹æ©Ÿå¯¦ç¾
â”‚   â”‚   â”‚   â”œâ”€â”€ states.ts     # ç‹€æ…‹å®šç¾©
â”‚   â”‚   â”‚   â”œâ”€â”€ transitions.ts # è½‰æ›è¦å‰‡
â”‚   â”‚   â”‚   â””â”€â”€ machine.ts    # XState æ©Ÿå™¨é…ç½®
â”‚   â”‚   â”œâ”€â”€ store/            # ç‹€æ…‹ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ store.ts      # RxJS Subject
â”‚   â”‚   â”‚   â”œâ”€â”€ actions.ts    # Action å®šç¾©
â”‚   â”‚   â”‚   â””â”€â”€ effects.ts    # Side Effects
â”‚   â”‚   â”œâ”€â”€ audio-queue/      # éŸ³è¨Šä½‡åˆ—
â”‚   â”‚   â”‚   â”œâ”€â”€ queue.ts      # ä½‡åˆ—å¯¦ç¾
â”‚   â”‚   â”‚   â””â”€â”€ types.ts      # éŸ³è¨Šæ•¸æ“šé¡å‹
â”‚   â”‚   â””â”€â”€ buffer/           # ç·©è¡ç®¡ç†
â”‚   â”‚       â”œâ”€â”€ manager.ts    # BufferManager
â”‚   â”‚       â””â”€â”€ strategies.ts # Fixed/Sliding/Dynamic
â”‚   â”‚
â”‚   â”œâ”€â”€ services/             # ç„¡ç‹€æ…‹æœå‹™
â”‚   â”‚   â”œâ”€â”€ microphone/       # éº¥å…‹é¢¨æ“·å–
â”‚   â”‚   â”‚   â”œâ”€â”€ capture.ts    # getUserMedia å°è£
â”‚   â”‚   â”‚   â””â”€â”€ processor.ts  # AudioWorklet è™•ç†å™¨
â”‚   â”‚   â”œâ”€â”€ vad/              # èªéŸ³æ´»å‹•æª¢æ¸¬
â”‚   â”‚   â”‚   â”œâ”€â”€ silero-vad.ts # Silero VAD ONNX
â”‚   â”‚   â”‚   â””â”€â”€ worker.ts     # VAD Web Worker
â”‚   â”‚   â”œâ”€â”€ wake-word/        # å–šé†’è©æª¢æ¸¬
â”‚   â”‚   â”‚   â”œâ”€â”€ openwakeword.ts # OpenWakeWord ONNX
â”‚   â”‚   â”‚   â””â”€â”€ worker.ts     # Wake Word Worker
â”‚   â”‚   â”œâ”€â”€ denoise/          # é™å™ªè™•ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ rnnoise.ts    # RNNoise WASM
â”‚   â”‚   â”‚   â””â”€â”€ worker.ts     # Denoise Worker
â”‚   â”‚   â””â”€â”€ timer/            # è¨ˆæ™‚å™¨æœå‹™
â”‚   â”‚       â””â”€â”€ timer.ts      # å€’æ•¸è¨ˆæ™‚å™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ providers/            # ASR æä¾›è€…
â”‚   â”‚   â”œâ”€â”€ base.ts           # Provider ä»‹é¢
â”‚   â”‚   â”œâ”€â”€ webspeech/        # Web Speech API
â”‚   â”‚   â”‚   â””â”€â”€ provider.ts   # åŸç”Ÿ API å°è£
â”‚   â”‚   â””â”€â”€ whisper/          # Whisper æ¨¡å‹
â”‚   â”‚       â”œâ”€â”€ provider.ts   # Transformers.js
â”‚   â”‚       â””â”€â”€ worker.ts     # Whisper Worker
â”‚   â”‚
â”‚   â”œâ”€â”€ config/               # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ config.ts         # ConfigManager
â”‚   â”‚   â”œâ”€â”€ defaults.ts       # é è¨­é…ç½®
â”‚   â”‚   â””â”€â”€ types.ts          # é…ç½®ä»‹é¢
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                # å·¥å…·å‡½æ•¸
â”‚   â”‚   â”œâ”€â”€ logger.ts         # æ—¥èªŒç³»çµ±
â”‚   â”‚   â”œâ”€â”€ audio-tools.ts    # éŸ³è¨Šå·¥å…·
â”‚   â”‚   â””â”€â”€ singleton.ts      # å–®ä¾‹è¼”åŠ©
â”‚   â”‚
â”‚   â””â”€â”€ index.ts              # ä¸»å…¥å£
â”‚
â”œâ”€â”€ dist/                     # æ§‹å»ºè¼¸å‡º
â”‚   â”œâ”€â”€ webasr-core.esm.js   # ESM ç‰ˆæœ¬
â”‚   â”œâ”€â”€ webasr-core.umd.js   # UMD ç‰ˆæœ¬
â”‚   â””â”€â”€ types/                # TypeScript è²æ˜
â”‚
â”œâ”€â”€ examples/                 # ä½¿ç”¨ç¯„ä¾‹
â”‚   â”œâ”€â”€ basic/                # åŸºç¤ç”¨æ³•
â”‚   â”œâ”€â”€ react/                # React æ•´åˆ
â”‚   â”œâ”€â”€ vue/                  # Vue æ•´åˆ
â”‚   â””â”€â”€ cdn/                  # CDN å¼•å…¥
â”‚
â”œâ”€â”€ models/                   # ML æ¨¡å‹æ–‡ä»¶ï¼ˆå¯é¸ï¼Œæ‰“åŒ…æ™‚åŒ…å«ï¼‰
â”‚   â”œâ”€â”€ silero-vad/           # VAD æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ silero_vad.onnx      # å®Œæ•´ç‰ˆ (~1.5MB)
â”‚   â”‚   â””â”€â”€ silero_vad_q8.onnx   # é‡åŒ–ç‰ˆ (~400KB)
â”‚   â”œâ”€â”€ openwakeword/         # å–šé†’è©æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ hey_assistant.onnx      # å®Œæ•´ç‰ˆ (~2MB)
â”‚   â”‚   â””â”€â”€ hey_assistant_q8.onnx   # é‡åŒ–ç‰ˆ (~500KB)
â”‚   â””â”€â”€ whisper/              # Whisper æ¨¡å‹
â”‚       â”œâ”€â”€ whisper-tiny.onnx       # å®Œæ•´ç‰ˆ (~39MB)
â”‚       â””â”€â”€ whisper-tiny-q8.onnx    # é‡åŒ–ç‰ˆ (~10MB)
â”‚
â””â”€â”€ package.json              # NPM é…ç½®
```

## 3. æ ¸å¿ƒçµ„ä»¶è¨­è¨ˆ

### 3.1 FSM ç‹€æ…‹æ©Ÿ

ä½¿ç”¨ XState å¯¦ç¾ç‹€æ…‹ç®¡ç†ï¼Œåæ˜ å®Œæ•´çš„éŸ³è¨Šè™•ç†æµç¨‹ï¼š

```typescript
// states.ts
export enum State {
  IDLE = 'idle',
  WAKE_WORD_LISTENING = 'wake_word_listening',  // æŒçºŒç›£è½å–šé†’è©
  RECORDING = 'recording',                       // å–šé†’å¾Œé–‹å§‹éŒ„éŸ³
  SILENCE_DETECTED = 'silence_detected',         // VAD æª¢æ¸¬åˆ°éœéŸ³
  COUNTDOWN = 'countdown',                        // å€’æ•¸è¨ˆæ™‚ä¸­
  TRANSCRIBING = 'transcribing',                 // è½‰è­¯ä¸­
  ERROR = 'error'
}

// machine.ts
export const createASRMachine = (config: ASRConfig) => {
  return createMachine({
    id: 'webASR',
    initial: State.IDLE,
    context: {
      mode: config.mode, // 'streaming' | 'non-streaming'
      wakeWordEnabled: config.wakeWord?.enabled,
      vadEnabled: config.vad?.enabled,
      countdownSeconds: config.silenceTimeout || 2,
      audioQueue: [],
      recordingBuffer: []
    },
    states: {
      [State.IDLE]: {
        on: {
          START: State.WAKE_WORD_LISTENING,
          UPLOAD: State.TRANSCRIBING  // ç›´æ¥ä¸Šå‚³æª”æ¡ˆ
        }
      },
      [State.WAKE_WORD_LISTENING]: {
        // æŒçºŒå°‡éŸ³è¨Šé€çµ¦ OpenWakeWord
        on: {
          WAKE_WORD_DETECTED: {
            target: State.RECORDING,
            actions: 'clearAudioQueue'  // æ¸…ç©ºä½‡åˆ—ï¼Œé–‹å§‹æ–°éŒ„éŸ³
          },
          STOP: State.IDLE
        }
      },
      [State.RECORDING]: {
        // åŒæ™‚å•Ÿå‹• VADï¼Œè¨˜éŒ„éŸ³è¨Š
        on: {
          SILENCE_DETECTED: State.SILENCE_DETECTED,
          STOP: State.IDLE
        },
        invoke: {
          src: 'vadService',  // å•Ÿå‹• VAD æœå‹™
        }
      },
      [State.SILENCE_DETECTED]: {
        entry: 'startCountdown',
        on: {
          COUNTDOWN_COMPLETE: State.TRANSCRIBING,
          SPEECH_DETECTED: State.RECORDING,  // é‡æ–°æª¢æ¸¬åˆ°èªéŸ³ï¼Œè¿”å›éŒ„éŸ³
          STOP: State.IDLE
        }
      },
      [State.COUNTDOWN]: {
        // å€’æ•¸è¨ˆæ™‚ç‹€æ…‹ï¼ˆå¯é¸ï¼Œå¦‚æœéœ€è¦æ›´ç²¾ç´°çš„æ§åˆ¶ï¼‰
        after: {
          COUNTDOWN_DELAY: State.TRANSCRIBING
        },
        on: {
          SPEECH_DETECTED: State.RECORDING,
          STOP: State.IDLE
        }
      },
      [State.TRANSCRIBING]: {
        entry: 'sendToProvider',  // ç™¼é€æ•´å€‹ä½‡åˆ—çµ¦ ASR Provider
        on: {
          TRANSCRIPTION_COMPLETE: State.WAKE_WORD_LISTENING,  // å®Œæˆå¾Œè¿”å›ç›£è½
          TRANSCRIPTION_PARTIAL: State.TRANSCRIBING,
          ERROR: State.ERROR
        }
      },
      [State.ERROR]: {
        on: {
          RETRY: State.IDLE,
          RESET: State.IDLE
        }
      }
    }
  });
};
```

### 3.2 éŸ³è¨Šä½‡åˆ—ç®¡ç†

ç°¡åŒ–ç‰ˆçš„ AudioQueueï¼Œé©åˆå–®ç”¨æˆ¶å ´æ™¯ï¼Œä¸¦æ•´åˆ SolidJS éŸ¿æ‡‰å¼ï¼š

```typescript
// audio-queue/queue.ts
import { createSignal, createEffect } from 'solid-js';

export class AudioQueue {
  private queue: AudioChunk[] = [];
  private maxSize: number;
  private [getSize, setSize] = createSignal(0);
  private [isRecording, setIsRecording] = createSignal(false);
  private recordingBuffer: AudioChunk[] = [];

  constructor(config: QueueConfig) {
    this.maxSize = config.maxQueueSize || 100;
  }

  push(chunk: AudioChunk): void {
    const timestampedChunk = {
      data: chunk.data,
      timestamp: Date.now(),
      sampleRate: chunk.sampleRate,
      channels: chunk.channels
    };

    // å¦‚æœæ­£åœ¨éŒ„éŸ³ï¼ŒåŒæ™‚åŠ å…¥éŒ„éŸ³ç·©è¡å€
    if (this.isRecording()) {
      this.recordingBuffer.push(timestampedChunk);
    }

    this.queue.push(timestampedChunk);

    // é™åˆ¶ä½‡åˆ—å¤§å°
    if (this.queue.length > this.maxSize) {
      this.queue.shift();
    }
    
    this.setSize(this.queue.length);
  }

  pop(): AudioChunk | null {
    const chunk = this.queue.shift() || null;
    this.setSize(this.queue.length);
    return chunk;
  }

  // é–‹å§‹éŒ„éŸ³ï¼šæ¸…ç©ºä½‡åˆ—ä¸¦é–‹å§‹è¨˜éŒ„
  startRecording(): void {
    this.clear();
    this.recordingBuffer = [];
    this.setIsRecording(true);
  }

  // åœæ­¢éŒ„éŸ³ï¼šè¿”å›éŒ„éŸ³ç·©è¡å€
  stopRecording(): AudioChunk[] {
    this.setIsRecording(false);
    const recording = [...this.recordingBuffer];
    this.recordingBuffer = [];
    return recording;
  }

  // ç²å–æ•´å€‹éŒ„éŸ³ç·©è¡å€ï¼ˆä¸æ¸…ç©ºï¼‰
  getRecordingBuffer(): AudioChunk[] {
    return [...this.recordingBuffer];
  }

  getRange(startTime: number, endTime: number): AudioChunk[] {
    return this.queue.filter(
      chunk => chunk.timestamp >= startTime && chunk.timestamp <= endTime
    );
  }

  clear(): void {
    this.queue = [];
    this.setSize(0);
  }

  // SolidJS éŸ¿æ‡‰å¼æ¥å£
  get size() {
    return this.getSize();
  }

  get recording() {
    return this.isRecording();
  }
}
```

### 3.3 ç„¡ç‹€æ…‹æœå‹™è¨­è¨ˆ

æ¯å€‹æœå‹™éµå¾ªå–®ä¸€è·è²¬åŸå‰‡ï¼š

```typescript
// services/microphone/capture.ts
export class MicrophoneCapture {
  private static instance: MicrophoneCapture;
  private stream: MediaStream | null = null;
  private audioContext: AudioContext | null = null;
  private processor: AudioWorkletNode | null = null;

  private constructor() {}

  static getInstance(): MicrophoneCapture {
    if (!MicrophoneCapture.instance) {
      MicrophoneCapture.instance = new MicrophoneCapture();
    }
    return MicrophoneCapture.instance;
  }

  async start(onData: (chunk: AudioChunk) => void): Promise<void> {
    // è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™
    this.stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        sampleRate: 16000,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true
      }
    });

    // å‰µå»º AudioContext
    this.audioContext = new AudioContext({ sampleRate: 16000 });
    
    // è¼‰å…¥ AudioWorklet
    await this.audioContext.audioWorklet.addModule('/audio-processor.js');
    
    // é€£æ¥è™•ç†å™¨
    const source = this.audioContext.createMediaStreamSource(this.stream);
    this.processor = new AudioWorkletNode(this.audioContext, 'audio-processor');
    
    // ç›£è½éŸ³è¨Šæ•¸æ“š
    this.processor.port.onmessage = (event) => {
      onData({
        data: event.data.buffer,
        sampleRate: 16000,
        channels: 1
      });
    };

    source.connect(this.processor);
    this.processor.connect(this.audioContext.destination);
  }

  stop(): void {
    this.processor?.disconnect();
    this.stream?.getTracks().forEach(track => track.stop());
    this.audioContext?.close();
    
    this.processor = null;
    this.stream = null;
    this.audioContext = null;
  }
}

// æ¨¡çµ„ç´šåˆ¥å–®ä¾‹
export const microphoneCapture = MicrophoneCapture.getInstance();
```

### 3.4 ASR Provider ä»‹é¢

çµ±ä¸€çš„ Provider ä»‹é¢è¨­è¨ˆï¼š

```typescript
// providers/base.ts
export interface ASRProvider {
  name: string;
  isAvailable(): Promise<boolean>;
  initialize(config?: any): Promise<void>;
  transcribe(audio: AudioData): Promise<TranscriptionResult>;
  transcribeStream(
    audioStream: Observable<AudioData>
  ): Observable<TranscriptionResult>;
  destroy(): Promise<void>;
}

// providers/webspeech/provider.ts
import { createSignal, onCleanup } from 'solid-js';

export class WebSpeechProvider implements ASRProvider {
  name = 'webspeech';
  private recognition: SpeechRecognition | null = null;
  private [getTranscript, setTranscript] = createSignal<TranscriptionResult | null>(null);

  async isAvailable(): Promise<boolean> {
    return 'webkitSpeechRecognition' in window || 
           'SpeechRecognition' in window;
  }

  async initialize(config: WebSpeechConfig): Promise<void> {
    const SpeechRecognition = 
      window.SpeechRecognition || window.webkitSpeechRecognition;
    
    this.recognition = new SpeechRecognition();
    this.recognition.continuous = config.continuous ?? true;
    this.recognition.interimResults = config.interimResults ?? true;
    this.recognition.lang = config.language ?? 'zh-TW';
  }

  // ä¸²æµè½‰è­¯ï¼ˆå³æ™‚ï¼‰
  async transcribeStream(onResult: (result: TranscriptionResult) => void): Promise<void> {
    if (!this.recognition) {
      throw new Error('WebSpeech not initialized');
    }

    this.recognition.onresult = (event) => {
      const result = event.results[event.resultIndex];
      const transcriptionResult = {
        text: result[0].transcript,
        isFinal: result.isFinal,
        confidence: result[0].confidence,
        timestamp: Date.now()
      };
      
      this.setTranscript(transcriptionResult);
      onResult(transcriptionResult);
    };

    this.recognition.onerror = (error) => {
      console.error('WebSpeech error:', error);
    };

    this.recognition.onend = () => {
      console.log('WebSpeech recognition ended');
    };

    this.recognition.start();
    
    // æ¸…ç†å‡½æ•¸
    onCleanup(() => {
      this.recognition?.stop();
    });
  }

  stop(): void {
    this.recognition?.stop();
  }

  // SolidJS éŸ¿æ‡‰å¼æ¥å£
  get currentTranscript() {
    return this.getTranscript();
  }

  // éä¸²æµæ¨¡å¼ä¸æ”¯æ´
  async transcribe(audio: AudioData): Promise<TranscriptionResult> {
    throw new Error('WebSpeech API only supports streaming mode');
  }

  async destroy(): Promise<void> {
    this.stop();
    this.recognition = null;
  }
}
```

## 4. æœå‹™å±¤æ¶æ§‹

### 4.1 åŸ·è¡Œæ¨¡å¼ç®¡ç†å™¨

åœ¨åˆå§‹åŒ–æ™‚æª¢æ¸¬ç€è¦½å™¨èƒ½åŠ›ï¼Œé¸æ“‡æœ€é©åˆçš„åŸ·è¡Œæ¨¡å¼ä¸¦å›ºå®šä½¿ç”¨ï¼š

```typescript
export class ExecutionModeManager {
  private capabilities: BrowserCapabilities;
  private executionChain: ExecutionMode[];
  
  async initialize(): Promise<ExecutionConfig> {
    // æª¢æ¸¬ç€è¦½å™¨èƒ½åŠ›ï¼ˆåªåœ¨åˆå§‹åŒ–æ™‚åŸ·è¡Œä¸€æ¬¡ï¼‰
    this.capabilities = await this.detectCapabilities();
    
    // æ±ºå®šå›ºå®šçš„åŸ·è¡Œæ¨¡å¼
    this.executionMode = this.determineExecutionMode();
    
    // è¿”å›å›ºå®šé…ç½®
    return this.getFixedConfig();
  }
  
  private async detectCapabilities(): Promise<BrowserCapabilities> {
    return {
      webWorker: typeof Worker !== 'undefined',
      sharedArrayBuffer: typeof SharedArrayBuffer !== 'undefined',
      webAssembly: typeof WebAssembly !== 'undefined',
      webGPU: await this.checkWebGPU(),
      webGL2: this.checkWebGL2(),
      simd: await this.checkSIMD(),
      threads: self.crossOriginIsolated || false,
      hardwareConcurrency: navigator.hardwareConcurrency || 1,
      deviceMemory: navigator.deviceMemory || 0
    };
  }
}

  private determineExecutionMode(): ExecutionMode {
    // æ ¹æ“šèƒ½åŠ›é¸æ“‡åŸ·è¡Œæ¨¡å¼ï¼ˆåˆå§‹åŒ–å¾Œä¸å†æ”¹è®Šï¼‰
    if (this.capabilities.webWorker && this.capabilities.threads) {
      console.log('Using worker-threaded mode (best performance)');
      return 'worker-threaded';
    }
    if (this.capabilities.webWorker) {
      console.warn('SharedArrayBuffer not available, using basic worker mode');
      return 'worker';
    }
    console.warn('Web Worker not supported, falling back to main thread');
    return 'main-thread';
  }
  
  getFixedConfig(): ExecutionConfig {
    // è¿”å›å›ºå®šçš„é…ç½®ï¼ˆä¸æœƒå‹•æ…‹æ”¹è®Šï¼‰
    return {
      mode: this.executionMode,
      onnxExecutionProviders: this.getONNXProviders(),
      workerPoolSize: Math.min(4, this.capabilities.hardwareConcurrency),
      enableWASMSIMD: this.capabilities.simd,
      enableWASMThreads: this.capabilities.threads,
      modelCaching: this.capabilities.deviceMemory > 4 ? 'memory' : 'indexeddb'
    };
  }
}

export const executionModeManager = new ExecutionModeManager();
```

### 4.2 éŸ³è¨Šç®¡ç·šæ•´åˆå™¨

æä¾›çµ±ä¸€çš„éŸ³è¨Šç®¡ç·šç®¡ç†ï¼Œä½¿ç”¨åˆå§‹åŒ–æ™‚æ±ºå®šçš„å›ºå®šé…ç½®ï¼š

```typescript
export class AudioPipelineIntegration {
  private audioContext: AudioContext;
  private workletNode: AudioWorkletNode;
  private executionMode: ExecutionConfig;
  
  async initialize(config: AudioPipelineConfig): Promise<void> {
    // 1. æª¢æŸ¥ç€è¦½å™¨ç›¸å®¹æ€§
    const compatibility = await this.checkBrowserCompatibility();
    
    // 2. åŸ·è¡ŒéŸ³è¨Šè¨ºæ–·
    const diagnostics = await this.diagnoseAudioCapabilities();
    
    // 3. ç²å–å›ºå®šåŸ·è¡Œæ¨¡å¼ï¼ˆåˆå§‹åŒ–æ™‚å·²æ±ºå®šï¼‰
    this.executionMode = executionModeManager.getFixedConfig();
    
    // 4. è¼‰å…¥ AudioWorkletï¼ˆå¦‚æœéœ€è¦ï¼‰
    if (this.executionMode.mode !== 'main-thread') {
      await this.loadAudioWorklet();
    }
  }
  
  private async loadAudioWorklet(): Promise<void> {
    const basePath = window.location.pathname.substring(
      0, 
      window.location.pathname.lastIndexOf('/') + 1
    );
    const workletPath = `${basePath}worklets/audio-processor.worklet.js`;
    
    await this.audioContext.audioWorklet.addModule(workletPath);
    
    this.workletNode = new AudioWorkletNode(
      this.audioContext,
      'audio-processor',
      {
        processorOptions: {
          sampleRate: 16000,
          frameSize: 1280, // 80ms chunks for wake word detection
          executionMode: this.executionMode.mode
        }
      }
    );
  }
}

export const audioPipeline = new AudioPipelineIntegration();
```

## 5. é…ç½®ç³»çµ±

### 4.1 é…ç½®çµæ§‹

```typescript
// config/types.ts
export interface WebASRConfig {
  // æ¨¡å¼é…ç½®
  mode: 'streaming' | 'non-streaming';
  
  // éŸ³è¨Šé…ç½®
  audio: {
    sampleRate: number;
    channels: number;
    bufferSize: number;
    queueMaxSize: number;
  };

  // æœå‹™é…ç½®
  services: {
    microphone: {
      enabled: boolean;
      echoCancellation?: boolean;
      noiseSuppression?: boolean;
    };
    
    vad: {
      enabled: boolean;
      model?: string;
      threshold?: number;
      minSpeechDuration?: number;
      maxSilenceDuration?: number;
    };
    
    wakeWord: {
      enabled: boolean;
      words?: string[];
      model?: string;
      threshold?: number;
    };
    
    denoise: {
      enabled: boolean;
      model?: string;
      strength?: number;
    };
    
    timer: {
      enabled: boolean;
      defaultDuration?: number;
    };
  };

  // Provider é…ç½®
  providers: {
    primary: 'webspeech' | 'whisper';
    webspeech?: {
      language: string;
      continuous: boolean;
      interimResults: boolean;
    };
    whisper?: {
      model: string;
      language: string;
      task: 'transcribe' | 'translate';
    };
  };

  // æ—¥èªŒé…ç½®
  logging: {
    level: 'debug' | 'info' | 'warn' | 'error';
    enabled: boolean;
  };
}
```

### 4.2 é è¨­é…ç½®

```typescript
// config/defaults.ts
export const defaultConfig: WebASRConfig = {
  mode: 'streaming',
  
  audio: {
    sampleRate: 16000,
    channels: 1,
    bufferSize: 4096,
    queueMaxSize: 100
  },

  services: {
    microphone: {
      enabled: true,
      echoCancellation: true,
      noiseSuppression: true
    },
    
    vad: {
      enabled: true,
      model: 'silero-vad',
      threshold: 0.5,
      minSpeechDuration: 250,
      maxSilenceDuration: 1000
    },
    
    wakeWord: {
      enabled: false,
      words: ['hey assistant'],
      threshold: 0.5
    },
    
    denoise: {
      enabled: false,
      strength: 0.7
    },
    
    timer: {
      enabled: false,
      defaultDuration: 30000
    }
  },

  providers: {
    primary: 'webspeech',
    webspeech: {
      language: 'zh-TW',
      continuous: true,
      interimResults: true
    }
  },

  logging: {
    level: 'info',
    enabled: true
  }
};
```

## 6. ä½¿ç”¨ç¯„ä¾‹

### 5.1 åŸºæœ¬ä½¿ç”¨

```javascript
// ESM å°å…¥
import { WebASRCore } from 'webasr-core';

// å‰µå»ºå¯¦ä¾‹
const asr = new WebASRCore({
  mode: 'streaming',
  providers: {
    primary: 'webspeech',
    webspeech: {
      language: 'zh-TW'
    }
  }
});

// ç›£è½äº‹ä»¶
asr.on('transcription', (result) => {
  console.log('è­˜åˆ¥çµæœ:', result.text);
  console.log('æ˜¯å¦æœ€çµ‚:', result.isFinal);
});

asr.on('error', (error) => {
  console.error('éŒ¯èª¤:', error);
});

// é–‹å§‹è­˜åˆ¥
await asr.start();

// åœæ­¢è­˜åˆ¥
asr.stop();
```

### 5.2 CDN ä½¿ç”¨

```html
<!DOCTYPE html>
<html>
<head>
  <script src="https://cdn.jsdelivr.net/npm/webasr-core/dist/webasr-core.umd.js"></script>
</head>
<body>
  <button id="start">é–‹å§‹éŒ„éŸ³</button>
  <button id="stop">åœæ­¢éŒ„éŸ³</button>
  <div id="result"></div>

  <script>
    const asr = new WebASRCore.WebASRCore({
      mode: 'streaming',
      providers: {
        primary: 'webspeech'
      }
    });

    asr.on('transcription', (result) => {
      document.getElementById('result').textContent = result.text;
    });

    document.getElementById('start').onclick = () => asr.start();
    document.getElementById('stop').onclick = () => asr.stop();
  </script>
</body>
</html>
```

### 5.3 é€²éšä½¿ç”¨ - å•Ÿç”¨æ‰€æœ‰æœå‹™

```typescript
import { WebASRCore } from 'webasr-core';

const asr = new WebASRCore({
  mode: 'non-streaming',
  
  services: {
    // å•Ÿç”¨ VAD
    vad: {
      enabled: true,
      threshold: 0.5,
      minSpeechDuration: 250
    },
    
    // å•Ÿç”¨å–šé†’è©
    wakeWord: {
      enabled: true,
      words: ['å°åŠ©æ‰‹', 'å˜¿ Siri'],
      threshold: 0.6
    },
    
    // å•Ÿç”¨é™å™ª
    denoise: {
      enabled: true,
      strength: 0.8
    },
    
    // å•Ÿç”¨è¨ˆæ™‚å™¨
    timer: {
      enabled: true,
      defaultDuration: 30000
    }
  },

  // ä½¿ç”¨ Whisper
  providers: {
    primary: 'whisper',
    whisper: {
      model: 'whisper-base',
      language: 'zh',
      task: 'transcribe'
    }
  }
});

// å–šé†’è©æª¢æ¸¬
asr.on('wake-word-detected', (word) => {
  console.log(`æª¢æ¸¬åˆ°å–šé†’è©: ${word}`);
});

// VAD äº‹ä»¶
asr.on('speech-start', () => {
  console.log('é–‹å§‹èªªè©±');
});

asr.on('speech-end', () => {
  console.log('åœæ­¢èªªè©±');
});

// è¨ˆæ™‚å™¨äº‹ä»¶
asr.on('timer-expired', () => {
  console.log('éŒ„éŸ³è¶…æ™‚');
  asr.stop();
});

await asr.start();
```

### 5.4 æª”æ¡ˆä¸Šå‚³è™•ç†

```typescript
// è™•ç†éŸ³è¨Šæª”æ¡ˆ
const fileInput = document.getElementById('file-input');

fileInput.addEventListener('change', async (event) => {
  const file = event.target.files[0];
  
  if (file) {
    // ä½¿ç”¨æª”æ¡ˆæ¨¡å¼
    const result = await asr.transcribeFile(file, {
      provider: 'whisper',
      language: 'zh'
    });
    
    console.log('è½‰éŒ„çµæœ:', result.text);
  }
});
```

## 7. æ¨¡å‹ç®¡ç†ç³»çµ±

### 7.1 æ¨¡å‹é è¼‰å…¥ç³»çµ±

åŸºæ–¼ POC å¯¦è¸ï¼Œæä¾›æ¨¡å‹é è¼‰å…¥ç­–ç•¥ï¼š

```typescript
export class ModelPreloader {
  private preloadedUrls: Set<string> = new Set();
  private preloadPromises: Map<string, Promise<any>> = new Map();
  private loadingStatus: Map<string, LoadingStatus> = new Map();
  
  /**
   * ä½¿ç”¨ link prefetch é è¼‰å…¥æ¨¡å‹
   */
  prefetchModel(modelPath: string): void {
    const files = this.getModelFiles(modelPath);
    
    files.forEach(file => {
      const fullUrl = this.getFullUrl(file);
      if (!this.preloadedUrls.has(fullUrl)) {
        // å‰µå»º link prefetch æ¨™ç±¤
        const link = document.createElement('link');
        link.rel = 'prefetch';
        link.href = fullUrl;
        link.as = 'fetch';
        link.crossOrigin = 'anonymous';
        document.head.appendChild(link);
        this.preloadedUrls.add(fullUrl);
      }
    });
  }
  
  /**
   * ä½¿ç”¨ fetch é è¼‰å…¥ä¸¦å¿«å–
   */
  async preloadModelWithCache(modelPath: string): Promise<boolean> {
    const files = this.getModelFiles(modelPath);
    const promises: Promise<Blob>[] = [];
    
    for (const file of files) {
      const fullUrl = this.getFullUrl(file);
      
      if (this.preloadPromises.has(fullUrl)) {
        promises.push(this.preloadPromises.get(fullUrl)!);
        continue;
      }
      
      const promise = this.fetchWithRetry(fullUrl, file);
      this.preloadPromises.set(fullUrl, promise);
      promises.push(promise);
    }
    
    try {
      await Promise.all(promises);
      console.log(`All files preloaded for ${modelPath}`);
      return true;
    } catch (error) {
      console.error('Failed to preload some files:', error);
      return false;
    }
  }
  
  /**
   * å¸¶é‡è©¦æ©Ÿåˆ¶çš„ fetch
   */
  private async fetchWithRetry(
    url: string, 
    fileName: string, 
    retries: number = 3
  ): Promise<Blob> {
    this.loadingStatus.set(fileName, { status: 'loading', progress: 0 });
    
    // ç™¼é€è¼‰å…¥é–‹å§‹äº‹ä»¶
    window.dispatchEvent(new CustomEvent('modelLoadStart', {
      detail: { modelName: fileName }
    }));
    
    for (let i = 0; i < retries; i++) {
      try {
        const response = await fetch(url, {
          method: 'GET',
          cache: 'force-cache', // å¼·åˆ¶ä½¿ç”¨å¿«å–
          mode: 'cors',
          credentials: 'omit'
        });
        
        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }
        
        // è¿½è¹¤ä¸‹è¼‰é€²åº¦
        const blob = await this.trackProgress(response, fileName);
        
        this.loadingStatus.set(fileName, { status: 'completed', progress: 100 });
        return blob;
      } catch (error) {
        console.warn(`Failed to load ${fileName} (attempt ${i + 1}/${retries}):`, error);
        if (i === retries - 1) throw error;
        await this.delay(Math.pow(2, i) * 1000); // æŒ‡æ•¸é€€é¿
      }
    }
    
    throw new Error(`Failed to load ${fileName} after ${retries} attempts`);
  }
  
  /**
   * è¿½è¹¤ä¸‹è¼‰é€²åº¦
   */
  private async trackProgress(
    response: Response, 
    fileName: string
  ): Promise<Blob> {
    const contentLength = response.headers.get('content-length');
    const total = parseInt(contentLength || '0', 10);
    
    if (!total || !response.body) {
      return response.blob();
    }
    
    const reader = response.body.getReader();
    const chunks: Uint8Array[] = [];
    let received = 0;
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      chunks.push(value);
      received += value.length;
      
      const progress = Math.min((received / total) * 100, 100);
      this.loadingStatus.set(fileName, { status: 'loading', progress });
      
      // ç™¼é€é€²åº¦äº‹ä»¶
      window.dispatchEvent(new CustomEvent('modelLoadProgress', {
        detail: { fileName, progress: Math.round(progress), received, total }
      }));
    }
    
    return new Blob(chunks);
  }
}

export const modelPreloader = new ModelPreloader();
```

## 7. æ¨¡å‹ç®¡ç†ç³»çµ±ï¼ˆåŸæœ‰å…§å®¹ï¼‰

### 6.1 æ¨¡å‹è¼‰å…¥ç­–ç•¥

WebASRCore æä¾›ä¸‰ç¨®æ¨¡å‹è¼‰å…¥æ–¹å¼ï¼š

1. **å…§å»ºæ¨¡å‹**ï¼šæ‰“åŒ…åœ¨åº«ä¸­çš„è¼•é‡ç´šæ¨¡å‹
2. **è‡ªå®šç¾©è·¯å¾‘**ï¼šç”¨æˆ¶æŒ‡å®šçš„æœ¬åœ°æª”æ¡ˆè·¯å¾‘æˆ–é ç«¯ URL
3. **Hugging Face**ï¼šè‡ªå‹•å¾ HF ä¸‹è¼‰ä¸¦å¿«å–

```typescript
// models/model-manager.ts
export interface ModelConfig {
  type: 'builtin' | 'custom' | 'huggingface';
  path?: string;  // æœ¬åœ°æª”æ¡ˆè·¯å¾‘ã€URL æˆ– HF æ¨¡å‹ ID
  cache?: boolean;  // æ˜¯å¦å¿«å–åˆ° IndexedDB
  quantized?: boolean;  // æ˜¯å¦ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬
}

export class ModelManager {
  private static instance: ModelManager;
  private modelCache = new Map<string, ArrayBuffer>();
  private db: IDBDatabase | null = null;

  private constructor() {
    this.initIndexedDB();
  }

  static getInstance(): ModelManager {
    if (!ModelManager.instance) {
      ModelManager.instance = new ModelManager();
    }
    return ModelManager.instance;
  }

  private async initIndexedDB(): Promise<void> {
    const request = indexedDB.open('WebASRCore', 1);
    
    request.onupgradeneeded = (event) => {
      const db = (event.target as IDBOpenDBRequest).result;
      if (!db.objectStoreNames.contains('models')) {
        db.createObjectStore('models', { keyPath: 'name' });
      }
    };

    this.db = await new Promise((resolve, reject) => {
      request.onsuccess = () => resolve(request.result);
      request.onerror = () => reject(request.error);
    });
  }

  async loadModel(name: string, config: ModelConfig): Promise<ArrayBuffer> {
    // æª¢æŸ¥è¨˜æ†¶é«”å¿«å–
    const cacheKey = `${name}-${config.type}-${config.path}`;
    if (this.modelCache.has(cacheKey)) {
      console.log(`Model ${name} loaded from memory cache`);
      return this.modelCache.get(cacheKey)!;
    }

    // æª¢æŸ¥ IndexedDB å¿«å–
    if (config.cache && this.db) {
      const cached = await this.getFromIndexedDB(cacheKey);
      if (cached) {
        console.log(`Model ${name} loaded from IndexedDB`);
        this.modelCache.set(cacheKey, cached);
        return cached;
      }
    }

    // è¼‰å…¥æ¨¡å‹
    let modelData: ArrayBuffer;
    
    switch (config.type) {
      case 'builtin':
        modelData = await this.loadBuiltinModel(name, config.quantized);
        break;
      
      case 'custom':
        if (!config.path) {
          throw new Error('Custom model requires a path');
        }
        modelData = await this.loadFromPathOrFile(config.path);
        break;
      
      case 'huggingface':
        if (!config.path) {
          throw new Error('Hugging Face model requires a model ID');
        }
        modelData = await this.loadFromHuggingFace(config.path, config.quantized);
        break;
      
      default:
        throw new Error(`Unknown model type: ${config.type}`);
    }

    // å¿«å–åˆ°è¨˜æ†¶é«”
    this.modelCache.set(cacheKey, modelData);

    // å¿«å–åˆ° IndexedDB
    if (config.cache && this.db) {
      await this.saveToIndexedDB(cacheKey, modelData);
    }

    return modelData;
  }

  private async loadBuiltinModel(name: string, quantized = false): Promise<ArrayBuffer> {
    // å…§å»ºæ¨¡å‹æ˜ å°„è¡¨
    const builtinModels = {
      'silero-vad': {
        normal: '/models/silero-vad/silero_vad.onnx',
        quantized: '/models/silero-vad/silero_vad_q8.onnx'
      },
      'openwakeword-hey': {
        normal: '/models/openwakeword/hey_assistant.onnx',
        quantized: '/models/openwakeword/hey_assistant_q8.onnx'
      },
      'whisper-tiny': {
        normal: '/models/whisper/whisper-tiny.onnx',
        quantized: '/models/whisper/whisper-tiny-q8.onnx'
      }
    };

    const modelPath = builtinModels[name];
    if (!modelPath) {
      throw new Error(`Unknown builtin model: ${name}`);
    }

    const url = quantized ? modelPath.quantized : modelPath.normal;
    return await this.loadFromPathOrFile(url);
  }

  private async loadFromPathOrFile(path: string): Promise<ArrayBuffer> {
    // æª¢æŸ¥æ˜¯å¦ç‚º File ç‰©ä»¶æˆ– Blob
    if (path instanceof File || path instanceof Blob) {
      return await path.arrayBuffer();
    }
    
    // æª¢æŸ¥æ˜¯å¦ç‚ºæœ¬åœ°æª”æ¡ˆè·¯å¾‘ï¼ˆFile Inputï¼‰
    if (path.startsWith('file://') || path.startsWith('blob:')) {
      // è™•ç†æœ¬åœ°æª”æ¡ˆ URL
      const response = await fetch(path);
      return await response.arrayBuffer();
    }
    
    // æª¢æŸ¥æ˜¯å¦ç‚ºç›¸å°è·¯å¾‘ï¼ˆç›¸å°æ–¼ç•¶å‰ç¶²ç«™ï¼‰
    if (!path.startsWith('http://') && !path.startsWith('https://')) {
      // ç›¸å°è·¯å¾‘ï¼Œæ§‹å»ºå®Œæ•´ URL
      const baseUrl = window.location.origin;
      const fullPath = path.startsWith('/') ? path : `/${path}`;
      path = `${baseUrl}${fullPath}`;
    }
    
    // å¾ URL è¼‰å…¥
    const response = await fetch(path);
    if (!response.ok) {
      throw new Error(`Failed to load model from ${path}: ${response.statusText}`);
    }
    return await response.arrayBuffer();
  }
  
  // æ”¯æ´å¾ File Input è¼‰å…¥æ¨¡å‹
  async loadFromFileInput(file: File): Promise<ArrayBuffer> {
    return await file.arrayBuffer();
  }

  private async loadFromHuggingFace(modelId: string, quantized = false): Promise<ArrayBuffer> {
    // Hugging Face CDN URL æ ¼å¼
    const baseUrl = 'https://huggingface.co';
    const quantizedSuffix = quantized ? '_q8' : '';
    
    // æ ¹æ“šæ¨¡å‹é¡å‹æ§‹å»º URL
    let url: string;
    
    if (modelId.includes('whisper')) {
      // Whisper æ¨¡å‹
      url = `${baseUrl}/${modelId}/resolve/main/onnx/model${quantizedSuffix}.onnx`;
    } else if (modelId.includes('silero')) {
      // Silero VAD
      url = `${baseUrl}/${modelId}/resolve/main/silero_vad${quantizedSuffix}.onnx`;
    } else if (modelId.includes('openwakeword')) {
      // OpenWakeWord
      const wordName = modelId.split('/').pop();
      url = `${baseUrl}/${modelId}/resolve/main/${wordName}${quantizedSuffix}.onnx`;
    } else {
      // é€šç”¨ ONNX æ¨¡å‹
      url = `${baseUrl}/${modelId}/resolve/main/model${quantizedSuffix}.onnx`;
    }

    console.log(`Loading model from Hugging Face: ${url}`);
    
    try {
      return await this.loadFromPathOrFile(url);
    } catch (error) {
      console.error(`Failed to load from HF, trying alternative URL...`);
      // å˜—è©¦å‚™ç”¨ URL æ ¼å¼
      const altUrl = `${baseUrl}/${modelId}/resolve/main/onnx/model.onnx`;
      return await this.loadFromPathOrFile(altUrl);
    }
  }

  private async getFromIndexedDB(key: string): Promise<ArrayBuffer | null> {
    if (!this.db) return null;

    const transaction = this.db.transaction(['models'], 'readonly');
    const store = transaction.objectStore('models');
    const request = store.get(key);

    return new Promise((resolve) => {
      request.onsuccess = () => {
        resolve(request.result?.data || null);
      };
      request.onerror = () => resolve(null);
    });
  }

  private async saveToIndexedDB(key: string, data: ArrayBuffer): Promise<void> {
    if (!this.db) return;

    const transaction = this.db.transaction(['models'], 'readwrite');
    const store = transaction.objectStore('models');
    
    await store.put({
      name: key,
      data: data,
      timestamp: Date.now(),
      size: data.byteLength
    });
  }

  // æ¸…ç†å¿«å–
  async clearCache(memory = true, indexed = true): Promise<void> {
    if (memory) {
      this.modelCache.clear();
    }
    
    if (indexed && this.db) {
      const transaction = this.db.transaction(['models'], 'readwrite');
      const store = transaction.objectStore('models');
      await store.clear();
    }
  }

  // ç²å–å¿«å–çµ±è¨ˆ
  async getCacheStats(): Promise<{
    memorySize: number;
    indexedDBSize: number;
    modelCount: number;
  }> {
    let memorySize = 0;
    for (const model of this.modelCache.values()) {
      memorySize += model.byteLength;
    }

    let indexedDBSize = 0;
    let modelCount = 0;
    
    if (this.db) {
      const transaction = this.db.transaction(['models'], 'readonly');
      const store = transaction.objectStore('models');
      const request = store.getAll();
      
      const models = await new Promise<any[]>((resolve) => {
        request.onsuccess = () => resolve(request.result);
        request.onerror = () => resolve([]);
      });
      
      modelCount = models.length;
      indexedDBSize = models.reduce((sum, m) => sum + m.size, 0);
    }

    return { memorySize, indexedDBSize, modelCount };
  }
}

// æ¨¡çµ„ç´šå–®ä¾‹
export const modelManager = ModelManager.getInstance();
```

### 6.2 æœå‹™ä¸­çš„æ¨¡å‹ä½¿ç”¨

```typescript
// services/vad/silero-vad.ts
import * as ort from 'onnxruntime-web';
import { modelManager, ModelConfig } from '../../models/model-manager';

export class SileroVAD {
  private static instance: SileroVAD;
  private session: ort.InferenceSession | null = null;
  private modelConfig: ModelConfig;

  private constructor() {
    // é è¨­ä½¿ç”¨å…§å»ºçš„é‡åŒ–æ¨¡å‹
    this.modelConfig = {
      type: 'builtin',
      quantized: true,
      cache: true
    };
  }

  static getInstance(): SileroVAD {
    if (!SileroVAD.instance) {
      SileroVAD.instance = new SileroVAD();
    }
    return SileroVAD.instance;
  }

  // å…è¨±ç”¨æˆ¶è¦†è“‹æ¨¡å‹é…ç½®
  async initialize(customConfig?: Partial<ModelConfig>): Promise<void> {
    // åˆä½µé…ç½®
    this.modelConfig = { ...this.modelConfig, ...customConfig };

    // è¼‰å…¥æ¨¡å‹
    const modelData = await modelManager.loadModel('silero-vad', this.modelConfig);

    // å‰µå»º ONNX Runtime session
    this.session = await ort.InferenceSession.create(modelData, {
      executionProviders: ['wasm'],  // ä½¿ç”¨ WASM backend
      graphOptimizationLevel: 'all'
    });

    console.log('Silero VAD initialized');
  }

  async detect(audioData: Float32Array): Promise<{
    isSpeech: boolean;
    confidence: number;
  }> {
    if (!this.session) {
      throw new Error('VAD not initialized');
    }

    // æº–å‚™è¼¸å…¥å¼µé‡
    const inputTensor = new ort.Tensor('float32', audioData, [1, audioData.length]);

    // åŸ·è¡Œæ¨ç†
    const results = await this.session.run({ input: inputTensor });
    
    // è§£æçµæœ
    const output = results.output.data as Float32Array;
    const confidence = output[0];
    
    return {
      isSpeech: confidence > 0.5,
      confidence: confidence
    };
  }
}

export const sileroVAD = SileroVAD.getInstance();
```

### 6.3 é…ç½®ä¸­çš„æ¨¡å‹è¨­å®š

```typescript
// ä½¿ç”¨ç¯„ä¾‹ 1: ä½¿ç”¨å…§å»ºæ¨¡å‹
const asr = new WebASRCore({
  services: {
    vad: {
      enabled: true,
      modelConfig: {
        type: 'builtin',
        quantized: true,  // ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬ä»¥æ¸›å°‘å¤§å°
        cache: true
      }
    }
  }
});

// ä½¿ç”¨ç¯„ä¾‹ 2: å¾æœ¬åœ°æª”æ¡ˆç³»çµ±è¼‰å…¥
const fileInput = document.getElementById('model-file') as HTMLInputElement;
fileInput.addEventListener('change', async (event) => {
  const file = event.target.files[0];
  
  const asr = new WebASRCore({
    services: {
      vad: {
        enabled: true,
        modelConfig: {
          type: 'custom',
          path: file,  // ç›´æ¥å‚³å…¥ File ç‰©ä»¶
          cache: true
        }
      }
    }
  });
});

// ä½¿ç”¨ç¯„ä¾‹ 3: å¾ç›¸å°è·¯å¾‘è¼‰å…¥ï¼ˆç›¸å°æ–¼ç¶²ç«™æ ¹ç›®éŒ„ï¼‰
const asr = new WebASRCore({
  services: {
    wakeWord: {
      enabled: true,
      modelConfig: {
        type: 'custom',
        path: '/assets/models/custom-wakeword.onnx',  // æœ¬åœ°ç›¸å°è·¯å¾‘
        cache: true
      }
    }
  }
});

// ä½¿ç”¨ç¯„ä¾‹ 4: å¾é ç«¯ URL è¼‰å…¥
const asr = new WebASRCore({
  services: {
    denoise: {
      enabled: true,
      modelConfig: {
        type: 'custom',
        path: 'https://example.com/models/rnnoise.wasm',  // é ç«¯ URL
        cache: true
      }
    }
  }
});

// ä½¿ç”¨ç¯„ä¾‹ 5: å¾ Hugging Face è¼‰å…¥
const asr = new WebASRCore({
  providers: {
    whisper: {
      modelConfig: {
        type: 'huggingface',
        path: 'openai/whisper-tiny',  // HF æ¨¡å‹ ID
        quantized: true,
        cache: true
      }
    }
  }
});

// å‹•æ…‹è¼‰å…¥æ¨¡å‹æª”æ¡ˆ
const modelFileInput = document.getElementById('upload-model') as HTMLInputElement;
modelFileInput.addEventListener('change', async (event) => {
  const file = event.target.files[0];
  if (file) {
    // ç›´æ¥ä½¿ç”¨ File ç‰©ä»¶
    const modelData = await modelManager.loadFromFileInput(file);
    
    // æˆ–è€…é€éé…ç½®
    await asr.services.vad.initialize({
      type: 'custom',
      path: file,
      cache: true
    });
  }
});
```

## 8. æ€§èƒ½å„ªåŒ–ç­–ç•¥

### 7.1 æ™ºæ…§å‹æ¨¡å‹é è¼‰å…¥

```typescript
class ModelPreloader {
  static async preloadEssentials(): Promise<void> {
    // é è¼‰å…¥å¸¸ç”¨çš„å°æ¨¡å‹
    const essentials = [
      { name: 'silero-vad', config: { type: 'builtin', quantized: true } },
      { name: 'openwakeword-hey', config: { type: 'builtin', quantized: true } }
    ];

    await Promise.all(
      essentials.map(m => modelManager.loadModel(m.name, m.config))
    );
  }

  static async preloadOnIdle(): Promise<void> {
    // åœ¨ç€è¦½å™¨ç©ºé–’æ™‚é è¼‰å…¥å¤§æ¨¡å‹
    if ('requestIdleCallback' in window) {
      requestIdleCallback(async () => {
        await modelManager.loadModel('whisper-tiny', {
          type: 'builtin',
          quantized: true,
          cache: true
        });
      });
    }
  }
}
```

### 7.2 Web Worker éš”é›¢

```typescript
// workers/vad.worker.ts
let vadModel: any = null;

self.onmessage = async (event) => {
  const { type, data } = event.data;

  switch (type) {
    case 'init':
      // è¼‰å…¥æ¨¡å‹
      vadModel = await loadVADModel(data.modelPath);
      self.postMessage({ type: 'ready' });
      break;

    case 'process':
      // è™•ç†éŸ³è¨Š
      const result = await vadModel.process(data.audio);
      self.postMessage({ 
        type: 'result', 
        data: { isSpeech: result.isSpeech, confidence: result.confidence }
      });
      break;
  }
};
```

### 7.3 éŸ³è¨Šç·©è¡å„ªåŒ–

```typescript
class OptimizedBuffer {
  private buffer: Float32Array;
  private writeIndex = 0;
  private readIndex = 0;

  constructor(size: number) {
    this.buffer = new Float32Array(size);
  }

  push(data: Float32Array): void {
    // ç’°å½¢ç·©è¡å€å¯¦ç¾
    for (let i = 0; i < data.length; i++) {
      this.buffer[this.writeIndex] = data[i];
      this.writeIndex = (this.writeIndex + 1) % this.buffer.length;
    }
  }

  read(size: number): Float32Array {
    const result = new Float32Array(size);
    for (let i = 0; i < size; i++) {
      result[i] = this.buffer[this.readIndex];
      this.readIndex = (this.readIndex + 1) % this.buffer.length;
    }
    return result;
  }
}
```

## 9. æ¸¬è©¦ç­–ç•¥

### 7.1 å–®å…ƒæ¸¬è©¦

```typescript
// tests/services/microphone.test.ts
describe('MicrophoneCapture', () => {
  it('should request correct audio constraints', async () => {
    const mockGetUserMedia = jest.fn();
    navigator.mediaDevices.getUserMedia = mockGetUserMedia;

    await microphoneCapture.start(() => {});

    expect(mockGetUserMedia).toHaveBeenCalledWith({
      audio: {
        sampleRate: 16000,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true
      }
    });
  });
});
```

### 7.2 æ•´åˆæ¸¬è©¦

```typescript
// tests/integration/pipeline.test.ts
describe('Audio Pipeline', () => {
  it('should process audio through complete pipeline', async () => {
    const asr = new WebASRCore(testConfig);
    const results: any[] = [];

    asr.on('transcription', (result) => {
      results.push(result);
    });

    // æ¨¡æ“¬éŸ³è¨Šè¼¸å…¥
    await simulateAudioInput(asr, testAudioFile);

    expect(results).toHaveLength(greaterThan(0));
    expect(results[results.length - 1].isFinal).toBe(true);
  });
});
```

## 10. éƒ¨ç½²å’Œç™¼å¸ƒ

### 8.1 NPM ç™¼å¸ƒé…ç½®

```json
{
  "name": "webasr-core",
  "version": "1.0.0",
  "description": "é›¶ä¼ºæœå™¨ä¾è³´çš„å‰ç«¯èªéŸ³è­˜åˆ¥æ ¸å¿ƒåº«",
  "main": "dist/webasr-core.umd.js",
  "module": "dist/webasr-core.esm.js",
  "types": "dist/types/index.d.ts",
  "exports": {
    ".": {
      "import": "./dist/webasr-core.esm.js",
      "require": "./dist/webasr-core.umd.js",
      "types": "./dist/types/index.d.ts"
    }
  },
  "files": [
    "dist",
    "models"
  ],
  "sideEffects": false,
  "scripts": {
    "build": "vite build",
    "test": "vitest",
    "lint": "eslint src",
    "type-check": "tsc --noEmit"
  },
  "keywords": [
    "speech-recognition",
    "asr",
    "voice",
    "audio",
    "webrtc",
    "whisper",
    "vad",
    "wake-word"
  ],
  "license": "MIT"
}
```

### 8.2 CDN é…ç½®

```javascript
// vite.config.js
export default {
  build: {
    lib: {
      entry: 'src/index.ts',
      name: 'WebASRCore',
      formats: ['es', 'umd']
    },
    rollupOptions: {
      external: [],
      output: {
        globals: {}
      }
    }
  }
};
```

## 11. Worker æ•´åˆæ¶æ§‹

### 11.1 Worker ç®¡ç†å™¨

åŸºæ–¼ POC å¯¦è¸ï¼Œæä¾›å®Œæ•´çš„ Worker ç®¡ç†æ¶æ§‹ï¼š

```typescript
export class WorkerManager {
  private workers: Map<string, Worker> = new Map();
  private pendingMessages: Map<string, PendingMessage> = new Map();
  
  /**
   * å‰µå»ºæˆ–ç²å– Worker
   */
  async getWorker(type: WorkerType): Promise<Worker> {
    if (this.workers.has(type)) {
      return this.workers.get(type)!;
    }
    
    const worker = await this.createWorker(type);
    this.workers.set(type, worker);
    return worker;
  }
  
  /**
   * å‰µå»º Worker
   */
  private async createWorker(type: WorkerType): Promise<Worker> {
    const basePath = window.location.pathname.replace(/\/[^\/]*$/, '/');
    const workerPath = `${basePath}workers/${type}.worker.js`;
    
    const worker = new Worker(workerPath, { type: 'module' });
    
    // è¨­å®šè¨Šæ¯è™•ç†
    worker.onmessage = (event) => {
      const data = event.data;
      
      // è™•ç†å¸¶ messageId çš„å›æ‡‰
      if (data.messageId && this.pendingMessages.has(data.messageId)) {
        const handler = this.pendingMessages.get(data.messageId)!;
        this.pendingMessages.delete(data.messageId);
        
        if (data.error) {
          handler.reject(new Error(data.error));
        } else {
          handler.resolve(data);
        }
      } else {
        // è™•ç†ä¸€èˆ¬è¨Šæ¯
        this.handleWorkerMessage(type, data);
      }
    };
    
    worker.onerror = (error) => {
      console.error(`[${type}] Worker error:`, error);
      this.handleWorkerError(type, error);
    };
    
    // åˆå§‹åŒ– Worker
    await this.sendMessage(worker, {
      type: 'initialize',
      config: this.getWorkerConfig(type)
    });
    
    return worker;
  }
  
  /**
   * ç™¼é€è¨Šæ¯çµ¦ Worker ä¸¦ç­‰å¾…å›æ‡‰
   */
  async sendMessage(worker: Worker, message: any): Promise<any> {
    return new Promise((resolve, reject) => {
      const messageId = this.generateMessageId();
      
      this.pendingMessages.set(messageId, { resolve, reject });
      
      worker.postMessage({
        ...message,
        messageId
      });
      
      // è¶…æ™‚è™•ç†
      setTimeout(() => {
        if (this.pendingMessages.has(messageId)) {
          this.pendingMessages.delete(messageId);
          reject(new Error('Worker message timeout'));
        }
      }, 30000); // 30 ç§’è¶…æ™‚
    });
  }
}

export const workerManager = new WorkerManager();
```

### 11.2 ML æ¨è«– Worker

å°ˆé–€è™•ç† ONNX Runtime æ¨è«–ï¼š

```typescript
// workers/ml-inference.worker.js
import * as ort from 'onnxruntime-web';

class MLInferenceWorker {
  private sessions: Map<string, ort.InferenceSession> = new Map();
  
  async handleMessage(event: MessageEvent) {
    const { type, data, messageId } = event.data;
    
    try {
      switch (type) {
        case 'initialize':
          await this.initialize(data);
          self.postMessage({ messageId, success: true });
          break;
          
        case 'loadModel':
          const session = await this.loadModel(data);
          self.postMessage({ messageId, sessionId: data.modelId });
          break;
          
        case 'inference':
          const result = await this.runInference(data);
          self.postMessage({ messageId, result });
          break;
          
        default:
          throw new Error(`Unknown message type: ${type}`);
      }
    } catch (error) {
      self.postMessage({
        messageId,
        error: error.message
      });
    }
  }
  
  private async loadModel(data: any): Promise<void> {
    const { modelId, modelPath, options } = data;
    
    const session = await ort.InferenceSession.create(
      modelPath,
      options
    );
    
    this.sessions.set(modelId, session);
  }
  
  private async runInference(data: any): Promise<any> {
    const { sessionId, inputs } = data;
    const session = this.sessions.get(sessionId);
    
    if (!session) {
      throw new Error(`Session ${sessionId} not found`);
    }
    
    // è½‰æ›è¼¸å…¥ç‚º ONNX Tensor
    const feeds: Record<string, ort.Tensor> = {};
    for (const [name, value] of Object.entries(inputs)) {
      feeds[name] = new ort.Tensor(
        value.type,
        value.data,
        value.dims
      );
    }
    
    // åŸ·è¡Œæ¨è«–
    const results = await session.run(feeds);
    
    // è½‰æ›è¼¸å‡º
    const outputs: Record<string, any> = {};
    for (const [name, tensor] of Object.entries(results)) {
      outputs[name] = {
        data: tensor.data,
        dims: tensor.dims,
        type: tensor.type
      };
    }
    
    return outputs;
  }
}

const worker = new MLInferenceWorker();
self.addEventListener('message', (e) => worker.handleMessage(e));
```

## 12. ç³»çµ±æ¶æ§‹åœ–

### 9.1 æ•´é«”æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 WebASR Core                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   FSM    â”‚â”€â”€â”€â”€â–¶â”‚  Store   â”‚                 â”‚
â”‚  â”‚ (XState) â”‚     â”‚(SolidJS) â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚       â–²                â”‚                        â”‚
â”‚       â”‚                â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚           Services Layer              â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚      â”‚
â”‚  â”‚  â”‚Microphoneâ”‚  â”‚   VAD    â”‚         â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚      â”‚
â”‚  â”‚  â”‚WakeWord  â”‚  â”‚  Timer   â”‚         â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚         Audio Processing              â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚      â”‚
â”‚  â”‚  â”‚AudioQueueâ”‚  â”‚ Buffer   â”‚         â”‚      â”‚
â”‚  â”‚  â”‚(Storage) â”‚  â”‚ Manager  â”‚         â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚           ASR Providers               â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚      â”‚
â”‚  â”‚  â”‚WebSpeech â”‚  â”‚ Whisper  â”‚         â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 éŸ³è¨Šè™•ç†æµç¨‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Audio Processing Pipeline               â”‚
â”‚                                                           â”‚
â”‚  Microphone â”€â”€â–¶ AudioQueue â”€â”€â–¶ BufferManager             â”‚
â”‚                     â”‚               â”‚                     â”‚
â”‚                     â”‚               â–¼                     â”‚
â”‚                     â”‚        OpenWakeWord Buffer         â”‚
â”‚                     â”‚         (1024 samples)             â”‚
â”‚                     â”‚               â”‚                     â”‚
â”‚                     â”‚               â–¼                     â”‚
â”‚                     â”‚         Wake Detected              â”‚
â”‚                     â”‚               â”‚                     â”‚
â”‚                     â–¼               â–¼                     â”‚
â”‚                Clear Queue    Start Recording            â”‚
â”‚                     â”‚               â”‚                     â”‚
â”‚                     â–¼               â–¼                     â”‚
â”‚                AudioQueue    BufferManager               â”‚
â”‚               (Recording)     (VAD Buffer)               â”‚
â”‚                     â”‚         (512 samples)              â”‚
â”‚                     â”‚               â”‚                     â”‚
â”‚                     â”‚               â–¼                     â”‚
â”‚                     â”‚          VAD Service               â”‚
â”‚                     â”‚               â”‚                     â”‚
â”‚                     â”‚               â–¼                     â”‚
â”‚                     â”‚       Silence Detected             â”‚
â”‚                     â”‚               â”‚                     â”‚
â”‚                     â”‚               â–¼                     â”‚
â”‚                     â”‚       Countdown Timer              â”‚
â”‚                     â”‚               â”‚                     â”‚
â”‚                     â”‚               â–¼                     â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ BufferManager            â”‚
â”‚                              (ASR Buffer)                â”‚
â”‚                                    â”‚                     â”‚
â”‚                                    â–¼                     â”‚
â”‚                              ASR Provider                â”‚
â”‚                         â”œâ”€â–¶ WebSpeech (4096/2048)      â”‚
â”‚                         â””â”€â–¶ Whisper (dynamic)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.3 AudioQueue èˆ‡ BufferManager å”ä½œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AudioQueue (æš«å­˜)                       â”‚
â”‚                                                          â”‚
â”‚  [chunk1][chunk2][chunk3][chunk4][chunk5][chunk6]...    â”‚
â”‚     â–²                                                    â”‚
â”‚     â”‚ push (from microphone)                            â”‚
â”‚     â”‚                                                    â”‚
â”‚  readIndex â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶                           â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ read (non-destructive)
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BufferManager Instances                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  OpenWakeWord Buffer:  [1024 samples] â”€â”€â–¶ Process       â”‚
â”‚                                                          â”‚
â”‚  VAD Buffer:          [512 samples]  â”€â”€â–¶ Process        â”‚
â”‚                                                          â”‚
â”‚  WebSpeech Buffer:    [4096 samples] â”€â”€â–¶ Stream         â”‚
â”‚                        (step: 2048)                      â”‚
â”‚                                                          â”‚
â”‚  Whisper Buffer:      [dynamic size] â”€â”€â–¶ Batch          â”‚
â”‚                        (1-30 seconds)                    â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.4 é—œéµè¨­è¨ˆèªªæ˜

#### AudioQueue è·è²¬
- **æš«å­˜éŸ³è¨Š**: æŒçºŒæ¥æ”¶ä¸¦å„²å­˜ä¾†è‡ªéº¥å…‹é¢¨çš„éŸ³è¨Šæ•¸æ“š
- **éç ´å£æ€§è®€å–**: ä½¿ç”¨ readIndex è¿½è¹¤è®€å–ä½ç½®ï¼Œä¸åˆªé™¤æ•¸æ“š
- **å¾ªç’°ç·©è¡**: ç•¶é”åˆ°æœ€å¤§å®¹é‡æ™‚ï¼Œä½¿ç”¨ FIFO ç­–ç•¥
- **æ¸…ç©ºæ©Ÿåˆ¶**: å–šé†’è©è§¸ç™¼æ™‚æ¸…ç©ºä½‡åˆ—ï¼Œé–‹å§‹æ–°çš„éŒ„éŸ³æ®µ

#### BufferManager è·è²¬
- **çª—å£ç®¡ç†**: æ ¹æ“šä¸åŒæœå‹™éœ€æ±‚ï¼Œæä¾›é©ç•¶å¤§å°çš„æ•¸æ“šçª—å£
- **æ¨¡å¼æ”¯æ´**:
  - Fixed: å›ºå®šå¤§å°çª—å£ï¼ˆVAD: 512, OpenWakeWord: 1024ï¼‰
  - Sliding: æ»‘å‹•çª—å£ï¼ˆWebSpeech: 4096/2048ï¼‰
  - Dynamic: å‹•æ…‹ç´¯ç©ï¼ˆWhisper: 1-30ç§’ï¼‰
- **å¾ AudioQueue å–å€¼**: éç ´å£æ€§åœ°å¾ AudioQueue è®€å–æ•¸æ“š
- **å°±ç·’æª¢æŸ¥**: åˆ¤æ–·æ˜¯å¦æœ‰è¶³å¤ æ•¸æ“šä¾›æœå‹™è™•ç†

## 10. é–‹ç™¼è·¯ç·šåœ–

### Phase 1 - MVP (ç¬¬ä¸€éšæ®µ)
- [x] æ ¸å¿ƒæ¶æ§‹è¨­è¨ˆ
- [ ] FSM ç‹€æ…‹æ©Ÿå¯¦ç¾
- [ ] éŸ³è¨Šä½‡åˆ—å’Œç·©è¡ç®¡ç†
- [ ] éº¥å…‹é¢¨æ“·å–æœå‹™
- [ ] WebSpeech API æ•´åˆ
- [ ] åŸºæœ¬é…ç½®ç³»çµ±

### Phase 2 - é€²éšåŠŸèƒ½
- [ ] VAD æœå‹™å¯¦ç¾ï¼ˆSilero ONNXï¼‰
- [ ] å–šé†’è©æª¢æ¸¬ï¼ˆOpenWakeWordï¼‰
- [ ] Whisper æ•´åˆï¼ˆTransformers.jsï¼‰
- [ ] Web Worker å„ªåŒ–
- [ ] é™å™ªæœå‹™ï¼ˆRNNoise WASMï¼‰

### Phase 3 - ç”Ÿç”¢å°±ç·’
- [ ] å®Œæ•´æ¸¬è©¦è¦†è“‹
- [ ] æ€§èƒ½å„ªåŒ–
- [ ] æ–‡æª”å®Œå–„
- [ ] ç¯„ä¾‹æ‡‰ç”¨
- [ ] CI/CD è¨­ç½®
- [ ] NPM ç™¼å¸ƒ

### Phase 4 - ç”Ÿæ…‹ç³»çµ±
- [ ] React Hooks
- [ ] Vue Composables  
- [ ] Angular Service
- [ ] æ’ä»¶ç³»çµ±
- [ ] è‡ªå®šç¾© Provider æ”¯æ´

## 10. æŠ€è¡“æŒ‘æˆ°å’Œè§£æ±ºæ–¹æ¡ˆ

### 10.1 æ¨¡å‹å¤§å°å•é¡Œ

**æŒ‘æˆ°**ï¼šML æ¨¡å‹æª”æ¡ˆè¼ƒå¤§ï¼Œå½±éŸ¿è¼‰å…¥é€Ÿåº¦

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- æ¨¡å‹é‡åŒ–ï¼ˆINT8ï¼‰
- åˆ†å±¤è¼‰å…¥ï¼ˆæŒ‰éœ€è¼‰å…¥ï¼‰
- CDN è¨—ç®¡ + å¿«å–ç­–ç•¥
- æä¾›å¤šç¨®æ¨¡å‹å¤§å°é¸é …

### 10.2 è·¨ç€è¦½å™¨å…¼å®¹æ€§

**æŒ‘æˆ°**ï¼šä¸åŒç€è¦½å™¨ API æ”¯æ´åº¦ä¸ä¸€

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- Polyfill ç­–ç•¥
- åŠŸèƒ½æª¢æ¸¬ + å„ªé›…é™ç´š
- å¤š Provider å‚™é¸æ–¹æ¡ˆ

### 10.3 å¯¦æ™‚æ€§èƒ½è¦æ±‚

**æŒ‘æˆ°**ï¼šéŸ³è¨Šè™•ç†éœ€è¦ä½å»¶é²

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- AudioWorklet è™•ç†éŸ³è¨Š
- Web Worker é‹è¡Œ ML æ¨ç†
- ç’°å½¢ç·©è¡å€å„ªåŒ–
- WebAssembly åŠ é€Ÿ

## 11. å®‰å…¨æ€§è€ƒé‡

- **éš±ç§ä¿è­·**ï¼šæ‰€æœ‰è™•ç†æœ¬åœ°å®Œæˆï¼Œç„¡æ•¸æ“šä¸Šå‚³
- **æ¬Šé™ç®¡ç†**ï¼šæ˜ç¢ºçš„éº¥å…‹é¢¨æ¬Šé™è«‹æ±‚æµç¨‹
- **éŒ¯èª¤è™•ç†**ï¼šå®Œå–„çš„éŒ¯èª¤é‚Šç•Œå’Œé™ç´šç­–ç•¥
- **è³‡æºæ¸…ç†**ï¼šè‡ªå‹•é‡‹æ”¾éŸ³è¨Šè³‡æºå’Œè¨˜æ†¶é«”

## 12. çµè«–

WebASRCore é€šéæ‰¿è¥² ASRHub çš„å„ªç§€æ¶æ§‹è¨­è¨ˆï¼Œä¸¦é‡å°å‰ç«¯ç’°å¢ƒé€²è¡Œå„ªåŒ–ï¼Œæä¾›äº†ä¸€å€‹å¼·å¤§ã€éˆæ´»ä¸”æ˜“ç”¨çš„èªéŸ³è­˜åˆ¥è§£æ±ºæ–¹æ¡ˆã€‚å®ƒä¸åƒ…ä¿è­·ç”¨æˆ¶éš±ç§ï¼Œé‚„æä¾›äº†å‡ºè‰²çš„é–‹ç™¼é«”é©—å’Œæ€§èƒ½è¡¨ç¾ã€‚

### æ ¸å¿ƒå„ªå‹¢ç¸½çµ

1. **é›¶ä¼ºæœå™¨æˆæœ¬**ï¼šå®Œå…¨å®¢æˆ¶ç«¯è™•ç†
2. **å³æ’å³ç”¨**ï¼šç°¡å–®çš„ APIï¼Œè±å¯Œçš„é…ç½®é¸é …
3. **æ¼¸é€²å¼æ¶æ§‹**ï¼šæŒ‰éœ€å•Ÿç”¨æœå‹™å’ŒåŠŸèƒ½
4. **éŸ¿æ‡‰å¼ç³»çµ±**ï¼šåŸºæ–¼ SolidJS çš„ç´°ç²’åº¦éŸ¿æ‡‰å¼æ¶æ§‹
5. **ç”Ÿæ…‹å‹å¥½**ï¼šæ”¯æ´ä¸»æµå‰ç«¯æ¡†æ¶
6. **æœªä¾†å°±ç·’**ï¼šæ¨¡çµ„åŒ–è¨­è¨ˆä¾¿æ–¼æ“´å±•

### æ ¸å¿ƒéŸ³è¨Šè™•ç†æµç¨‹

1. **æŒçºŒç›£è½**ï¼šéº¥å…‹é¢¨éŸ³è¨ŠæŒçºŒå‚³é€çµ¦ OpenWakeWord
2. **å–šé†’è§¸ç™¼**ï¼šæª¢æ¸¬åˆ°å–šé†’è©å¾Œæ¸…ç©ºä½‡åˆ—ï¼Œé–‹å§‹æ–°çš„éŒ„éŸ³æ®µ
3. **VAD ç›£æ¸¬**ï¼šåŒæ™‚å•Ÿå‹• VAD æª¢æ¸¬èªéŸ³æ´»å‹•
4. **éœéŸ³æª¢æ¸¬**ï¼šç•¶ VAD æª¢æ¸¬åˆ°éœéŸ³æ™‚å•Ÿå‹•å€’æ•¸è¨ˆæ™‚
5. **å€’æ•¸è¨ˆæ™‚**ï¼šå€’æ•¸æœŸé–“è‹¥é‡æ–°æª¢æ¸¬åˆ°èªéŸ³å‰‡å–æ¶ˆå€’æ•¸
6. **è½‰è­¯è™•ç†**ï¼š
   - **ä¸²æµæ¨¡å¼**ï¼šå³æ™‚å‚³é€çµ¦ Web Speech API
   - **éä¸²æµæ¨¡å¼**ï¼šå€’æ•¸çµæŸå¾Œå°‡æ•´å€‹éŒ„éŸ³ä½‡åˆ—å‚³é€çµ¦ Whisper
7. **å¾ªç’°ç›£è½**ï¼šå®Œæˆè½‰è­¯å¾Œè‡ªå‹•è¿”å›å–šé†’è©ç›£è½ç‹€æ…‹

### SolidJS å„ªå‹¢

- **ç´°ç²’åº¦éŸ¿æ‡‰å¼**ï¼šåªæ›´æ–°çœŸæ­£æ”¹è®Šçš„éƒ¨åˆ†ï¼Œæœ€å°åŒ–æ¸²æŸ“é–‹éŠ·
- **è‡ªå‹•ä¾è³´è¿½è¹¤**ï¼šç„¡éœ€æ‰‹å‹•ç®¡ç†è¨‚é–±å’Œå–æ¶ˆè¨‚é–±
- **è¼•é‡ç´š**ï¼šæ¯” RxJS æ›´å°çš„ bundle size
- **ç›´è¦º API**ï¼šæ›´ç°¡å–®çš„éŸ¿æ‡‰å¼ç¨‹å¼è¨­è¨ˆæ¨¡å‹

é€éé€™å€‹è¨­è¨ˆï¼Œé–‹ç™¼è€…å¯ä»¥å¿«é€Ÿæ§‹å»ºå…·æœ‰èªéŸ³è­˜åˆ¥èƒ½åŠ›çš„ Web æ‡‰ç”¨ï¼Œç„¡éœ€æ“”å¿ƒå¾Œç«¯åŸºç¤è¨­æ–½å’Œéš±ç§å•é¡Œã€‚

---

*æœ¬è¨­è¨ˆæ–‡æª”åŸºæ–¼ ASRHub v0.3.0 æ¶æ§‹ç†å¿µ*
*æ–‡æª”ç‰ˆæœ¬: 1.0.0*
*æ›´æ–°æ—¥æœŸ: 2025*