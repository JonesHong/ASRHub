#!/usr/bin/env python3
"""
Pipeline æ•´åˆæ¸¬è©¦å·¥å…·
æ¸¬è©¦ WakeWord â†’ VAD â†’ Recording çš„å®Œæ•´æµç¨‹
ä»¥åŠå¤š Operator ä¸²è¯åŠŸèƒ½
"""

import asyncio
import sys
import os
import time
import numpy as np
import pyaudio
from typing import Dict, Any, Optional, List
from pathlib import Path
import psutil
import queue
import threading

# æ·»åŠ  src åˆ°è·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# åªåœ¨éœ€è¦ç¹ªè£½æ•ˆèƒ½åœ–è¡¨æ™‚å°å…¥ matplotlib
try:
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False

from src.pipeline.manager import PipelineManager
from src.pipeline.operators.wakeword import OpenWakeWordOperator
from src.pipeline.operators.vad import SileroVADOperator
from src.pipeline.operators.recording import RecordingOperator
from src.pipeline.operators.sample_rate import SampleRateAdjustmentOperator
from src.core.fsm import StateMachine, State
from src.utils.logger import logger

# ä½¿ç”¨çµ±ä¸€çš„è¦–è¦ºåŒ–å·¥å…·
from src.utils.visualization import PipelineVisualization


class PipelineIntegrationTester:
    """Pipeline æ•´åˆæ¸¬è©¦å™¨"""
    
    def __init__(self):
        # Pipeline ç®¡ç†å™¨
        self.pipeline_manager = PipelineManager()
        
        # éŸ³è¨Šåƒæ•¸
        self.sample_rate = 16000
        self.channels = 1
        self.chunk_size = 1280
        self.format = pyaudio.paInt16
        
        # PyAudio
        self.p = pyaudio.PyAudio()
        self.stream = None
        self.is_running = False
        
        # æ¸¬è©¦çµæœ
        self.test_results = []
        
        # è¦–è¦ºåŒ–
        self.visualization = PipelineVisualization()
        
        # æ•ˆèƒ½ç›£æ§
        self.process_monitor = psutil.Process()
        self.performance_data = {
            'cpu': [],
            'memory': [],
            'latency': [],
            'timestamps': []
        }
    
    async def setup(self):
        """è¨­å®šæ¸¬è©¦ç’°å¢ƒ"""
        logger.info("è¨­å®š Pipeline æ¸¬è©¦ç’°å¢ƒ...")
        
        try:
            # åˆå§‹åŒ– Pipeline ç®¡ç†å™¨
            await self.pipeline_manager.start()
            
            logger.info("âœ“ Pipeline æ¸¬è©¦ç’°å¢ƒè¨­å®šå®Œæˆ")
            
        except Exception as e:
            logger.error(f"è¨­å®šå¤±æ•—: {e}")
            raise
    
    async def cleanup(self):
        """æ¸…ç†æ¸¬è©¦ç’°å¢ƒ"""
        logger.info("æ¸…ç†æ¸¬è©¦ç’°å¢ƒ...")
        
        try:
            if self.stream:
                self.stream.stop_stream()
                self.stream.close()
            
            self.p.terminate()
            
            # åœæ­¢æ‰€æœ‰ pipelines
            await self.pipeline_manager.stop()
            
            logger.info("âœ“ æ¸¬è©¦ç’°å¢ƒæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¸…ç†éŒ¯èª¤: {e}")
    
    async def test_basic_pipeline(self):
        """æ¸¬è©¦åŸºæœ¬ Pipeline åŠŸèƒ½"""
        logger.info("\n=== æ¸¬è©¦åŸºæœ¬ Pipeline åŠŸèƒ½ ===")
        
        # å‰µå»ºç°¡å–® pipeline: SampleRate â†’ VAD
        pipeline_config = {
            'name': 'basic_pipeline',
            'operators': [
                {
                    'type': 'sample_rate_adjustment',
                    'config': {
                        'target_rate': 16000,
                        'quality': 'high'
                    }
                },
                {
                    'type': 'vad',
                    'config': {
                        'threshold': 0.5,
                        'min_silence_duration': 0.5
                    }
                }
            ]
        }
        
        pipeline_id = await self.pipeline_manager.create_pipeline(pipeline_config)
        
        # ç”Ÿæˆæ¸¬è©¦éŸ³è¨Š
        test_audio = self._generate_test_audio(3.0)
        
        # è™•ç†éŸ³è¨Š
        start_time = time.time()
        
        chunk_size_bytes = self.chunk_size * 2
        for i in range(0, len(test_audio), chunk_size_bytes):
            chunk = test_audio[i:i + chunk_size_bytes]
            result = await self.pipeline_manager.process(pipeline_id, chunk)
            
        processing_time = time.time() - start_time
        
        # ç²å– pipeline çµ±è¨ˆ
        stats = self.pipeline_manager.get_pipeline_stats(pipeline_id)
        
        result = {
            'test_name': 'åŸºæœ¬ Pipeline',
            'pipeline_id': pipeline_id,
            'processing_time': processing_time,
            'processed_chunks': stats.get('processed_chunks', 0),
            'success': True
        }
        
        self.test_results.append(result)
        logger.info(f"åŸºæœ¬ Pipeline æ¸¬è©¦å®Œæˆï¼Œè™•ç†æ™‚é–“: {processing_time:.3f}s")
        
        # æ¸…ç†
        await self.pipeline_manager.remove_pipeline(pipeline_id)
    
    async def test_complete_pipeline(self):
        """æ¸¬è©¦å®Œæ•´ Pipeline (WakeWord â†’ VAD â†’ Recording)"""
        logger.info("\n=== æ¸¬è©¦å®Œæ•´ Pipeline ===")
        
        # å‰µå»ºå®Œæ•´ pipeline
        pipeline_config = {
            'name': 'complete_pipeline',
            'operators': [
                {
                    'type': 'sample_rate_adjustment',
                    'config': {
                        'target_rate': 16000
                    }
                },
                {
                    'type': 'wakeword',
                    'config': {
                        'model_path': 'models/hi_kmu_0721.onnx',
                        'threshold': 0.5
                    }
                },
                {
                    'type': 'vad',
                    'config': {
                        'threshold': 0.5,
                        'min_silence_duration': 0.5
                    }
                },
                {
                    'type': 'recording',
                    'config': {
                        'vad_controlled': True,
                        'silence_countdown': 1.8,
                        'storage': {
                            'type': 'memory'
                        }
                    }
                }
            ]
        }
        
        pipeline_id = await self.pipeline_manager.create_pipeline(pipeline_config)
        
        # ç²å– pipeline åƒè€ƒ
        pipeline = self.pipeline_manager.pipelines.get(pipeline_id)
        
        # è¨­å®šäº‹ä»¶è™•ç†
        wake_detected = False
        recording_completed = False
        
        async def on_wake(event):
            nonlocal wake_detected
            wake_detected = True
            logger.info("Pipeline æª¢æ¸¬åˆ°å–šé†’è©")
        
        async def on_recording(event):
            nonlocal recording_completed
            recording_completed = True
            logger.info("Pipeline éŒ„éŸ³å®Œæˆ")
        
        # è¨»å†Šäº‹ä»¶è™•ç†å™¨
        # TODO: å¯¦ä½œäº‹ä»¶ç³»çµ±
        
        # æ¸¬è©¦å ´æ™¯ï¼šæ¨¡æ“¬å–šé†’è© â†’ èªéŸ³ â†’ éœéŸ³
        logger.info("æ¨¡æ“¬å–šé†’è©è§¸ç™¼å ´æ™¯...")
        
        # é€™è£¡æ‡‰è©²ä½¿ç”¨å¯¦éš›çš„å–šé†’è©éŸ³è¨Š
        # ç‚ºäº†æ¸¬è©¦ï¼Œæˆ‘å€‘ä½¿ç”¨æ¨¡æ“¬éŸ³è¨Š
        test_duration = 5.0
        test_audio = self._generate_speech(test_duration)
        
        # è™•ç†éŸ³è¨Š
        chunk_size_bytes = self.chunk_size * 2
        for i in range(0, len(test_audio), chunk_size_bytes):
            chunk = test_audio[i:i + chunk_size_bytes]
            await self.pipeline_manager.process(pipeline_id, chunk)
            await asyncio.sleep(0.032)
        
        result = {
            'test_name': 'å®Œæ•´ Pipeline',
            'pipeline_id': pipeline_id,
            'wake_detected': wake_detected,
            'recording_completed': recording_completed,
            'success': True
        }
        
        self.test_results.append(result)
        
        # æ¸…ç†
        await self.pipeline_manager.remove_pipeline(pipeline_id)
    
    async def test_multiple_pipelines(self):
        """æ¸¬è©¦å¤šå€‹ Pipeline ä¸¦è¡Œé‹è¡Œ"""
        logger.info("\n=== æ¸¬è©¦å¤šå€‹ Pipeline ä¸¦è¡Œ ===")
        
        num_pipelines = 3
        pipeline_ids = []
        
        # å‰µå»ºå¤šå€‹ pipeline
        for i in range(num_pipelines):
            config = {
                'name': f'parallel_pipeline_{i}',
                'operators': [
                    {
                        'type': 'vad',
                        'config': {
                            'threshold': 0.5 + i * 0.1  # ä¸åŒçš„é–¾å€¼
                        }
                    }
                ]
            }
            
            pipeline_id = await self.pipeline_manager.create_pipeline(config)
            pipeline_ids.append(pipeline_id)
        
        # ä¸¦è¡Œè™•ç†éŸ³è¨Š
        test_audio = self._generate_speech_with_silence(5.0)
        chunk_size_bytes = self.chunk_size * 2
        
        tasks = []
        for i in range(0, len(test_audio), chunk_size_bytes):
            chunk = test_audio[i:i + chunk_size_bytes]
            
            # æ¯å€‹ pipeline è™•ç†ç›¸åŒçš„éŸ³è¨Š
            for pipeline_id in pipeline_ids:
                task = self.pipeline_manager.process(pipeline_id, chunk)
                tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # çµ±è¨ˆæˆåŠŸç‡
        success_count = sum(1 for r in results if not isinstance(r, Exception))
        total_tasks = len(tasks)
        
        result = {
            'test_name': 'å¤š Pipeline ä¸¦è¡Œ',
            'num_pipelines': num_pipelines,
            'total_tasks': total_tasks,
            'success_count': success_count,
            'success_rate': success_count / total_tasks,
            'success': success_count == total_tasks
        }
        
        self.test_results.append(result)
        logger.info(f"ä¸¦è¡Œæ¸¬è©¦å®Œæˆï¼ŒæˆåŠŸç‡: {result['success_rate']:.2%}")
        
        # æ¸…ç†
        for pipeline_id in pipeline_ids:
            await self.pipeline_manager.remove_pipeline(pipeline_id)
    
    async def test_error_recovery(self):
        """æ¸¬è©¦éŒ¯èª¤æ¢å¾©èƒ½åŠ›"""
        logger.info("\n=== æ¸¬è©¦éŒ¯èª¤æ¢å¾© ===")
        
        # å‰µå»ºåŒ…å«æ•…éšœ operator çš„ pipeline
        pipeline_config = {
            'name': 'error_test_pipeline',
            'operators': [
                {
                    'type': 'vad',
                    'config': {
                        'threshold': 0.5
                    }
                },
                {
                    'type': 'faulty_operator',  # ä¸å­˜åœ¨çš„ operator
                    'config': {}
                }
            ]
        }
        
        # å˜—è©¦å‰µå»ºæ‡‰è©²å¤±æ•—çš„ pipeline
        try:
            pipeline_id = await self.pipeline_manager.create_pipeline(pipeline_config)
            pipeline_created = True
        except Exception as e:
            pipeline_created = False
            logger.info(f"Pipeline å‰µå»ºå¤±æ•—ï¼ˆé æœŸè¡Œç‚ºï¼‰: {e}")
        
        # å‰µå»ºæ­£å¸¸çš„ pipeline
        normal_config = {
            'name': 'normal_pipeline',
            'operators': [
                {
                    'type': 'vad',
                    'config': {'threshold': 0.5}
                }
            ]
        }
        
        pipeline_id = await self.pipeline_manager.create_pipeline(normal_config)
        
        # æ¸¬è©¦è™•ç†ç„¡æ•ˆè³‡æ–™
        invalid_data = b"invalid_audio_data"
        error_occurred = False
        
        try:
            await self.pipeline_manager.process(pipeline_id, invalid_data)
        except Exception as e:
            error_occurred = True
            logger.info(f"è™•ç†ç„¡æ•ˆè³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼ˆé æœŸè¡Œç‚ºï¼‰: {e}")
        
        # ç¢ºèª pipeline ä»ç„¶å¯ç”¨
        valid_audio = self._generate_silence(0.1)
        can_process_after_error = True
        
        try:
            await self.pipeline_manager.process(pipeline_id, valid_audio)
        except Exception:
            can_process_after_error = False
        
        result = {
            'test_name': 'éŒ¯èª¤æ¢å¾©',
            'faulty_pipeline_rejected': not pipeline_created,
            'error_on_invalid_data': error_occurred,
            'recovery_after_error': can_process_after_error,
            'success': not pipeline_created and can_process_after_error
        }
        
        self.test_results.append(result)
        
        # æ¸…ç†
        await self.pipeline_manager.remove_pipeline(pipeline_id)
    
    async def test_performance_stress(self):
        """å£“åŠ›æ¸¬è©¦å’Œæ•ˆèƒ½ç›£æ§"""
        logger.info("\n=== å£“åŠ›æ¸¬è©¦ ===")
        
        # å‰µå»ºé«˜è² è¼‰ pipeline
        pipeline_config = {
            'name': 'stress_test_pipeline',
            'operators': [
                {'type': 'sample_rate_adjustment', 'config': {'target_rate': 16000}},
                {'type': 'vad', 'config': {'threshold': 0.5}},
                {'type': 'recording', 'config': {'storage': {'type': 'memory'}}}
            ]
        }
        
        pipeline_id = await self.pipeline_manager.create_pipeline(pipeline_config)
        
        # æ¸¬è©¦åƒæ•¸
        test_duration = 10.0  # ç§’
        chunk_duration = self.chunk_size / self.sample_rate
        total_chunks = int(test_duration / chunk_duration)
        
        # é‡ç½®æ•ˆèƒ½è³‡æ–™
        self.performance_data = {
            'cpu': [],
            'memory': [],
            'latency': [],
            'timestamps': []
        }
        
        logger.info(f"é–‹å§‹ {test_duration}s å£“åŠ›æ¸¬è©¦...")
        
        # ç”Ÿæˆæ¸¬è©¦éŸ³è¨Š
        test_audio = self._generate_speech_with_silence(test_duration)
        chunk_size_bytes = self.chunk_size * 2
        
        # è™•ç†éŸ³è¨Šä¸¦ç›£æ§æ•ˆèƒ½
        start_time = time.time()
        
        for i in range(0, len(test_audio), chunk_size_bytes):
            chunk = test_audio[i:i + chunk_size_bytes]
            
            # è¨˜éŒ„è™•ç†å‰ç‹€æ…‹
            chunk_start = time.time()
            cpu_percent = self.process_monitor.cpu_percent(interval=0)
            memory_mb = self.process_monitor.memory_info().rss / 1024 / 1024
            
            # è™•ç†éŸ³è¨Š
            await self.pipeline_manager.process(pipeline_id, chunk)
            
            # è¨˜éŒ„è™•ç†å»¶é²
            latency = time.time() - chunk_start
            
            # ä¿å­˜æ•ˆèƒ½è³‡æ–™
            self.performance_data['cpu'].append(cpu_percent)
            self.performance_data['memory'].append(memory_mb)
            self.performance_data['latency'].append(latency * 1000)  # ms
            self.performance_data['timestamps'].append(time.time() - start_time)
        
        total_time = time.time() - start_time
        
        # è¨ˆç®—çµ±è¨ˆ
        avg_cpu = np.mean(self.performance_data['cpu'])
        max_cpu = np.max(self.performance_data['cpu'])
        avg_memory = np.mean(self.performance_data['memory'])
        max_memory = np.max(self.performance_data['memory'])
        avg_latency = np.mean(self.performance_data['latency'])
        max_latency = np.max(self.performance_data['latency'])
        
        result = {
            'test_name': 'å£“åŠ›æ¸¬è©¦',
            'duration': test_duration,
            'total_chunks': total_chunks,
            'avg_cpu_percent': avg_cpu,
            'max_cpu_percent': max_cpu,
            'avg_memory_mb': avg_memory,
            'max_memory_mb': max_memory,
            'avg_latency_ms': avg_latency,
            'max_latency_ms': max_latency,
            'realtime_factor': total_time / test_duration,
            'success': avg_latency < 50 and avg_cpu < 80  # å»¶é² < 50ms, CPU < 80%
        }
        
        self.test_results.append(result)
        
        logger.info(f"å£“åŠ›æ¸¬è©¦å®Œæˆ:")
        logger.info(f"  å¹³å‡ CPU: {avg_cpu:.1f}%")
        logger.info(f"  å¹³å‡è¨˜æ†¶é«”: {avg_memory:.1f} MB")
        logger.info(f"  å¹³å‡å»¶é²: {avg_latency:.1f} ms")
        logger.info(f"  å³æ™‚ä¿‚æ•¸: {result['realtime_factor']:.2f}x")
        
        # æ¸…ç†
        await self.pipeline_manager.remove_pipeline(pipeline_id)
    
    async def test_24hour_stability(self):
        """24 å°æ™‚ç©©å®šæ€§æ¸¬è©¦ï¼ˆæ¨¡æ“¬ï¼‰"""
        logger.info("\n=== é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦ï¼ˆæ¨¡æ“¬ï¼‰ ===")
        
        # å‰µå»ºæ¸¬è©¦ pipeline
        pipeline_config = {
            'name': 'stability_test_pipeline',
            'operators': [
                {'type': 'vad', 'config': {'threshold': 0.5}},
                {'type': 'recording', 'config': {'storage': {'type': 'memory'}}}
            ]
        }
        
        pipeline_id = await self.pipeline_manager.create_pipeline(pipeline_config)
        
        # æ¨¡æ“¬ 24 å°æ™‚ï¼ˆå¯¦éš›é‹è¡Œ 1 åˆ†é˜ï¼‰
        simulated_hours = 24
        actual_duration = 60  # ç§’
        chunks_per_hour = 100  # æ¯å°æ™‚è™•ç†çš„å¡Šæ•¸
        
        logger.info(f"é–‹å§‹ç©©å®šæ€§æ¸¬è©¦ï¼ˆæ¨¡æ“¬ {simulated_hours} å°æ™‚ï¼‰...")
        
        initial_memory = self.process_monitor.memory_info().rss / 1024 / 1024
        errors = 0
        processed_chunks = 0
        
        start_time = time.time()
        
        while time.time() - start_time < actual_duration:
            try:
                # ç”Ÿæˆéš¨æ©ŸéŸ³è¨Š
                chunk = self._generate_random_audio(self.chunk_size * 2)
                await self.pipeline_manager.process(pipeline_id, chunk)
                processed_chunks += 1
                
            except Exception as e:
                errors += 1
                logger.warning(f"è™•ç†éŒ¯èª¤: {e}")
            
            # æ¨¡æ“¬æ™‚é–“é–“éš”
            await asyncio.sleep(actual_duration / (simulated_hours * chunks_per_hour))
        
        # æœ€çµ‚è¨˜æ†¶é«”
        final_memory = self.process_monitor.memory_info().rss / 1024 / 1024
        memory_growth = final_memory - initial_memory
        
        result = {
            'test_name': 'ç©©å®šæ€§æ¸¬è©¦',
            'simulated_hours': simulated_hours,
            'actual_duration': actual_duration,
            'processed_chunks': processed_chunks,
            'errors': errors,
            'error_rate': errors / max(1, processed_chunks),
            'memory_growth_mb': memory_growth,
            'success': errors == 0 and memory_growth < 100
        }
        
        self.test_results.append(result)
        
        logger.info(f"ç©©å®šæ€§æ¸¬è©¦å®Œæˆ:")
        logger.info(f"  è™•ç†å¡Šæ•¸: {processed_chunks}")
        logger.info(f"  éŒ¯èª¤æ•¸: {errors}")
        logger.info(f"  è¨˜æ†¶é«”å¢é•·: {memory_growth:.1f} MB")
        
        # æ¸…ç†
        await self.pipeline_manager.remove_pipeline(pipeline_id)
    
    def _generate_test_audio(self, duration: float) -> bytes:
        """ç”Ÿæˆæ¸¬è©¦éŸ³è¨Š"""
        samples = int(duration * self.sample_rate)
        t = np.linspace(0, duration, samples)
        audio = 0.3 * np.sin(2 * np.pi * 440 * t)
        return (audio * 20000).astype(np.int16).tobytes()
    
    def _generate_speech(self, duration: float) -> bytes:
        """ç”Ÿæˆæ¨¡æ“¬èªéŸ³"""
        samples = int(duration * self.sample_rate)
        t = np.linspace(0, duration, samples)
        speech = np.zeros(samples)
        
        for f0 in [120, 200, 300]:
            speech += 0.3 * np.sin(2 * np.pi * f0 * t)
            for h in range(2, 5):
                speech += 0.1 / h * np.sin(2 * np.pi * f0 * h * t)
        
        envelope = 0.7 + 0.3 * np.sin(2 * np.pi * 3 * t)
        speech *= envelope
        
        return (speech / np.max(np.abs(speech)) * 25000).astype(np.int16).tobytes()
    
    def _generate_silence(self, duration: float) -> bytes:
        """ç”ŸæˆéœéŸ³"""
        samples = int(duration * self.sample_rate)
        return np.zeros(samples, dtype=np.int16).tobytes()
    
    def _generate_speech_with_silence(self, duration: float) -> bytes:
        """ç”ŸæˆèªéŸ³å’ŒéœéŸ³äº¤æ›¿çš„éŸ³è¨Š"""
        # ç°¡åŒ–å¯¦ä½œï¼Œäº¤æ›¿ç”ŸæˆèªéŸ³å’ŒéœéŸ³
        half_duration = duration / 2
        speech = self._generate_speech(half_duration)
        silence = self._generate_silence(half_duration)
        return speech + silence
    
    def _generate_random_audio(self, size: int) -> bytes:
        """ç”Ÿæˆéš¨æ©ŸéŸ³è¨Šè³‡æ–™"""
        return np.random.randint(-5000, 5000, size=size//2, dtype=np.int16).tobytes()
    
    def print_test_results(self):
        """æ‰“å°æ¸¬è©¦çµæœ"""
        print("\n" + "="*60)
        print("ğŸ“Š Pipeline æ•´åˆæ¸¬è©¦çµæœ")
        print("="*60)
        
        for result in self.test_results:
            test_name = result['test_name']
            success = result.get('success', False)
            status = "âœ… é€šé" if success else "âŒ å¤±æ•—"
            
            print(f"\n{test_name}: {status}")
            for key, value in result.items():
                if key not in ['test_name', 'success']:
                    if isinstance(value, float):
                        print(f"  {key}: {value:.3f}")
                    else:
                        print(f"  {key}: {value}")
        
        # ç¸½çµ
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r.get('success', False))
        
        print("\n" + "-"*60)
        print(f"ç¸½è¨ˆ: {passed_tests}/{total_tests} æ¸¬è©¦é€šé")
        
        # æ•ˆèƒ½ç¸½çµ
        stress_result = next((r for r in self.test_results if r['test_name'] == 'å£“åŠ›æ¸¬è©¦'), None)
        if stress_result:
            print("\næ•ˆèƒ½ç¸½çµ:")
            print(f"  å¹³å‡ CPU ä½¿ç”¨ç‡: {stress_result['avg_cpu_percent']:.1f}%")
            print(f"  å¹³å‡è™•ç†å»¶é²: {stress_result['avg_latency_ms']:.1f} ms")
            print(f"  å³æ™‚è™•ç†èƒ½åŠ›: {stress_result['realtime_factor']:.2f}x")
        
        print("="*60)
    
    def plot_performance_data(self):
        """ç¹ªè£½æ•ˆèƒ½è³‡æ–™åœ–è¡¨"""
        if not self.performance_data['timestamps']:
            return
            
        if not MATPLOTLIB_AVAILABLE:
            logger.warning("matplotlib æœªå®‰è£ï¼Œç„¡æ³•ç¹ªè£½æ•ˆèƒ½åœ–è¡¨")
            return
        
        fig, axes = plt.subplots(3, 1, figsize=(10, 10))
        
        # CPU ä½¿ç”¨ç‡
        ax1 = axes[0]
        ax1.plot(self.performance_data['timestamps'], self.performance_data['cpu'])
        ax1.set_title('CPU ä½¿ç”¨ç‡')
        ax1.set_xlabel('æ™‚é–“ (ç§’)')
        ax1.set_ylabel('CPU %')
        ax1.grid(True)
        
        # è¨˜æ†¶é«”ä½¿ç”¨
        ax2 = axes[1]
        ax2.plot(self.performance_data['timestamps'], self.performance_data['memory'])
        ax2.set_title('è¨˜æ†¶é«”ä½¿ç”¨')
        ax2.set_xlabel('æ™‚é–“ (ç§’)')
        ax2.set_ylabel('è¨˜æ†¶é«” (MB)')
        ax2.grid(True)
        
        # è™•ç†å»¶é²
        ax3 = axes[2]
        ax3.plot(self.performance_data['timestamps'], self.performance_data['latency'])
        ax3.set_title('è™•ç†å»¶é²')
        ax3.set_xlabel('æ™‚é–“ (ç§’)')
        ax3.set_ylabel('å»¶é² (ms)')
        ax3.grid(True)
        
        plt.tight_layout()
        plt.savefig('pipeline_performance.png')
        logger.info("æ•ˆèƒ½åœ–è¡¨å·²ä¿å­˜è‡³ pipeline_performance.png")


async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ”§ Pipeline æ•´åˆæ¸¬è©¦å·¥å…·")
    print("-" * 60)
    
    tester = PipelineIntegrationTester()
    
    try:
        # è¨­å®šæ¸¬è©¦ç’°å¢ƒ
        await tester.setup()
        
        # åŸ·è¡Œæ¸¬è©¦å¥—ä»¶
        tests = [
            ("åŸºæœ¬ Pipeline", tester.test_basic_pipeline),
            ("å®Œæ•´ Pipeline", tester.test_complete_pipeline),
            ("å¤š Pipeline ä¸¦è¡Œ", tester.test_multiple_pipelines),
            ("éŒ¯èª¤æ¢å¾©", tester.test_error_recovery),
            ("å£“åŠ›æ¸¬è©¦", tester.test_performance_stress),
        ]
        
        # è©¢å•æ˜¯å¦åŸ·è¡Œé•·æ™‚é–“æ¸¬è©¦
        if input("\næ˜¯å¦åŸ·è¡Œé•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦ï¼ˆéœ€è¦ 1 åˆ†é˜ï¼‰ï¼Ÿ(y/n): ").lower() == 'y':
            tests.append(("ç©©å®šæ€§æ¸¬è©¦", tester.test_24hour_stability))
        
        for test_name, test_func in tests:
            print(f"\nåŸ·è¡Œæ¸¬è©¦: {test_name}")
            try:
                await test_func()
            except Exception as e:
                logger.error(f"æ¸¬è©¦å¤±æ•—: {e}")
                import traceback
                traceback.print_exc()
        
    except KeyboardInterrupt:
        print("\næ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\næ¸¬è©¦éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†è³‡æº
        await tester.cleanup()
        
        # æ‰“å°çµæœ
        tester.print_test_results()
        
        # ç¹ªè£½æ•ˆèƒ½åœ–è¡¨
        if input("\næ˜¯å¦ç”Ÿæˆæ•ˆèƒ½åœ–è¡¨ï¼Ÿ(y/n): ").lower() == 'y':
            tester.plot_performance_data()


if __name__ == "__main__":
    asyncio.run(main())